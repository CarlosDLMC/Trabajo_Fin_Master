{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from cryptocmd import CmcScraper\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from matplotlib import style, pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "tf.random.set_seed(42)\n",
    "WINDOW_SIZE = 7\n",
    "PRICE = 'Precio'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_crypto_df(sym):\n",
    "    scraper = CmcScraper(sym)\n",
    "    return scraper.get_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def only_prices_df(df):\n",
    "    result = df.copy()\n",
    "    result.set_index('Date', inplace=True)\n",
    "    return pd.DataFrame(result['Open']).rename(columns={'Open': PRICE}).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_windows(df, window_size):\n",
    "    result = df.copy()\n",
    "    for i in range(1, window_size + 1):\n",
    "        result[f\"Precio - {i} dia(s)\"] = result[PRICE].shift(periods=i)\n",
    "    return result.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_train_test_datasets(X, y, split=0.8, batch_size=128):\n",
    "    split_size = int(len(X) * split)\n",
    "    X_train, y_train = X[:split_size], y[:split_size]\n",
    "    X_test, y_test = X[split_size:], y[split_size:]\n",
    "    \n",
    "    train_datos = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "    train_etiquetas = tf.data.Dataset.from_tensor_slices(y_train)\n",
    "    test_datos = tf.data.Dataset.from_tensor_slices(X_test)\n",
    "    test_etiquetas = tf.data.Dataset.from_tensor_slices(y_test)\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.zip((train_datos, train_etiquetas))\n",
    "    test_dataset = tf.data.Dataset.zip((test_datos, test_etiquetas))\n",
    "    AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    train_dataset = train_dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    test_dataset = test_dataset.batch(batch_size).prefetch(AUTOTUNE)\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_checkpoint(name, metric='val_loss'):\n",
    "    return ModelCheckpoint(save_best_only=True, filepath=os.path.join(\"modelos\", name), monitor=metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Market Cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3402</th>\n",
       "      <td>2013-04-28</td>\n",
       "      <td>135.300003</td>\n",
       "      <td>135.979996</td>\n",
       "      <td>132.100006</td>\n",
       "      <td>134.210007</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.488567e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3401</th>\n",
       "      <td>2013-04-29</td>\n",
       "      <td>134.444000</td>\n",
       "      <td>147.488007</td>\n",
       "      <td>134.000000</td>\n",
       "      <td>144.539993</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.603769e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3400</th>\n",
       "      <td>2013-04-30</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>146.929993</td>\n",
       "      <td>134.050003</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.542813e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3399</th>\n",
       "      <td>2013-05-01</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>139.889999</td>\n",
       "      <td>107.720001</td>\n",
       "      <td>116.989998</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.298955e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3398</th>\n",
       "      <td>2013-05-02</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>125.599998</td>\n",
       "      <td>92.281898</td>\n",
       "      <td>105.209999</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.168517e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-08-17</td>\n",
       "      <td>23881.315512</td>\n",
       "      <td>24407.057907</td>\n",
       "      <td>23243.354456</td>\n",
       "      <td>23335.998222</td>\n",
       "      <td>3.093162e+10</td>\n",
       "      <td>4.462836e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-08-18</td>\n",
       "      <td>23341.038978</td>\n",
       "      <td>23563.831594</td>\n",
       "      <td>23177.602470</td>\n",
       "      <td>23212.739077</td>\n",
       "      <td>2.374761e+10</td>\n",
       "      <td>4.439473e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-08-19</td>\n",
       "      <td>23213.313242</td>\n",
       "      <td>23213.313242</td>\n",
       "      <td>20868.847439</td>\n",
       "      <td>20877.553692</td>\n",
       "      <td>4.050961e+10</td>\n",
       "      <td>3.993093e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-08-20</td>\n",
       "      <td>20872.842174</td>\n",
       "      <td>21350.806299</td>\n",
       "      <td>20856.731336</td>\n",
       "      <td>21166.060396</td>\n",
       "      <td>2.759567e+10</td>\n",
       "      <td>4.048481e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-08-21</td>\n",
       "      <td>21160.392783</td>\n",
       "      <td>21668.845908</td>\n",
       "      <td>21103.196808</td>\n",
       "      <td>21534.121231</td>\n",
       "      <td>2.310231e+10</td>\n",
       "      <td>4.119067e+11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3403 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date          Open          High           Low         Close  \\\n",
       "3402 2013-04-28    135.300003    135.979996    132.100006    134.210007   \n",
       "3401 2013-04-29    134.444000    147.488007    134.000000    144.539993   \n",
       "3400 2013-04-30    144.000000    146.929993    134.050003    139.000000   \n",
       "3399 2013-05-01    139.000000    139.889999    107.720001    116.989998   \n",
       "3398 2013-05-02    116.379997    125.599998     92.281898    105.209999   \n",
       "...         ...           ...           ...           ...           ...   \n",
       "4    2022-08-17  23881.315512  24407.057907  23243.354456  23335.998222   \n",
       "3    2022-08-18  23341.038978  23563.831594  23177.602470  23212.739077   \n",
       "2    2022-08-19  23213.313242  23213.313242  20868.847439  20877.553692   \n",
       "1    2022-08-20  20872.842174  21350.806299  20856.731336  21166.060396   \n",
       "0    2022-08-21  21160.392783  21668.845908  21103.196808  21534.121231   \n",
       "\n",
       "            Volume    Market Cap  \n",
       "3402  0.000000e+00  1.488567e+09  \n",
       "3401  0.000000e+00  1.603769e+09  \n",
       "3400  0.000000e+00  1.542813e+09  \n",
       "3399  0.000000e+00  1.298955e+09  \n",
       "3398  0.000000e+00  1.168517e+09  \n",
       "...            ...           ...  \n",
       "4     3.093162e+10  4.462836e+11  \n",
       "3     2.374761e+10  4.439473e+11  \n",
       "2     4.050961e+10  3.993093e+11  \n",
       "1     2.759567e+10  4.048481e+11  \n",
       "0     2.310231e+10  4.119067e+11  \n",
       "\n",
       "[3403 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = get_crypto_df('BTC')[::-1]\n",
    "df_original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precio</th>\n",
       "      <th>Precio - 1 dia(s)</th>\n",
       "      <th>Precio - 2 dia(s)</th>\n",
       "      <th>Precio - 3 dia(s)</th>\n",
       "      <th>Precio - 4 dia(s)</th>\n",
       "      <th>Precio - 5 dia(s)</th>\n",
       "      <th>Precio - 6 dia(s)</th>\n",
       "      <th>Precio - 7 dia(s)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2013-05-05</th>\n",
       "      <td>112.900002</td>\n",
       "      <td>98.099998</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>134.444000</td>\n",
       "      <td>135.300003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-06</th>\n",
       "      <td>115.980003</td>\n",
       "      <td>112.900002</td>\n",
       "      <td>98.099998</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>144.000000</td>\n",
       "      <td>134.444000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-07</th>\n",
       "      <td>112.250000</td>\n",
       "      <td>115.980003</td>\n",
       "      <td>112.900002</td>\n",
       "      <td>98.099998</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>139.000000</td>\n",
       "      <td>144.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-08</th>\n",
       "      <td>109.599998</td>\n",
       "      <td>112.250000</td>\n",
       "      <td>115.980003</td>\n",
       "      <td>112.900002</td>\n",
       "      <td>98.099998</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>116.379997</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2013-05-09</th>\n",
       "      <td>113.199997</td>\n",
       "      <td>109.599998</td>\n",
       "      <td>112.250000</td>\n",
       "      <td>115.980003</td>\n",
       "      <td>112.900002</td>\n",
       "      <td>98.099998</td>\n",
       "      <td>106.250000</td>\n",
       "      <td>116.379997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-17</th>\n",
       "      <td>23881.316406</td>\n",
       "      <td>24126.136719</td>\n",
       "      <td>24318.316406</td>\n",
       "      <td>24429.056641</td>\n",
       "      <td>24402.187500</td>\n",
       "      <td>23957.203125</td>\n",
       "      <td>23948.345703</td>\n",
       "      <td>23162.898438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-18</th>\n",
       "      <td>23341.039062</td>\n",
       "      <td>23881.316406</td>\n",
       "      <td>24126.136719</td>\n",
       "      <td>24318.316406</td>\n",
       "      <td>24429.056641</td>\n",
       "      <td>24402.187500</td>\n",
       "      <td>23957.203125</td>\n",
       "      <td>23948.345703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-19</th>\n",
       "      <td>23213.312500</td>\n",
       "      <td>23341.039062</td>\n",
       "      <td>23881.316406</td>\n",
       "      <td>24126.136719</td>\n",
       "      <td>24318.316406</td>\n",
       "      <td>24429.056641</td>\n",
       "      <td>24402.187500</td>\n",
       "      <td>23957.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-20</th>\n",
       "      <td>20872.841797</td>\n",
       "      <td>23213.312500</td>\n",
       "      <td>23341.039062</td>\n",
       "      <td>23881.316406</td>\n",
       "      <td>24126.136719</td>\n",
       "      <td>24318.316406</td>\n",
       "      <td>24429.056641</td>\n",
       "      <td>24402.187500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-08-21</th>\n",
       "      <td>21160.392578</td>\n",
       "      <td>20872.841797</td>\n",
       "      <td>23213.312500</td>\n",
       "      <td>23341.039062</td>\n",
       "      <td>23881.316406</td>\n",
       "      <td>24126.136719</td>\n",
       "      <td>24318.316406</td>\n",
       "      <td>24429.056641</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3396 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Precio  Precio - 1 dia(s)  Precio - 2 dia(s)  \\\n",
       "Date                                                             \n",
       "2013-05-05    112.900002          98.099998         106.250000   \n",
       "2013-05-06    115.980003         112.900002          98.099998   \n",
       "2013-05-07    112.250000         115.980003         112.900002   \n",
       "2013-05-08    109.599998         112.250000         115.980003   \n",
       "2013-05-09    113.199997         109.599998         112.250000   \n",
       "...                  ...                ...                ...   \n",
       "2022-08-17  23881.316406       24126.136719       24318.316406   \n",
       "2022-08-18  23341.039062       23881.316406       24126.136719   \n",
       "2022-08-19  23213.312500       23341.039062       23881.316406   \n",
       "2022-08-20  20872.841797       23213.312500       23341.039062   \n",
       "2022-08-21  21160.392578       20872.841797       23213.312500   \n",
       "\n",
       "            Precio - 3 dia(s)  Precio - 4 dia(s)  Precio - 5 dia(s)  \\\n",
       "Date                                                                  \n",
       "2013-05-05         116.379997         139.000000         144.000000   \n",
       "2013-05-06         106.250000         116.379997         139.000000   \n",
       "2013-05-07          98.099998         106.250000         116.379997   \n",
       "2013-05-08         112.900002          98.099998         106.250000   \n",
       "2013-05-09         115.980003         112.900002          98.099998   \n",
       "...                       ...                ...                ...   \n",
       "2022-08-17       24429.056641       24402.187500       23957.203125   \n",
       "2022-08-18       24318.316406       24429.056641       24402.187500   \n",
       "2022-08-19       24126.136719       24318.316406       24429.056641   \n",
       "2022-08-20       23881.316406       24126.136719       24318.316406   \n",
       "2022-08-21       23341.039062       23881.316406       24126.136719   \n",
       "\n",
       "            Precio - 6 dia(s)  Precio - 7 dia(s)  \n",
       "Date                                              \n",
       "2013-05-05         134.444000         135.300003  \n",
       "2013-05-06         144.000000         134.444000  \n",
       "2013-05-07         139.000000         144.000000  \n",
       "2013-05-08         116.379997         139.000000  \n",
       "2013-05-09         106.250000         116.379997  \n",
       "...                       ...                ...  \n",
       "2022-08-17       23948.345703       23162.898438  \n",
       "2022-08-18       23957.203125       23948.345703  \n",
       "2022-08-19       24402.187500       23957.203125  \n",
       "2022-08-20       24429.056641       24402.187500  \n",
       "2022-08-21       24318.316406       24429.056641  \n",
       "\n",
       "[3396 rows x 8 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prices = only_prices_df(df_original)\n",
    "prices = create_windows(prices, 7)\n",
    "prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<PrefetchDataset shapes: ((None, 7), (None,)), types: (tf.float32, tf.float32)>,\n",
       " <PrefetchDataset shapes: ((None, 7), (None,)), types: (tf.float32, tf.float32)>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### Probamos el modelo simple solo con los precios ######\n",
    "X = prices.drop(\"Precio\", axis=1)\n",
    "y = prices[\"Precio\"]\n",
    "train_dataset_price, test_dataset_price = get_train_test_datasets(X, y)\n",
    "train_dataset_price, test_dataset_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 122.6308 - mae: 122.6308WARNING:tensorflow:From /home/mentefria/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 1449.2683 - mae: 1449.2683 - val_loss: 4244.1523 - val_mae: 4244.1523 - lr: 0.0010\n",
      "Epoch 2/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 12.0164 - mae: 12.0164INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 386.2114 - mae: 386.2114 - val_loss: 3109.2629 - val_mae: 3109.2629 - lr: 0.0010\n",
      "Epoch 3/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 8.7712 - mae: 8.7712INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 196.9995 - mae: 196.9995 - val_loss: 1878.1392 - val_mae: 1878.1392 - lr: 0.0010\n",
      "Epoch 4/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.1890 - mae: 5.1890INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 187.5509 - mae: 187.5509 - val_loss: 1856.9244 - val_mae: 1856.9244 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 183.8182 - mae: 183.8182 - val_loss: 1877.1147 - val_mae: 1877.1147 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 233.8544 - mae: 233.8544 - val_loss: 1921.6956 - val_mae: 1921.6956 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 419.6327 - mae: 419.6327 - val_loss: 3053.5833 - val_mae: 3053.5833 - lr: 0.0010\n",
      "Epoch 8/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 8.6860 - mae: 8.6860INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 17ms/step - loss: 188.9910 - mae: 188.9910 - val_loss: 1806.9232 - val_mae: 1806.9232 - lr: 0.0010\n",
      "Epoch 9/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 4.9216 - mae: 4.9216INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 234.9097 - mae: 234.9097 - val_loss: 1790.5459 - val_mae: 1790.5459 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 330.0934 - mae: 330.0934 - val_loss: 2324.3184 - val_mae: 2324.3184 - lr: 0.0010\n",
      "Epoch 11/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.6488 - mae: 6.6488INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 209.2106 - mae: 209.2106 - val_loss: 1784.7333 - val_mae: 1784.7333 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 260.9218 - mae: 260.9218 - val_loss: 1813.8197 - val_mae: 1813.8197 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 305.8865 - mae: 305.8865 - val_loss: 2162.1082 - val_mae: 2162.1082 - lr: 0.0010\n",
      "Epoch 14/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.2547 - mae: 6.2547INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 214.2859 - mae: 214.2859 - val_loss: 1783.7853 - val_mae: 1783.7853 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 251.2216 - mae: 251.2216 - val_loss: 1921.6689 - val_mae: 1921.6689 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 236.1283 - mae: 236.1283 - val_loss: 1885.8688 - val_mae: 1885.8688 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 225.5200 - mae: 225.5200 - val_loss: 1830.2034 - val_mae: 1830.2034 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 229.2244 - mae: 229.2244 - val_loss: 1835.5261 - val_mae: 1835.5261 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 226.9732 - mae: 226.9732 - val_loss: 1842.3932 - val_mae: 1842.3932 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 219.3376 - mae: 219.3376 - val_loss: 1796.4401 - val_mae: 1796.4401 - lr: 0.0010\n",
      "Epoch 21/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.2755 - mae: 5.2755INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 220.6025 - mae: 220.6025 - val_loss: 1772.0872 - val_mae: 1772.0872 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 225.4554 - mae: 225.4554 - val_loss: 1824.8989 - val_mae: 1824.8989 - lr: 0.0010\n",
      "Epoch 23/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.4636 - mae: 5.4636INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 211.4273 - mae: 211.4273 - val_loss: 1767.7279 - val_mae: 1767.7279 - lr: 0.0010\n",
      "Epoch 24/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.2591 - mae: 5.2591INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 209.4786 - mae: 209.4786 - val_loss: 1747.0850 - val_mae: 1747.0850 - lr: 0.0010\n",
      "Epoch 25/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.2009 - mae: 5.2009INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 212.9610 - mae: 212.9610 - val_loss: 1740.7246 - val_mae: 1740.7246 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 218.5982 - mae: 218.5982 - val_loss: 1777.1475 - val_mae: 1777.1475 - lr: 0.0010\n",
      "Epoch 27/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.3929 - mae: 5.3929INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 208.4304 - mae: 208.4304 - val_loss: 1726.6482 - val_mae: 1726.6482 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 208.0540 - mae: 208.0540 - val_loss: 1745.8575 - val_mae: 1745.8575 - lr: 0.0010\n",
      "Epoch 29/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.3180 - mae: 5.3180INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 204.8128 - mae: 204.8128 - val_loss: 1726.2308 - val_mae: 1726.2308 - lr: 0.0010\n",
      "Epoch 30/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.2868 - mae: 5.2868INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 201.9819 - mae: 201.9819 - val_loss: 1655.1725 - val_mae: 1655.1725 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 222.7183 - mae: 222.7183 - val_loss: 1764.6116 - val_mae: 1764.6116 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 204.8085 - mae: 204.8085 - val_loss: 1729.8572 - val_mae: 1729.8572 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 193.8894 - mae: 193.8894 - val_loss: 1655.8013 - val_mae: 1655.8013 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 206.0061 - mae: 206.0061 - val_loss: 1683.9978 - val_mae: 1683.9978 - lr: 0.0010\n",
      "Epoch 35/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.2551 - mae: 5.2551INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 192.1911 - mae: 192.1911 - val_loss: 1649.5789 - val_mae: 1649.5789 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 240.4354 - mae: 240.4354 - val_loss: 1743.1750 - val_mae: 1743.1750 - lr: 0.0010\n",
      "Epoch 37/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 467.6034 - mae: 467.6034 - val_loss: 1707.4364 - val_mae: 1707.4364 - lr: 0.0010\n",
      "Epoch 38/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.2004 - mae: 5.2004INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 199.9826 - mae: 199.9826 - val_loss: 1587.4897 - val_mae: 1587.4897 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 275.1357 - mae: 275.1357 - val_loss: 2016.3198 - val_mae: 2016.3198 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 237.7717 - mae: 237.7717 - val_loss: 1898.4343 - val_mae: 1898.4343 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 205.3978 - mae: 205.3978 - val_loss: 1676.2590 - val_mae: 1676.2590 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 198.5486 - mae: 198.5486 - val_loss: 1708.8132 - val_mae: 1708.8132 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 216.4590 - mae: 216.4590 - val_loss: 1760.3119 - val_mae: 1760.3119 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 184.4219 - mae: 184.4219 - val_loss: 1653.0099 - val_mae: 1653.0099 - lr: 0.0010\n",
      "Epoch 45/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 4.9632 - mae: 4.9632INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 214.5449 - mae: 214.5449 - val_loss: 1575.8125 - val_mae: 1575.8125 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 220.5875 - mae: 220.5875 - val_loss: 1799.2540 - val_mae: 1799.2540 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 198.9325 - mae: 198.9325 - val_loss: 1700.7646 - val_mae: 1700.7646 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 193.9270 - mae: 193.9270 - val_loss: 1623.2443 - val_mae: 1623.2443 - lr: 0.0010\n",
      "Epoch 49/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.4569 - mae: 5.4569INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 166.3873 - mae: 166.3873 - val_loss: 1497.9265 - val_mae: 1497.9265 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 260.8152 - mae: 260.8152 - val_loss: 1800.9823 - val_mae: 1800.9823 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 195.3620 - mae: 195.3620 - val_loss: 1568.3551 - val_mae: 1568.3551 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 221.6460 - mae: 221.6460 - val_loss: 1697.3401 - val_mae: 1697.3401 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 193.7540 - mae: 193.7540 - val_loss: 1549.8965 - val_mae: 1549.8965 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 215.2570 - mae: 215.2570 - val_loss: 1637.3190 - val_mae: 1637.3190 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 192.7357 - mae: 192.7357 - val_loss: 1572.1824 - val_mae: 1572.1824 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 194.1818 - mae: 194.1818 - val_loss: 1528.6892 - val_mae: 1528.6892 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 206.7366 - mae: 206.7366 - val_loss: 1690.1759 - val_mae: 1690.1759 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 170.9905 - mae: 170.9905 - val_loss: 1567.8405 - val_mae: 1567.8405 - lr: 0.0010\n",
      "Epoch 59/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.6062 - mae: 5.6062INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 162.9981 - mae: 162.9981 - val_loss: 1454.1155 - val_mae: 1454.1155 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 220.8515 - mae: 220.8515 - val_loss: 1693.5615 - val_mae: 1693.5615 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 177.1956 - mae: 177.1956 - val_loss: 1511.7732 - val_mae: 1511.7732 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 192.9992 - mae: 192.9992 - val_loss: 1552.8412 - val_mae: 1552.8412 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 189.9921 - mae: 189.9921 - val_loss: 1517.9039 - val_mae: 1517.9039 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 195.7023 - mae: 195.7023 - val_loss: 1605.2365 - val_mae: 1605.2365 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 1ms/step - loss: 173.6065 - mae: 173.6065 - val_loss: 1513.2877 - val_mae: 1513.2877 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 177.5234 - mae: 177.5234 - val_loss: 1492.3710 - val_mae: 1492.3710 - lr: 0.0010\n",
      "Epoch 67/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.6072 - mae: 5.6072INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 169.3326 - mae: 169.3326 - val_loss: 1448.3136 - val_mae: 1448.3136 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 248.8470 - mae: 248.8470 - val_loss: 1887.9600 - val_mae: 1887.9600 - lr: 0.0010\n",
      "Epoch 69/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.7697 - mae: 7.7697INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 159.1658 - mae: 159.1658 - val_loss: 1441.8971 - val_mae: 1441.8971 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 193.0728 - mae: 193.0728 - val_loss: 1528.8893 - val_mae: 1528.8893 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 188.5349 - mae: 188.5349 - val_loss: 1652.3518 - val_mae: 1652.3518 - lr: 0.0010\n",
      "Epoch 72/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.7519 - mae: 6.7519INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 155.7377 - mae: 155.7377 - val_loss: 1427.1580 - val_mae: 1427.1580 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 188.6231 - mae: 188.6231 - val_loss: 1505.5590 - val_mae: 1505.5590 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 188.6050 - mae: 188.6050 - val_loss: 1548.0828 - val_mae: 1548.0828 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 172.0915 - mae: 172.0915 - val_loss: 1464.1282 - val_mae: 1464.1282 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 183.8114 - mae: 183.8114 - val_loss: 1561.4037 - val_mae: 1561.4037 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 188.8446 - mae: 188.8446 - val_loss: 1538.2700 - val_mae: 1538.2700 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 174.5191 - mae: 174.5191 - val_loss: 1552.7034 - val_mae: 1552.7034 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 189.8088 - mae: 189.8088 - val_loss: 1552.9329 - val_mae: 1552.9329 - lr: 0.0010\n",
      "Epoch 80/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.1492 - mae: 6.1492INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 171.2499 - mae: 171.2499 - val_loss: 1406.2805 - val_mae: 1406.2805 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 215.3560 - mae: 215.3560 - val_loss: 1689.2357 - val_mae: 1689.2357 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 162.8696 - mae: 162.8696 - val_loss: 1427.1516 - val_mae: 1427.1516 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 187.5724 - mae: 187.5724 - val_loss: 1640.0575 - val_mae: 1640.0575 - lr: 0.0010\n",
      "Epoch 84/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.1079 - mae: 7.1079INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 147.1332 - mae: 147.1332 - val_loss: 1383.1450 - val_mae: 1383.1450 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 188.0936 - mae: 188.0936 - val_loss: 1429.7167 - val_mae: 1429.7167 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 205.6812 - mae: 205.6812 - val_loss: 1692.8535 - val_mae: 1692.8535 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 151.3256 - mae: 151.3256 - val_loss: 1448.7712 - val_mae: 1448.7712 - lr: 0.0010\n",
      "Epoch 88/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.3042 - mae: 5.3042INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 143.4516 - mae: 143.4516 - val_loss: 1367.9041 - val_mae: 1367.9041 - lr: 0.0010\n",
      "Epoch 89/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.4278 - mae: 5.4278INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 135.9203 - mae: 135.9203 - val_loss: 1313.2416 - val_mae: 1313.2416 - lr: 0.0010\n",
      "Epoch 90/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.1727 - mae: 5.1727INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 129.4051 - mae: 129.4051 - val_loss: 1312.0466 - val_mae: 1312.0466 - lr: 0.0010\n",
      "Epoch 91/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 4.6989 - mae: 4.6989INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 124.4161 - mae: 124.4161 - val_loss: 1272.0063 - val_mae: 1272.0063 - lr: 0.0010\n",
      "Epoch 92/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.3409 - mae: 5.3409INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 15ms/step - loss: 123.4411 - mae: 123.4411 - val_loss: 1259.5043 - val_mae: 1259.5043 - lr: 0.0010\n",
      "Epoch 93/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.4338 - mae: 5.4338INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 122.4719 - mae: 122.4719 - val_loss: 1252.3237 - val_mae: 1252.3237 - lr: 0.0010\n",
      "Epoch 94/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.4791 - mae: 5.4791INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 18ms/step - loss: 122.2598 - mae: 122.2598 - val_loss: 1237.8424 - val_mae: 1237.8424 - lr: 0.0010\n",
      "Epoch 95/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.2532 - mae: 5.2532INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 120.2466 - mae: 120.2466 - val_loss: 1231.1725 - val_mae: 1231.1725 - lr: 0.0010\n",
      "Epoch 96/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 4.9890 - mae: 4.9890INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 119.4108 - mae: 119.4108 - val_loss: 1226.5017 - val_mae: 1226.5017 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 119.5908 - mae: 119.5908 - val_loss: 1242.0344 - val_mae: 1242.0344 - lr: 0.0010\n",
      "Epoch 98/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 4.5643 - mae: 4.5643INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 16ms/step - loss: 123.9865 - mae: 123.9865 - val_loss: 1221.6162 - val_mae: 1221.6162 - lr: 0.0010\n",
      "Epoch 99/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 5.5639 - mae: 5.5639INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 13ms/step - loss: 118.7294 - mae: 118.7294 - val_loss: 1209.4061 - val_mae: 1209.4061 - lr: 0.0010\n",
      "Epoch 100/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 4.9925 - mae: 4.9925INFO:tensorflow:Assets written to: modelos/FCC_simple/assets\n",
      "22/22 [==============================] - 0s 14ms/step - loss: 118.5395 - mae: 118.5395 - val_loss: 1209.3976 - val_mae: 1209.3976 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7120fabd30>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1 = tf.keras.Sequential([\n",
    "    layers.Dense(128, activation=\"relu\"),\n",
    "    layers.Dense(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"linear\")\n",
    "], name=\"FCC_simple\")\n",
    "\n",
    "model_1.compile(loss=\"mae\",\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=[\"mae\"])\n",
    "\n",
    "model_1.fit(train_dataset_price,\n",
    "                 epochs=100,\n",
    "                 validation_data=test_dataset_price,\n",
    "                 verbose=1,\n",
    "                 callbacks=[model_checkpoint(model_1.name),\n",
    "                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 1209.3976 - mean_absolute_error: 1209.3976\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1209.3975830078125, 1209.3975830078125]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_1_best = tf.keras.models.load_model(os.path.join('modelos', 'FCC_simple'))\n",
    "model_1_best.evaluate(test_dataset_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 2989.7854 - mae: 2989.7854INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 2989.7854 - mae: 2989.7854 - val_loss: 26376.7617 - val_mae: 26376.7617 - lr: 0.0010\n",
      "Epoch 2/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 73.6007 - mae: 73.6007INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 1434.9688 - mae: 1434.9688 - val_loss: 6533.4575 - val_mae: 6533.4575 - lr: 0.0010\n",
      "Epoch 3/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 17.9170 - mae: 17.9170INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 458.6756 - mae: 458.6756 - val_loss: 2744.7803 - val_mae: 2744.7803 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 387.5008 - mae: 387.5008 - val_loss: 2777.9453 - val_mae: 2777.9453 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 372.7372 - mae: 372.7372 - val_loss: 2791.3425 - val_mae: 2791.3425 - lr: 0.0010\n",
      "Epoch 6/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.7618 - mae: 7.7618INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 260.1784 - mae: 260.1784 - val_loss: 2424.8020 - val_mae: 2424.8020 - lr: 0.0010\n",
      "Epoch 7/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.8483 - mae: 6.8483INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 225.5218 - mae: 225.5218 - val_loss: 2253.7686 - val_mae: 2253.7686 - lr: 0.0010\n",
      "Epoch 8/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.4712 - mae: 6.4712INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 238.6992 - mae: 238.6992 - val_loss: 2216.7241 - val_mae: 2216.7241 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 262.6355 - mae: 262.6355 - val_loss: 2352.3923 - val_mae: 2352.3923 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 237.9099 - mae: 237.9099 - val_loss: 2240.2781 - val_mae: 2240.2781 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 244.8055 - mae: 244.8055 - val_loss: 2237.4714 - val_mae: 2237.4714 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 253.0914 - mae: 253.0914 - val_loss: 2281.1658 - val_mae: 2281.1658 - lr: 0.0010\n",
      "Epoch 13/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.5781 - mae: 6.5781INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 243.2697 - mae: 243.2697 - val_loss: 2186.5276 - val_mae: 2186.5276 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 262.0841 - mae: 262.0841 - val_loss: 2305.2676 - val_mae: 2305.2676 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 236.5903 - mae: 236.5903 - val_loss: 2188.2913 - val_mae: 2188.2913 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 246.9047 - mae: 246.9047 - val_loss: 2212.6335 - val_mae: 2212.6335 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 248.5033 - mae: 248.5033 - val_loss: 2227.8403 - val_mae: 2227.8403 - lr: 0.0010\n",
      "Epoch 18/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.5065 - mae: 6.5065INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 244.5844 - mae: 244.5844 - val_loss: 2185.3691 - val_mae: 2185.3691 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 249.5224 - mae: 249.5224 - val_loss: 2217.1646 - val_mae: 2217.1646 - lr: 0.0010\n",
      "Epoch 20/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.5350 - mae: 6.5350INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 240.3145 - mae: 240.3145 - val_loss: 2149.3210 - val_mae: 2149.3210 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 250.5258 - mae: 250.5258 - val_loss: 2215.7288 - val_mae: 2215.7288 - lr: 0.0010\n",
      "Epoch 22/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.6019 - mae: 6.6019INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 235.8420 - mae: 235.8420 - val_loss: 2146.4153 - val_mae: 2146.4153 - lr: 0.0010\n",
      "Epoch 23/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.3689 - mae: 6.3689INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 239.3498 - mae: 239.3498 - val_loss: 2142.0808 - val_mae: 2142.0808 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 245.1748 - mae: 245.1748 - val_loss: 2165.4712 - val_mae: 2165.4712 - lr: 0.0010\n",
      "Epoch 25/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.5454 - mae: 6.5454INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 237.4813 - mae: 237.4813 - val_loss: 2107.1389 - val_mae: 2107.1389 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 245.7024 - mae: 245.7024 - val_loss: 2169.4514 - val_mae: 2169.4514 - lr: 0.0010\n",
      "Epoch 27/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.6738 - mae: 6.6738INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 233.1734 - mae: 233.1734 - val_loss: 2073.5918 - val_mae: 2073.5918 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 247.8476 - mae: 247.8476 - val_loss: 2182.4526 - val_mae: 2182.4526 - lr: 0.0010\n",
      "Epoch 29/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.8485 - mae: 6.8485INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 229.0595 - mae: 229.0595 - val_loss: 2061.2024 - val_mae: 2061.2024 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 242.0447 - mae: 242.0447 - val_loss: 2112.5610 - val_mae: 2112.5610 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 234.3395 - mae: 234.3395 - val_loss: 2099.2444 - val_mae: 2099.2444 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 233.7941 - mae: 233.7941 - val_loss: 2076.7834 - val_mae: 2076.7834 - lr: 0.0010\n",
      "Epoch 33/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.6250 - mae: 6.6250INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 231.2945 - mae: 231.2945 - val_loss: 1970.0509 - val_mae: 1970.0509 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 265.9565 - mae: 265.9565 - val_loss: 2219.9468 - val_mae: 2219.9468 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 222.3883 - mae: 222.3883 - val_loss: 2026.0724 - val_mae: 2026.0724 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 235.7292 - mae: 235.7292 - val_loss: 2072.3965 - val_mae: 2072.3965 - lr: 0.0010\n",
      "Epoch 37/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 6.8850 - mae: 6.8850INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 225.8409 - mae: 225.8409 - val_loss: 1961.0717 - val_mae: 1961.0717 - lr: 0.0010\n",
      "Epoch 38/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 249.3447 - mae: 249.3447 - val_loss: 2070.9404 - val_mae: 2070.9404 - lr: 0.0010\n",
      "Epoch 39/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 2ms/step - loss: 237.7173 - mae: 237.7173 - val_loss: 2097.8789 - val_mae: 2097.8789 - lr: 0.0010\n",
      "Epoch 40/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.2273 - mae: 7.2273INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 218.5975 - mae: 218.5975 - val_loss: 1945.4772 - val_mae: 1945.4772 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 240.4846 - mae: 240.4846 - val_loss: 2047.9974 - val_mae: 2047.9974 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 230.8246 - mae: 230.8246 - val_loss: 2036.4261 - val_mae: 2036.4261 - lr: 0.0010\n",
      "Epoch 43/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.1355 - mae: 7.1355INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 222.5208 - mae: 222.5208 - val_loss: 1943.4385 - val_mae: 1943.4385 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 233.7597 - mae: 233.7597 - val_loss: 2006.4060 - val_mae: 2006.4060 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 227.0950 - mae: 227.0950 - val_loss: 1999.3435 - val_mae: 1999.3435 - lr: 0.0010\n",
      "Epoch 46/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.2024 - mae: 7.2024INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 221.3011 - mae: 221.3011 - val_loss: 1922.3849 - val_mae: 1922.3849 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 234.3880 - mae: 234.3880 - val_loss: 2011.1967 - val_mae: 2011.1967 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 225.0754 - mae: 225.0754 - val_loss: 1964.8982 - val_mae: 1964.8982 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 223.6282 - mae: 223.6282 - val_loss: 1942.0970 - val_mae: 1942.0970 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 226.4068 - mae: 226.4068 - val_loss: 1962.9269 - val_mae: 1962.9269 - lr: 0.0010\n",
      "Epoch 51/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.5172 - mae: 7.5172INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 218.2093 - mae: 218.2093 - val_loss: 1848.7933 - val_mae: 1848.7933 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 242.9745 - mae: 242.9745 - val_loss: 2059.3262 - val_mae: 2059.3262 - lr: 0.0010\n",
      "Epoch 53/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 8.3505 - mae: 8.3505INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 20ms/step - loss: 210.6254 - mae: 210.6254 - val_loss: 1836.2375 - val_mae: 1836.2375 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 236.5387 - mae: 236.5387 - val_loss: 1994.9296 - val_mae: 1994.9296 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 216.2976 - mae: 216.2976 - val_loss: 1870.4164 - val_mae: 1870.4164 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 224.8110 - mae: 224.8110 - val_loss: 1935.4607 - val_mae: 1935.4607 - lr: 0.0010\n",
      "Epoch 57/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.9705 - mae: 7.9705INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 1s 23ms/step - loss: 212.3251 - mae: 212.3251 - val_loss: 1786.9283 - val_mae: 1786.9283 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 250.2424 - mae: 250.2424 - val_loss: 2082.9937 - val_mae: 2082.9937 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 201.1513 - mae: 201.1513 - val_loss: 1835.8590 - val_mae: 1835.8590 - lr: 0.0010\n",
      "Epoch 60/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.3197 - mae: 7.3197INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 215.6964 - mae: 215.6964 - val_loss: 1775.3942 - val_mae: 1775.3942 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 249.2296 - mae: 249.2296 - val_loss: 2053.7622 - val_mae: 2053.7622 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 199.0756 - mae: 199.0756 - val_loss: 1811.3993 - val_mae: 1811.3993 - lr: 0.0010\n",
      "Epoch 63/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 7.4701 - mae: 7.4701INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 215.7204 - mae: 215.7204 - val_loss: 1767.6560 - val_mae: 1767.6560 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 245.5844 - mae: 245.5844 - val_loss: 2056.1421 - val_mae: 2056.1421 - lr: 0.0010\n",
      "Epoch 65/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 9.4971 - mae: 9.4971INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 196.3653 - mae: 196.3653 - val_loss: 1752.1814 - val_mae: 1752.1814 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 235.1201 - mae: 235.1201 - val_loss: 1938.6522 - val_mae: 1938.6522 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 207.8374 - mae: 207.8374 - val_loss: 1837.0560 - val_mae: 1837.0560 - lr: 0.0010\n",
      "Epoch 68/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 8.1948 - mae: 8.1948INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 21ms/step - loss: 207.6093 - mae: 207.6093 - val_loss: 1718.3588 - val_mae: 1718.3588 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 250.7813 - mae: 250.7813 - val_loss: 2058.5867 - val_mae: 2058.5867 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 193.9281 - mae: 193.9281 - val_loss: 1761.1667 - val_mae: 1761.1667 - lr: 0.0010\n",
      "Epoch 71/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 215.7280 - mae: 215.7280 - val_loss: 1759.4805 - val_mae: 1759.4805 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 231.5785 - mae: 231.5785 - val_loss: 1947.9225 - val_mae: 1947.9225 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 199.0620 - mae: 199.0620 - val_loss: 1743.2405 - val_mae: 1743.2405 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 220.2871 - mae: 220.2871 - val_loss: 1842.4861 - val_mae: 1842.4861 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 210.7298 - mae: 210.7298 - val_loss: 1797.1425 - val_mae: 1797.1425 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 210.5729 - mae: 210.5729 - val_loss: 1768.8717 - val_mae: 1768.8717 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 218.1037 - mae: 218.1037 - val_loss: 1833.8423 - val_mae: 1833.8423 - lr: 0.0010\n",
      "Epoch 78/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 9.4343 - mae: 9.4343INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 205.6951 - mae: 205.6951 - val_loss: 1695.1821 - val_mae: 1695.1821 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 233.1447 - mae: 233.1447 - val_loss: 1955.4967 - val_mae: 1955.4967 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 193.3837 - mae: 193.3837 - val_loss: 1733.5353 - val_mae: 1733.5353 - lr: 0.0010\n",
      "Epoch 81/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 8.6027 - mae: 8.6027INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 205.4556 - mae: 205.4556 - val_loss: 1628.3607 - val_mae: 1628.3607 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 82/100\n",
      "22/22 [==============================] - 0s 3ms/step - loss: 270.2261 - mae: 270.2261 - val_loss: 2244.4917 - val_mae: 2244.4917 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 178.0593 - mae: 178.0593 - val_loss: 1683.8750 - val_mae: 1683.8750 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 183.5544 - mae: 183.5544 - val_loss: 1633.8588 - val_mae: 1633.8588 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 265.9237 - mae: 265.9237 - val_loss: 2106.1067 - val_mae: 2106.1067 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 184.5920 - mae: 184.5920 - val_loss: 1717.7526 - val_mae: 1717.7526 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 198.2617 - mae: 198.2617 - val_loss: 1638.1389 - val_mae: 1638.1389 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 246.7305 - mae: 246.7305 - val_loss: 2048.3347 - val_mae: 2048.3347 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 179.3692 - mae: 179.3692 - val_loss: 1666.8441 - val_mae: 1666.8441 - lr: 0.0010\n",
      "Epoch 90/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 8.5933 - mae: 8.5933INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 22ms/step - loss: 200.8551 - mae: 200.8551 - val_loss: 1623.4541 - val_mae: 1623.4541 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 247.8898 - mae: 247.8898 - val_loss: 2053.3843 - val_mae: 2053.3843 - lr: 0.0010\n",
      "Epoch 92/100\n",
      " 1/22 [>.............................] - ETA: 0s - loss: 11.6095 - mae: 11.6095INFO:tensorflow:Assets written to: modelos/CNN_simple/assets\n",
      "22/22 [==============================] - 0s 19ms/step - loss: 174.7672 - mae: 174.7672 - val_loss: 1605.4968 - val_mae: 1605.4968 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 218.5750 - mae: 218.5750 - val_loss: 1676.2268 - val_mae: 1676.2268 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 225.2026 - mae: 225.2026 - val_loss: 1895.2406 - val_mae: 1895.2406 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 189.0634 - mae: 189.0634 - val_loss: 1686.8019 - val_mae: 1686.8019 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 201.4586 - mae: 201.4586 - val_loss: 1621.8528 - val_mae: 1621.8528 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 232.5310 - mae: 232.5310 - val_loss: 1924.8066 - val_mae: 1924.8066 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 182.1237 - mae: 182.1237 - val_loss: 1618.1605 - val_mae: 1618.1605 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 214.2551 - mae: 214.2551 - val_loss: 1749.1781 - val_mae: 1749.1781 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "22/22 [==============================] - 0s 2ms/step - loss: 200.5237 - mae: 200.5237 - val_loss: 1745.6218 - val_mae: 1745.6218 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f71200744f0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2 = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)),\n",
    "    layers.Conv1D(filters=16, kernel_size=4, padding=\"same\", activation=\"relu\"),\n",
    "    layers.Conv1D(filters=32,kernel_size=4,padding='same', activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(16),\n",
    "    layers.Dense(1)\n",
    "], name=\"CNN_simple\")\n",
    "\n",
    "model_2.compile(loss=\"mae\",\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=[\"mae\"])\n",
    "\n",
    "model_2.fit(train_dataset_price,\n",
    "                 epochs=100,\n",
    "                 validation_data=test_dataset_price,\n",
    "                 verbose=1,\n",
    "                 callbacks=[model_checkpoint(model_2.name),\n",
    "                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 1605.4968 - mean_absolute_error: 1605.4968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1605.496826171875, 1605.496826171875]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2_best = tf.keras.models.load_model(os.path.join('modelos', 'CNN_simple'))\n",
    "model_2_best.evaluate(test_dataset_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Epoch 1/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 1921.0135 - mae: 1921.0135INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 2974.2314 - mae: 2974.2314 - val_loss: 28355.7617 - val_mae: 28355.7617 - lr: 0.0010\n",
      "Epoch 2/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 1172.1711 - mae: 1172.1711INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 1838.7827 - mae: 1838.7827 - val_loss: 13599.8896 - val_mae: 13599.8896 - lr: 0.0010\n",
      "Epoch 3/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 249.6689 - mae: 249.6689INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 294.6134 - mae: 294.6134 - val_loss: 2250.8928 - val_mae: 2250.8928 - lr: 0.0010\n",
      "Epoch 4/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 166.6378 - mae: 166.6378INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 210.2908 - mae: 210.2908 - val_loss: 2011.0305 - val_mae: 2011.0305 - lr: 0.0010\n",
      "Epoch 5/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 141.0477 - mae: 141.0477INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 192.3037 - mae: 192.3037 - val_loss: 1930.5509 - val_mae: 1930.5509 - lr: 0.0010\n",
      "Epoch 6/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 189.6475 - mae: 189.6475 - val_loss: 2012.6602 - val_mae: 2012.6602 - lr: 0.0010\n",
      "Epoch 7/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 205.0405 - mae: 205.0405 - val_loss: 1970.2820 - val_mae: 1970.2820 - lr: 0.0010\n",
      "Epoch 8/100\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 120.9753 - mae: 120.9753INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 189.1234 - mae: 189.1234 - val_loss: 1875.2710 - val_mae: 1875.2710 - lr: 0.0010\n",
      "Epoch 9/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 176.3048 - mae: 176.3048 - val_loss: 1923.4088 - val_mae: 1923.4088 - lr: 0.0010\n",
      "Epoch 10/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 182.8274 - mae: 182.8274 - val_loss: 1938.2401 - val_mae: 1938.2401 - lr: 0.0010\n",
      "Epoch 11/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 195.9937 - mae: 195.9937 - val_loss: 1895.3391 - val_mae: 1895.3391 - lr: 0.0010\n",
      "Epoch 12/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 194.8048 - mae: 194.8048 - val_loss: 1886.7029 - val_mae: 1886.7029 - lr: 0.0010\n",
      "Epoch 13/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 193.3893 - mae: 193.3893 - val_loss: 1878.7612 - val_mae: 1878.7612 - lr: 0.0010\n",
      "Epoch 14/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 194.8168 - mae: 194.8168 - val_loss: 1920.7053 - val_mae: 1920.7053 - lr: 0.0010\n",
      "Epoch 15/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 135.3671 - mae: 135.3671INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 102ms/step - loss: 185.3577 - mae: 185.3577 - val_loss: 1859.5608 - val_mae: 1859.5608 - lr: 0.0010\n",
      "Epoch 16/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 149.0521 - mae: 149.0521INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 194.2958 - mae: 194.2958 - val_loss: 1851.7914 - val_mae: 1851.7914 - lr: 0.0010\n",
      "Epoch 17/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 220.1397 - mae: 220.1397 - val_loss: 1906.7419 - val_mae: 1906.7419 - lr: 0.0010\n",
      "Epoch 18/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 224.6563 - mae: 224.6563 - val_loss: 1946.7333 - val_mae: 1946.7333 - lr: 0.0010\n",
      "Epoch 19/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 213.0200 - mae: 213.0200 - val_loss: 1905.6996 - val_mae: 1905.6996 - lr: 0.0010\n",
      "Epoch 20/100\n",
      "22/22 [==============================] - ETA: 0s - loss: 128.8770 - mae: 128.877 - 0s 4ms/step - loss: 207.4529 - mae: 207.4529 - val_loss: 1870.6614 - val_mae: 1870.6614 - lr: 0.0010\n",
      "Epoch 21/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 210.7137 - mae: 210.7137 - val_loss: 1888.3456 - val_mae: 1888.3456 - lr: 0.0010\n",
      "Epoch 22/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 203.4006 - mae: 203.4006 - val_loss: 1860.6123 - val_mae: 1860.6123 - lr: 0.0010\n",
      "Epoch 23/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 202.4554 - mae: 202.4554 - val_loss: 1852.3193 - val_mae: 1852.3193 - lr: 0.0010\n",
      "Epoch 24/100\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 125.9170 - mae: 125.9170INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 201.8908 - mae: 201.8908 - val_loss: 1847.9619 - val_mae: 1847.9619 - lr: 0.0010\n",
      "Epoch 25/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 206.0037 - mae: 206.0037 - val_loss: 1885.3771 - val_mae: 1885.3771 - lr: 0.0010\n",
      "Epoch 26/100\n",
      "13/22 [================>.............] - ETA: 0s - loss: 44.8001 - mae: 44.8001INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 103ms/step - loss: 191.6487 - mae: 191.6487 - val_loss: 1806.3284 - val_mae: 1806.3284 - lr: 0.0010\n",
      "Epoch 27/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 197.1724 - mae: 197.1724 - val_loss: 1825.3987 - val_mae: 1825.3987 - lr: 0.0010\n",
      "Epoch 28/100\n",
      "22/22 [==============================] - 0s 6ms/step - loss: 197.4134 - mae: 197.4134 - val_loss: 1826.8428 - val_mae: 1826.8428 - lr: 0.0010\n",
      "Epoch 29/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 194.5055 - mae: 194.5055 - val_loss: 1807.3009 - val_mae: 1807.3009 - lr: 0.0010\n",
      "Epoch 30/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 195.2782 - mae: 195.2782 - val_loss: 1808.6195 - val_mae: 1808.6195 - lr: 0.0010\n",
      "Epoch 31/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 140.2517 - mae: 140.2517INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 193.2525 - mae: 193.2525 - val_loss: 1795.6553 - val_mae: 1795.6553 - lr: 0.0010\n",
      "Epoch 32/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 141.0748 - mae: 141.0748INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 82ms/step - loss: 194.1757 - mae: 194.1757 - val_loss: 1789.1862 - val_mae: 1789.1862 - lr: 0.0010\n",
      "Epoch 33/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 149.6974 - mae: 149.6974INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 192.1553 - mae: 192.1553 - val_loss: 1782.3474 - val_mae: 1782.3474 - lr: 0.0010\n",
      "Epoch 34/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 195.1505 - mae: 195.1505 - val_loss: 1807.5327 - val_mae: 1807.5327 - lr: 0.0010\n",
      "Epoch 35/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 136.3641 - mae: 136.3641INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 188.3115 - mae: 188.3115 - val_loss: 1762.2439 - val_mae: 1762.2439 - lr: 0.0010\n",
      "Epoch 36/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 195.2372 - mae: 195.2372 - val_loss: 1787.6533 - val_mae: 1787.6533 - lr: 0.0010\n",
      "Epoch 37/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 191.3193 - mae: 191.3193 - val_loss: 1777.4912 - val_mae: 1777.4912 - lr: 0.0010\n",
      "Epoch 38/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/22 [================>.............] - ETA: 0s - loss: 44.0195 - mae: 44.0195INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 187.4155 - mae: 187.4155 - val_loss: 1748.5538 - val_mae: 1748.5538 - lr: 0.0010\n",
      "Epoch 39/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 192.9255 - mae: 192.9255 - val_loss: 1771.6371 - val_mae: 1771.6371 - lr: 0.0010\n",
      "Epoch 40/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 188.7597 - mae: 188.7597 - val_loss: 1756.5579 - val_mae: 1756.5579 - lr: 0.0010\n",
      "Epoch 41/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 135.0946 - mae: 135.0946INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 186.2644 - mae: 186.2644 - val_loss: 1733.3844 - val_mae: 1733.3844 - lr: 0.0010\n",
      "Epoch 42/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 190.3028 - mae: 190.3028 - val_loss: 1750.6620 - val_mae: 1750.6620 - lr: 0.0010\n",
      "Epoch 43/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 135.0279 - mae: 135.0279INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 186.2428 - mae: 186.2428 - val_loss: 1730.7358 - val_mae: 1730.7358 - lr: 0.0010\n",
      "Epoch 44/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 186.9867 - mae: 186.9867 - val_loss: 1730.9044 - val_mae: 1730.9044 - lr: 0.0010\n",
      "Epoch 45/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 134.7237 - mae: 134.7237INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 185.8129 - mae: 185.8129 - val_loss: 1723.5508 - val_mae: 1723.5508 - lr: 0.0010\n",
      "Epoch 46/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 144.4686 - mae: 144.4686INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 86ms/step - loss: 185.2770 - mae: 185.2770 - val_loss: 1716.9963 - val_mae: 1716.9963 - lr: 0.0010\n",
      "Epoch 47/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 134.3855 - mae: 134.3855INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 185.1223 - mae: 185.1223 - val_loss: 1707.8252 - val_mae: 1707.8252 - lr: 0.0010\n",
      "Epoch 48/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 186.4876 - mae: 186.4876 - val_loss: 1711.0007 - val_mae: 1711.0007 - lr: 0.0010\n",
      "Epoch 49/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 144.5554 - mae: 144.5554INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 185.4559 - mae: 185.4559 - val_loss: 1703.1996 - val_mae: 1703.1996 - lr: 0.0010\n",
      "Epoch 50/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 145.3133 - mae: 145.3133INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 186.2704 - mae: 186.2704 - val_loss: 1700.2561 - val_mae: 1700.2561 - lr: 0.0010\n",
      "Epoch 51/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 186.8460 - mae: 186.8460 - val_loss: 1702.7993 - val_mae: 1702.7993 - lr: 0.0010\n",
      "Epoch 52/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 143.9805 - mae: 143.9805INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 184.9044 - mae: 184.9044 - val_loss: 1692.1177 - val_mae: 1692.1177 - lr: 0.0010\n",
      "Epoch 53/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 185.6000 - mae: 185.6000 - val_loss: 1694.2532 - val_mae: 1694.2532 - lr: 0.0010\n",
      "Epoch 54/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 143.0194 - mae: 143.0194INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 94ms/step - loss: 183.6581 - mae: 183.6581 - val_loss: 1686.3895 - val_mae: 1686.3895 - lr: 0.0010\n",
      "Epoch 55/100\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 113.3057 - mae: 113.3057INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 89ms/step - loss: 183.0884 - mae: 183.0884 - val_loss: 1680.9869 - val_mae: 1680.9869 - lr: 0.0010\n",
      "Epoch 56/100\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 113.0241 - mae: 113.0241INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 182.4720 - mae: 182.4720 - val_loss: 1671.9379 - val_mae: 1671.9379 - lr: 0.0010\n",
      "Epoch 57/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 132.9363 - mae: 132.9363INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 183.4871 - mae: 183.4871 - val_loss: 1670.0162 - val_mae: 1670.0162 - lr: 0.0010\n",
      "Epoch 58/100\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 113.9161 - mae: 113.9161INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 183.9207 - mae: 183.9207 - val_loss: 1669.1929 - val_mae: 1669.1929 - lr: 0.0010\n",
      "Epoch 59/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 131.7521 - mae: 131.7521INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 181.8565 - mae: 181.8565 - val_loss: 1659.0757 - val_mae: 1659.0757 - lr: 0.0010\n",
      "Epoch 60/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 183.1821 - mae: 183.1821 - val_loss: 1662.4222 - val_mae: 1662.4222 - lr: 0.0010\n",
      "Epoch 61/100\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 112.0840 - mae: 112.0840INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 96ms/step - loss: 181.2624 - mae: 181.2624 - val_loss: 1653.6901 - val_mae: 1653.6901 - lr: 0.0010\n",
      "Epoch 62/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 141.2983 - mae: 141.2983INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 90ms/step - loss: 181.3359 - mae: 181.3359 - val_loss: 1650.1737 - val_mae: 1650.1737 - lr: 0.0010\n",
      "Epoch 63/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 181.3120 - mae: 181.3120 - val_loss: 1650.5948 - val_mae: 1650.5948 - lr: 0.0010\n",
      "Epoch 64/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 129.8622 - mae: 129.8622INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 179.5011 - mae: 179.5011 - val_loss: 1640.5618 - val_mae: 1640.5618 - lr: 0.0010\n",
      "Epoch 65/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 180.4893 - mae: 180.4893 - val_loss: 1642.8219 - val_mae: 1642.8219 - lr: 0.0010\n",
      "Epoch 66/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 138.6103 - mae: 138.6103INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 178.3144 - mae: 178.3144 - val_loss: 1631.6178 - val_mae: 1631.6178 - lr: 0.0010\n",
      "Epoch 67/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 179.5823 - mae: 179.5823 - val_loss: 1636.1842 - val_mae: 1636.1842 - lr: 0.0010\n",
      "Epoch 68/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 137.7783 - mae: 137.7783INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 177.2697 - mae: 177.2697 - val_loss: 1619.7711 - val_mae: 1619.7711 - lr: 0.0010\n",
      "Epoch 69/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 140.3804 - mae: 140.3804INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 179.3445 - mae: 179.3445 - val_loss: 1619.6010 - val_mae: 1619.6010 - lr: 0.0010\n",
      "Epoch 70/100\n",
      "14/22 [==================>...........] - ETA: 0s - loss: 110.4236 - mae: 110.4236INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 85ms/step - loss: 178.5062 - mae: 178.5062 - val_loss: 1617.4059 - val_mae: 1617.4059 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 71/100\n",
      "17/22 [======================>.......] - ETA: 0s - loss: 137.3033 - mae: 137.3033INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 95ms/step - loss: 177.6240 - mae: 177.6240 - val_loss: 1611.3625 - val_mae: 1611.3625 - lr: 0.0010\n",
      "Epoch 72/100\n",
      "17/22 [======================>.......] - ETA: 0s - loss: 136.9795 - mae: 136.9795INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 177.2531 - mae: 177.2531 - val_loss: 1601.9965 - val_mae: 1601.9965 - lr: 0.0010\n",
      "Epoch 73/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 178.9440 - mae: 178.9440 - val_loss: 1611.8440 - val_mae: 1611.8440 - lr: 0.0010\n",
      "Epoch 74/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 127.4535 - mae: 127.4535INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 92ms/step - loss: 175.7583 - mae: 175.7583 - val_loss: 1599.3583 - val_mae: 1599.3583 - lr: 0.0010\n",
      "Epoch 75/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 137.4796 - mae: 137.4796INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 176.2091 - mae: 176.2091 - val_loss: 1588.3313 - val_mae: 1588.3313 - lr: 0.0010\n",
      "Epoch 76/100\n",
      "22/22 [==============================] - 0s 5ms/step - loss: 178.8773 - mae: 178.8773 - val_loss: 1590.8596 - val_mae: 1590.8596 - lr: 0.0010\n",
      "Epoch 77/100\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 168.2829 - mae: 168.2829INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 107ms/step - loss: 177.2172 - mae: 177.2172 - val_loss: 1583.9303 - val_mae: 1583.9303 - lr: 0.0010\n",
      "Epoch 78/100\n",
      "13/22 [================>.............] - ETA: 0s - loss: 42.2705 - mae: 42.2705INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 97ms/step - loss: 177.1276 - mae: 177.1276 - val_loss: 1578.8311 - val_mae: 1578.8311 - lr: 0.0010\n",
      "Epoch 79/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 177.7595 - mae: 177.7595 - val_loss: 1583.7991 - val_mae: 1583.7991 - lr: 0.0010\n",
      "Epoch 80/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 137.5063 - mae: 137.5063INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 88ms/step - loss: 175.5135 - mae: 175.5135 - val_loss: 1573.3524 - val_mae: 1573.3524 - lr: 0.0010\n",
      "Epoch 81/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 176.7683 - mae: 176.7683 - val_loss: 1579.8761 - val_mae: 1579.8761 - lr: 0.0010\n",
      "Epoch 82/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 135.6104 - mae: 135.6104INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 99ms/step - loss: 173.6761 - mae: 173.6761 - val_loss: 1561.4434 - val_mae: 1561.4434 - lr: 0.0010\n",
      "Epoch 83/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 177.4505 - mae: 177.4505 - val_loss: 1578.7643 - val_mae: 1578.7643 - lr: 0.0010\n",
      "Epoch 84/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 134.0666 - mae: 134.0666INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 172.1092 - mae: 172.1092 - val_loss: 1552.1178 - val_mae: 1552.1178 - lr: 0.0010\n",
      "Epoch 85/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 177.1006 - mae: 177.1006 - val_loss: 1569.9761 - val_mae: 1569.9761 - lr: 0.0010\n",
      "Epoch 86/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 133.5860 - mae: 133.5860INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 171.3640 - mae: 171.3640 - val_loss: 1544.5919 - val_mae: 1544.5919 - lr: 0.0010\n",
      "Epoch 87/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 176.4298 - mae: 176.4298 - val_loss: 1566.0116 - val_mae: 1566.0116 - lr: 0.0010\n",
      "Epoch 88/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 132.6775 - mae: 132.6775INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 170.3923 - mae: 170.3923 - val_loss: 1536.0533 - val_mae: 1536.0532 - lr: 0.0010\n",
      "Epoch 89/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 176.5587 - mae: 176.5587 - val_loss: 1561.6603 - val_mae: 1561.6603 - lr: 0.0010\n",
      "Epoch 90/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 131.5970 - mae: 131.5970INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 93ms/step - loss: 168.9021 - mae: 168.9021 - val_loss: 1533.3197 - val_mae: 1533.3197 - lr: 0.0010\n",
      "Epoch 91/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 173.0891 - mae: 173.0891 - val_loss: 1541.4749 - val_mae: 1541.4749 - lr: 0.0010\n",
      "Epoch 92/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 171.9995 - mae: 171.9995 - val_loss: 1533.3756 - val_mae: 1533.3756 - lr: 0.0010\n",
      "Epoch 93/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 172.9117 - mae: 172.9117 - val_loss: 1542.2242 - val_mae: 1542.2242 - lr: 0.0010\n",
      "Epoch 94/100\n",
      "15/22 [===================>..........] - ETA: 0s - loss: 123.3883 - mae: 123.3883INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 169.6025 - mae: 169.6025 - val_loss: 1531.3250 - val_mae: 1531.3250 - lr: 0.0010\n",
      "Epoch 95/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 132.5994 - mae: 132.5994INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 98ms/step - loss: 169.7157 - mae: 169.7157 - val_loss: 1523.2744 - val_mae: 1523.2744 - lr: 0.0010\n",
      "Epoch 96/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 171.6374 - mae: 171.6374 - val_loss: 1529.2255 - val_mae: 1529.2255 - lr: 0.0010\n",
      "Epoch 97/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 132.5392 - mae: 132.5392INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 87ms/step - loss: 169.5537 - mae: 169.5537 - val_loss: 1521.4894 - val_mae: 1521.4894 - lr: 0.0010\n",
      "Epoch 98/100\n",
      "12/22 [===============>..............] - ETA: 0s - loss: 24.7674 - mae: 24.7674INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 91ms/step - loss: 169.7673 - mae: 169.7673 - val_loss: 1520.3109 - val_mae: 1520.3109 - lr: 0.0010\n",
      "Epoch 99/100\n",
      "22/22 [==============================] - 0s 4ms/step - loss: 169.1618 - mae: 169.1618 - val_loss: 1520.5000 - val_mae: 1520.5000 - lr: 0.0010\n",
      "Epoch 100/100\n",
      "16/22 [====================>.........] - ETA: 0s - loss: 131.3586 - mae: 131.3586INFO:tensorflow:Assets written to: modelos/RNN_simple/assets\n",
      "22/22 [==============================] - 2s 83ms/step - loss: 168.1287 - mae: 168.1287 - val_loss: 1514.5292 - val_mae: 1514.5292 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f71a5789250>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = tf.keras.Sequential([\n",
    "    layers.Lambda(lambda x: tf.expand_dims(x, axis=1)),\n",
    "    layers.LSTM(128, activation=\"relu\", return_sequences=True),\n",
    "    layers.LSTM(16, activation=\"relu\"),\n",
    "    layers.Dense(1, activation=\"linear\")\n",
    "], name=\"RNN_simple\")\n",
    "\n",
    "model_3.compile(loss=\"mae\",\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=[\"mae\"])\n",
    "\n",
    "model_3.fit(train_dataset_price,\n",
    "                 epochs=100,\n",
    "                 validation_data=test_dataset_price,\n",
    "                 verbose=1,\n",
    "                 callbacks=[model_checkpoint(model_3.name),\n",
    "                           tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1514.5292 - mean_absolute_error: 1514.5292\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1514.5291748046875, 1514.5291748046875]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3_best = tf.keras.models.load_model(os.path.join('modelos', 'RNN_simple'))\n",
    "model_3_best.evaluate(test_dataset_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model_1_best.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predicted = pred[-100:]\n",
    "original = np.array(y)[-100:]\n",
    "plt.title('Histórico vs predicción')\n",
    "plt.plot(original, label = 'Datos originales')\n",
    "plt.plot(predicted, label = 'Datos predichos')\n",
    "plt.xlabel('Días')\n",
    "plt.ylabel('Precio Bitcoin')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### N BEATS ###########\n",
    "input_size=7\n",
    "theta_size=8\n",
    "horizon=1\n",
    "n_neurons=512\n",
    "n_layers=4\n",
    "stacks_len = 30\n",
    "\n",
    "nbeats_input = layers.Input(shape=(input_size), name=\"input\")\n",
    "residuals = nbeats_input\n",
    "\n",
    "for i in range(stacks_len):\n",
    "    x = residuals\n",
    "    for j in range(n_layers):\n",
    "        x = layers.Dense(n_neurons, activation=\"relu\", name=f\"{j}_dense_{i}th_stack\")(x)\n",
    "    theta = layers.Dense(theta_size, activation=\"linear\")(x)\n",
    "    \n",
    "    backcast, block_forecast = theta[:, :input_size], theta[:, horizon:]\n",
    "    residuals = layers.subtract([residuals, backcast])\n",
    "    if not i:\n",
    "        forecast = block_forecast\n",
    "    else:\n",
    "        forecast = layers.add([forecast, block_forecast])\n",
    "        \n",
    "model_4 = tf.keras.Model(inputs=nbeats_input, \n",
    "                         outputs=forecast, \n",
    "                         name=\"n-beats\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 562.6800 - mae: 562.6800INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 587ms/step - loss: 562.6800 - mae: 562.6800 - val_loss: 2406.6343 - val_mae: 2406.6343 - lr: 0.0010\n",
      "Epoch 2/2000\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 261.5963 - mae: 261.5963INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 573ms/step - loss: 267.8357 - mae: 267.8357 - val_loss: 2325.0994 - val_mae: 2325.0994 - lr: 0.0010\n",
      "Epoch 3/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 250.5253 - mae: 250.5253 - val_loss: 2488.5815 - val_mae: 2488.5815 - lr: 0.0010\n",
      "Epoch 4/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 263.1481 - mae: 263.1481 - val_loss: 2385.8765 - val_mae: 2385.8765 - lr: 0.0010\n",
      "Epoch 5/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 229.0937 - mae: 229.0937 - val_loss: 2339.9360 - val_mae: 2339.9360 - lr: 0.0010\n",
      "Epoch 6/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 232.6497 - mae: 232.6497 - val_loss: 2537.1228 - val_mae: 2537.1228 - lr: 0.0010\n",
      "Epoch 7/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 245.7188 - mae: 245.7188INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 597ms/step - loss: 245.7188 - mae: 245.7188 - val_loss: 2279.2065 - val_mae: 2279.2065 - lr: 0.0010\n",
      "Epoch 8/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 246.3100 - mae: 246.3100 - val_loss: 2331.9915 - val_mae: 2331.9915 - lr: 0.0010\n",
      "Epoch 9/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 254.5652 - mae: 254.5652 - val_loss: 2378.8599 - val_mae: 2378.8599 - lr: 0.0010\n",
      "Epoch 10/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 238.2083 - mae: 238.2083INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 603ms/step - loss: 238.2083 - mae: 238.2083 - val_loss: 2262.8591 - val_mae: 2262.8591 - lr: 0.0010\n",
      "Epoch 11/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 247.8701 - mae: 247.8701 - val_loss: 2311.1113 - val_mae: 2311.1113 - lr: 0.0010\n",
      "Epoch 12/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 224.1496 - mae: 224.1496 - val_loss: 2302.0310 - val_mae: 2302.0310 - lr: 0.0010\n",
      "Epoch 13/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 237.8867 - mae: 237.8867 - val_loss: 2281.6860 - val_mae: 2281.6860 - lr: 0.0010\n",
      "Epoch 14/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 227.7670 - mae: 227.7670 - val_loss: 2312.0222 - val_mae: 2312.0222 - lr: 0.0010\n",
      "Epoch 15/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 234.3340 - mae: 234.3340 - val_loss: 2535.2505 - val_mae: 2535.2505 - lr: 0.0010\n",
      "Epoch 16/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 262.6130 - mae: 262.6130 - val_loss: 2783.8127 - val_mae: 2783.8127 - lr: 0.0010\n",
      "Epoch 17/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 275.7974 - mae: 275.7974 - val_loss: 2426.4067 - val_mae: 2426.4067 - lr: 0.0010\n",
      "Epoch 18/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 243.3708 - mae: 243.3708 - val_loss: 2837.8228 - val_mae: 2837.8228 - lr: 0.0010\n",
      "Epoch 19/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 255.4469 - mae: 255.4469 - val_loss: 2549.2639 - val_mae: 2549.2639 - lr: 0.0010\n",
      "Epoch 20/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 259.5079 - mae: 259.5079 - val_loss: 2374.7969 - val_mae: 2374.7969 - lr: 0.0010\n",
      "Epoch 21/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 388.3405 - mae: 388.3405 - val_loss: 5351.7476 - val_mae: 5351.7476 - lr: 0.0010\n",
      "Epoch 22/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 386.8354 - mae: 386.8354 - val_loss: 3264.2214 - val_mae: 3264.2214 - lr: 0.0010\n",
      "Epoch 23/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 290.7896 - mae: 290.7896 - val_loss: 2967.8054 - val_mae: 2967.8054 - lr: 0.0010\n",
      "Epoch 24/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 294.6663 - mae: 294.6663 - val_loss: 2596.4707 - val_mae: 2596.4707 - lr: 0.0010\n",
      "Epoch 25/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 338.8804 - mae: 338.8804 - val_loss: 2621.0256 - val_mae: 2621.0256 - lr: 0.0010\n",
      "Epoch 26/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 422.3355 - mae: 422.3355 - val_loss: 6991.2598 - val_mae: 6991.2598 - lr: 0.0010\n",
      "Epoch 27/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 1239.9369 - mae: 1239.9369 - val_loss: 7797.0986 - val_mae: 7797.0986 - lr: 0.0010\n",
      "Epoch 28/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 2689.7668 - mae: 2689.7668 - val_loss: 50653.3164 - val_mae: 50653.3164 - lr: 0.0010\n",
      "Epoch 29/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 650.2993 - mae: 650.2993 - val_loss: 3422.9751 - val_mae: 3422.9751 - lr: 0.0010\n",
      "Epoch 30/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 379.4448 - mae: 379.4448 - val_loss: 3396.5256 - val_mae: 3396.5256 - lr: 0.0010\n",
      "Epoch 31/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 444.7271 - mae: 444.7271 - val_loss: 3416.1001 - val_mae: 3416.1001 - lr: 0.0010\n",
      "Epoch 32/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 331.7737 - mae: 331.7737 - val_loss: 4053.6143 - val_mae: 4053.6143 - lr: 0.0010\n",
      "Epoch 33/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 329.9025 - mae: 329.9025 - val_loss: 2455.6357 - val_mae: 2455.6357 - lr: 0.0010\n",
      "Epoch 34/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 233.1250 - mae: 233.1250 - val_loss: 2290.9062 - val_mae: 2290.9062 - lr: 0.0010\n",
      "Epoch 35/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 228.9513 - mae: 228.9513 - val_loss: 2339.5325 - val_mae: 2339.5325 - lr: 0.0010\n",
      "Epoch 36/2000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 242.8359 - mae: 242.8359INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 598ms/step - loss: 243.3921 - mae: 243.3921 - val_loss: 2218.1345 - val_mae: 2218.1345 - lr: 0.0010\n",
      "Epoch 37/2000\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 206.4951 - mae: 206.4951INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 616ms/step - loss: 213.0412 - mae: 213.0412 - val_loss: 2078.4131 - val_mae: 2078.4131 - lr: 0.0010\n",
      "Epoch 38/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 202.8514 - mae: 202.8514 - val_loss: 2135.4341 - val_mae: 2135.4341 - lr: 0.0010\n",
      "Epoch 39/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 221.5692 - mae: 221.5692 - val_loss: 2379.4893 - val_mae: 2379.4893 - lr: 0.0010\n",
      "Epoch 40/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 255.8883 - mae: 255.8883 - val_loss: 2437.2483 - val_mae: 2437.2483 - lr: 0.0010\n",
      "Epoch 41/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 229.1268 - mae: 229.1268INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 604ms/step - loss: 229.1268 - mae: 229.1268 - val_loss: 2021.9509 - val_mae: 2021.9509 - lr: 0.0010\n",
      "Epoch 42/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 190.6740 - mae: 190.6740INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 658ms/step - loss: 190.6740 - mae: 190.6740 - val_loss: 1868.6759 - val_mae: 1868.6759 - lr: 0.0010\n",
      "Epoch 43/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 199.9386 - mae: 199.9386 - val_loss: 2138.8962 - val_mae: 2138.8962 - lr: 0.0010\n",
      "Epoch 44/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 223.7399 - mae: 223.7399 - val_loss: 2232.2385 - val_mae: 2232.2385 - lr: 0.0010\n",
      "Epoch 45/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 205.3485 - mae: 205.3485 - val_loss: 1904.5276 - val_mae: 1904.5276 - lr: 0.0010\n",
      "Epoch 46/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 24ms/step - loss: 191.9422 - mae: 191.9422 - val_loss: 1910.0364 - val_mae: 1910.0364 - lr: 0.0010\n",
      "Epoch 47/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 186.2075 - mae: 186.2075INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 38s 2s/step - loss: 186.2075 - mae: 186.2075 - val_loss: 1510.9102 - val_mae: 1510.9102 - lr: 0.0010\n",
      "Epoch 48/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 177.1950 - mae: 177.1950 - val_loss: 1728.8518 - val_mae: 1728.8518 - lr: 0.0010\n",
      "Epoch 49/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 204.1718 - mae: 204.1718 - val_loss: 1992.1888 - val_mae: 1992.1888 - lr: 0.0010\n",
      "Epoch 50/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 196.2313 - mae: 196.2313 - val_loss: 1807.8434 - val_mae: 1807.8434 - lr: 0.0010\n",
      "Epoch 51/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 163.2853 - mae: 163.2853 - val_loss: 1592.4283 - val_mae: 1592.4283 - lr: 0.0010\n",
      "Epoch 52/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 165.8251 - mae: 165.8251 - val_loss: 1563.3833 - val_mae: 1563.3833 - lr: 0.0010\n",
      "Epoch 53/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 157.1087 - mae: 157.1087 - val_loss: 1591.0073 - val_mae: 1591.0073 - lr: 0.0010\n",
      "Epoch 54/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 158.5811 - mae: 158.5811 - val_loss: 1740.0306 - val_mae: 1740.0306 - lr: 0.0010\n",
      "Epoch 55/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 203.9262 - mae: 203.9262 - val_loss: 1727.1133 - val_mae: 1727.1133 - lr: 0.0010\n",
      "Epoch 56/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 173.3940 - mae: 173.3940 - val_loss: 1801.9702 - val_mae: 1801.9702 - lr: 0.0010\n",
      "Epoch 57/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 221.1424 - mae: 221.1424 - val_loss: 2078.7756 - val_mae: 2078.7756 - lr: 0.0010\n",
      "Epoch 58/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 224.1882 - mae: 224.1882 - val_loss: 2238.0471 - val_mae: 2238.0471 - lr: 0.0010\n",
      "Epoch 59/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 220.9196 - mae: 220.9196 - val_loss: 1860.5763 - val_mae: 1860.5763 - lr: 0.0010\n",
      "Epoch 60/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 158.7596 - mae: 158.7596 - val_loss: 1631.7064 - val_mae: 1631.7064 - lr: 0.0010\n",
      "Epoch 61/2000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 161.7793 - mae: 161.7793INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 631ms/step - loss: 162.0698 - mae: 162.0698 - val_loss: 1490.4352 - val_mae: 1490.4352 - lr: 0.0010\n",
      "Epoch 62/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 194.9738 - mae: 194.9738 - val_loss: 1620.5465 - val_mae: 1620.5465 - lr: 0.0010\n",
      "Epoch 63/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 186.4136 - mae: 186.4136 - val_loss: 1656.0367 - val_mae: 1656.0367 - lr: 0.0010\n",
      "Epoch 64/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 193.8606 - mae: 193.8606 - val_loss: 1922.6497 - val_mae: 1922.6497 - lr: 0.0010\n",
      "Epoch 65/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 224.0093 - mae: 224.0093 - val_loss: 2083.3083 - val_mae: 2083.3083 - lr: 0.0010\n",
      "Epoch 66/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 217.9289 - mae: 217.9289 - val_loss: 1962.1359 - val_mae: 1962.1359 - lr: 0.0010\n",
      "Epoch 67/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 248.1399 - mae: 248.1399 - val_loss: 2525.8330 - val_mae: 2525.8330 - lr: 0.0010\n",
      "Epoch 68/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 237.4803 - mae: 237.4803 - val_loss: 2287.7378 - val_mae: 2287.7378 - lr: 0.0010\n",
      "Epoch 69/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 212.4583 - mae: 212.4583 - val_loss: 1979.9261 - val_mae: 1979.9261 - lr: 0.0010\n",
      "Epoch 70/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 187.9415 - mae: 187.9415 - val_loss: 1973.3132 - val_mae: 1973.3132 - lr: 0.0010\n",
      "Epoch 71/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 187.7547 - mae: 187.7547 - val_loss: 1944.2048 - val_mae: 1944.2048 - lr: 0.0010\n",
      "Epoch 72/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 185.8160 - mae: 185.8160 - val_loss: 1548.2307 - val_mae: 1548.2307 - lr: 0.0010\n",
      "Epoch 73/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 182.8761 - mae: 182.8761 - val_loss: 1963.2535 - val_mae: 1963.2535 - lr: 0.0010\n",
      "Epoch 74/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 179.8820 - mae: 179.8820 - val_loss: 1701.8674 - val_mae: 1701.8674 - lr: 0.0010\n",
      "Epoch 75/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 158.1929 - mae: 158.1929 - val_loss: 1591.5701 - val_mae: 1591.5701 - lr: 0.0010\n",
      "Epoch 76/2000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 160.6306 - mae: 160.6306INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 600ms/step - loss: 161.0130 - mae: 161.0130 - val_loss: 1439.1367 - val_mae: 1439.1367 - lr: 0.0010\n",
      "Epoch 77/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 152.4872 - mae: 152.4872 - val_loss: 1521.2976 - val_mae: 1521.2976 - lr: 0.0010\n",
      "Epoch 78/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 161.3142 - mae: 161.3142 - val_loss: 1521.7909 - val_mae: 1521.7909 - lr: 0.0010\n",
      "Epoch 79/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 155.5727 - mae: 155.5727 - val_loss: 1656.7675 - val_mae: 1656.7675 - lr: 0.0010\n",
      "Epoch 80/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 187.2740 - mae: 187.2740 - val_loss: 1712.4189 - val_mae: 1712.4189 - lr: 0.0010\n",
      "Epoch 81/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 179.0358 - mae: 179.0358 - val_loss: 1489.3257 - val_mae: 1489.3257 - lr: 0.0010\n",
      "Epoch 82/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 167.3466 - mae: 167.3466 - val_loss: 1618.0195 - val_mae: 1618.0195 - lr: 0.0010\n",
      "Epoch 83/2000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 149.4308 - mae: 149.4308INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 627ms/step - loss: 149.9040 - mae: 149.9040 - val_loss: 1418.9323 - val_mae: 1418.9323 - lr: 0.0010\n",
      "Epoch 84/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 155.6139 - mae: 155.6139 - val_loss: 1561.9276 - val_mae: 1561.9276 - lr: 0.0010\n",
      "Epoch 85/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 171.5116 - mae: 171.5116 - val_loss: 1503.9377 - val_mae: 1503.9377 - lr: 0.0010\n",
      "Epoch 86/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 172.3238 - mae: 172.3238 - val_loss: 1517.5607 - val_mae: 1517.5607 - lr: 0.0010\n",
      "Epoch 87/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 151.4285 - mae: 151.4285 - val_loss: 1455.1570 - val_mae: 1455.1570 - lr: 0.0010\n",
      "Epoch 88/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 149.1869 - mae: 149.1869 - val_loss: 1477.7305 - val_mae: 1477.7305 - lr: 0.0010\n",
      "Epoch 89/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 165.3750 - mae: 165.3750 - val_loss: 1457.2834 - val_mae: 1457.2834 - lr: 0.0010\n",
      "Epoch 90/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 164.8235 - mae: 164.8235 - val_loss: 1470.8645 - val_mae: 1470.8645 - lr: 0.0010\n",
      "Epoch 91/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 163.9088 - mae: 163.9088 - val_loss: 1440.6407 - val_mae: 1440.6407 - lr: 0.0010\n",
      "Epoch 92/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 179.0243 - mae: 179.0243 - val_loss: 1805.8550 - val_mae: 1805.8550 - lr: 0.0010\n",
      "Epoch 93/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 162.5650 - mae: 162.5650 - val_loss: 1510.4910 - val_mae: 1510.4910 - lr: 0.0010\n",
      "Epoch 94/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 161.5720 - mae: 161.5720 - val_loss: 1471.0244 - val_mae: 1471.0244 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 168.9429 - mae: 168.9429 - val_loss: 1479.2043 - val_mae: 1479.2043 - lr: 0.0010\n",
      "Epoch 96/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 165.2014 - mae: 165.2014 - val_loss: 1490.4143 - val_mae: 1490.4143 - lr: 0.0010\n",
      "Epoch 97/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 172.7865 - mae: 172.7865 - val_loss: 1429.1664 - val_mae: 1429.1664 - lr: 0.0010\n",
      "Epoch 98/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 160.5760 - mae: 160.5760 - val_loss: 1533.6521 - val_mae: 1533.6521 - lr: 0.0010\n",
      "Epoch 99/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 173.4466 - mae: 173.4466 - val_loss: 1513.9463 - val_mae: 1513.9463 - lr: 0.0010\n",
      "Epoch 100/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 165.2608 - mae: 165.2608 - val_loss: 1665.0186 - val_mae: 1665.0186 - lr: 0.0010\n",
      "Epoch 101/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 162.4464 - mae: 162.4464 - val_loss: 1499.3727 - val_mae: 1499.3727 - lr: 0.0010\n",
      "Epoch 102/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 166.8477 - mae: 166.8477 - val_loss: 1565.6912 - val_mae: 1565.6912 - lr: 0.0010\n",
      "Epoch 103/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 183.5413 - mae: 183.5413 - val_loss: 1501.1847 - val_mae: 1501.1847 - lr: 0.0010\n",
      "Epoch 104/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 165.7333 - mae: 165.7333 - val_loss: 1423.5363 - val_mae: 1423.5363 - lr: 0.0010\n",
      "Epoch 105/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 154.6912 - mae: 154.6912INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 613ms/step - loss: 154.6912 - mae: 154.6912 - val_loss: 1416.0437 - val_mae: 1416.0437 - lr: 0.0010\n",
      "Epoch 106/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 152.4247 - mae: 152.4247 - val_loss: 1428.4022 - val_mae: 1428.4022 - lr: 0.0010\n",
      "Epoch 107/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 156.5261 - mae: 156.5261 - val_loss: 1765.7126 - val_mae: 1765.7126 - lr: 0.0010\n",
      "Epoch 108/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 206.6569 - mae: 206.6569 - val_loss: 1848.7886 - val_mae: 1848.7886 - lr: 0.0010\n",
      "Epoch 109/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 211.2828 - mae: 211.2828 - val_loss: 2111.7083 - val_mae: 2111.7083 - lr: 0.0010\n",
      "Epoch 110/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 202.4490 - mae: 202.4490 - val_loss: 1586.9589 - val_mae: 1586.9589 - lr: 0.0010\n",
      "Epoch 111/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 153.4966 - mae: 153.4966 - val_loss: 1612.5200 - val_mae: 1612.5200 - lr: 0.0010\n",
      "Epoch 112/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 166.2302 - mae: 166.2302 - val_loss: 1514.7394 - val_mae: 1514.7394 - lr: 0.0010\n",
      "Epoch 113/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 179.5352 - mae: 179.5352 - val_loss: 1626.9825 - val_mae: 1626.9825 - lr: 0.0010\n",
      "Epoch 114/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 172.5425 - mae: 172.5425 - val_loss: 1672.3142 - val_mae: 1672.3142 - lr: 0.0010\n",
      "Epoch 115/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 166.9459 - mae: 166.9459 - val_loss: 1496.5776 - val_mae: 1496.5776 - lr: 0.0010\n",
      "Epoch 116/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 155.8650 - mae: 155.8650 - val_loss: 1493.1783 - val_mae: 1493.1783 - lr: 0.0010\n",
      "Epoch 117/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 171.5268 - mae: 171.5268 - val_loss: 1622.2543 - val_mae: 1622.2543 - lr: 0.0010\n",
      "Epoch 118/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 157.2232 - mae: 157.2232 - val_loss: 1420.5233 - val_mae: 1420.5233 - lr: 0.0010\n",
      "Epoch 119/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 148.1643 - mae: 148.1643 - val_loss: 1453.8511 - val_mae: 1453.8511 - lr: 0.0010\n",
      "Epoch 120/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 163.6650 - mae: 163.6650 - val_loss: 1526.7963 - val_mae: 1526.7963 - lr: 0.0010\n",
      "Epoch 121/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 166.7335 - mae: 166.7335 - val_loss: 1525.4446 - val_mae: 1525.4446 - lr: 0.0010\n",
      "Epoch 122/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 152.6133 - mae: 152.6133 - val_loss: 1492.8684 - val_mae: 1492.8684 - lr: 0.0010\n",
      "Epoch 123/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 169.4505 - mae: 169.4505 - val_loss: 1482.8555 - val_mae: 1482.8555 - lr: 0.0010\n",
      "Epoch 124/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 194.5056 - mae: 194.5056 - val_loss: 1815.8998 - val_mae: 1815.8998 - lr: 0.0010\n",
      "Epoch 125/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 148.0916 - mae: 148.0916 - val_loss: 1470.0593 - val_mae: 1470.0593 - lr: 0.0010\n",
      "Epoch 126/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 174.5200 - mae: 174.5200 - val_loss: 1457.6962 - val_mae: 1457.6962 - lr: 0.0010\n",
      "Epoch 127/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 168.5837 - mae: 168.5837 - val_loss: 1456.7202 - val_mae: 1456.7202 - lr: 0.0010\n",
      "Epoch 128/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 151.5376 - mae: 151.5376 - val_loss: 1431.7726 - val_mae: 1431.7726 - lr: 0.0010\n",
      "Epoch 129/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 147.9453 - mae: 147.9453INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 640ms/step - loss: 147.9453 - mae: 147.9453 - val_loss: 1403.8573 - val_mae: 1403.8573 - lr: 0.0010\n",
      "Epoch 130/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 152.4343 - mae: 152.4343 - val_loss: 1466.2928 - val_mae: 1466.2928 - lr: 0.0010\n",
      "Epoch 131/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 143.0861 - mae: 143.0861 - val_loss: 1413.0393 - val_mae: 1413.0393 - lr: 0.0010\n",
      "Epoch 132/2000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 142.9472 - mae: 142.9472INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 625ms/step - loss: 143.2388 - mae: 143.2388 - val_loss: 1377.3536 - val_mae: 1377.3536 - lr: 0.0010\n",
      "Epoch 133/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 150.8349 - mae: 150.8349 - val_loss: 1623.8978 - val_mae: 1623.8978 - lr: 0.0010\n",
      "Epoch 134/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 162.3295 - mae: 162.3295 - val_loss: 1464.3446 - val_mae: 1464.3446 - lr: 0.0010\n",
      "Epoch 135/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 173.0449 - mae: 173.0449INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 644ms/step - loss: 173.0449 - mae: 173.0449 - val_loss: 1370.3572 - val_mae: 1370.3572 - lr: 0.0010\n",
      "Epoch 136/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 153.8294 - mae: 153.8294 - val_loss: 1389.6444 - val_mae: 1389.6444 - lr: 0.0010\n",
      "Epoch 137/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 138.9133 - mae: 138.9133INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 599ms/step - loss: 138.9133 - mae: 138.9133 - val_loss: 1346.1638 - val_mae: 1346.1638 - lr: 0.0010\n",
      "Epoch 138/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 133.2636 - mae: 133.2636 - val_loss: 1378.8217 - val_mae: 1378.8217 - lr: 0.0010\n",
      "Epoch 139/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 146.6465 - mae: 146.6465 - val_loss: 1434.9619 - val_mae: 1434.9619 - lr: 0.0010\n",
      "Epoch 140/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 139.8650 - mae: 139.8650 - val_loss: 1384.6544 - val_mae: 1384.6544 - lr: 0.0010\n",
      "Epoch 141/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 128.6211 - mae: 128.6211INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 641ms/step - loss: 128.6211 - mae: 128.6211 - val_loss: 1335.0203 - val_mae: 1335.0203 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 142/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 127.5291 - mae: 127.5291INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 627ms/step - loss: 127.5291 - mae: 127.5291 - val_loss: 1332.5444 - val_mae: 1332.5444 - lr: 0.0010\n",
      "Epoch 143/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 131.5867 - mae: 131.5867INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 598ms/step - loss: 131.5867 - mae: 131.5867 - val_loss: 1300.9277 - val_mae: 1300.9277 - lr: 0.0010\n",
      "Epoch 144/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 135.3040 - mae: 135.3040 - val_loss: 1394.0898 - val_mae: 1394.0898 - lr: 0.0010\n",
      "Epoch 145/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 152.8751 - mae: 152.8751 - val_loss: 1377.6063 - val_mae: 1377.6063 - lr: 0.0010\n",
      "Epoch 146/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 143.3616 - mae: 143.3616 - val_loss: 1369.5472 - val_mae: 1369.5472 - lr: 0.0010\n",
      "Epoch 147/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 133.5368 - mae: 133.5368 - val_loss: 1330.1547 - val_mae: 1330.1547 - lr: 0.0010\n",
      "Epoch 148/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 136.9847 - mae: 136.9847 - val_loss: 1341.2366 - val_mae: 1341.2366 - lr: 0.0010\n",
      "Epoch 149/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 141.9364 - mae: 141.9364 - val_loss: 1346.2111 - val_mae: 1346.2111 - lr: 0.0010\n",
      "Epoch 150/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 155.6638 - mae: 155.6638 - val_loss: 1391.8773 - val_mae: 1391.8773 - lr: 0.0010\n",
      "Epoch 151/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 134.3004 - mae: 134.3004 - val_loss: 1326.3855 - val_mae: 1326.3855 - lr: 0.0010\n",
      "Epoch 152/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 135.4612 - mae: 135.4612 - val_loss: 1303.7775 - val_mae: 1303.7775 - lr: 0.0010\n",
      "Epoch 153/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 135.9887 - mae: 135.9887 - val_loss: 1336.4006 - val_mae: 1336.4006 - lr: 0.0010\n",
      "Epoch 154/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 133.1857 - mae: 133.1857 - val_loss: 1366.8362 - val_mae: 1366.8362 - lr: 0.0010\n",
      "Epoch 155/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.5361 - mae: 130.5361 - val_loss: 1314.7434 - val_mae: 1314.7435 - lr: 0.0010\n",
      "Epoch 156/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 141.4130 - mae: 141.4130 - val_loss: 1349.3994 - val_mae: 1349.3994 - lr: 0.0010\n",
      "Epoch 157/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 164.1416 - mae: 164.1416 - val_loss: 1556.4277 - val_mae: 1556.4277 - lr: 0.0010\n",
      "Epoch 158/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 163.4970 - mae: 163.4970 - val_loss: 1423.5214 - val_mae: 1423.5214 - lr: 0.0010\n",
      "Epoch 159/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 134.6634 - mae: 134.6634 - val_loss: 1357.4174 - val_mae: 1357.4174 - lr: 0.0010\n",
      "Epoch 160/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 132.0358 - mae: 132.0358 - val_loss: 1372.0474 - val_mae: 1372.0474 - lr: 0.0010\n",
      "Epoch 161/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.9187 - mae: 130.9187 - val_loss: 1343.3099 - val_mae: 1343.3099 - lr: 0.0010\n",
      "Epoch 162/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 129.1155 - mae: 129.1155 - val_loss: 1343.2456 - val_mae: 1343.2456 - lr: 0.0010\n",
      "Epoch 163/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 138.4059 - mae: 138.4059 - val_loss: 1308.1411 - val_mae: 1308.1411 - lr: 0.0010\n",
      "Epoch 164/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 177.4031 - mae: 177.4031 - val_loss: 1464.4983 - val_mae: 1464.4983 - lr: 0.0010\n",
      "Epoch 165/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 148.2038 - mae: 148.2038 - val_loss: 1335.7233 - val_mae: 1335.7233 - lr: 0.0010\n",
      "Epoch 166/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 138.4659 - mae: 138.4659 - val_loss: 1350.6560 - val_mae: 1350.6560 - lr: 0.0010\n",
      "Epoch 167/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 157.7491 - mae: 157.7491 - val_loss: 1493.0035 - val_mae: 1493.0035 - lr: 0.0010\n",
      "Epoch 168/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 150.6703 - mae: 150.6703 - val_loss: 1371.5189 - val_mae: 1371.5189 - lr: 0.0010\n",
      "Epoch 169/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 144.3400 - mae: 144.3400 - val_loss: 1403.7830 - val_mae: 1403.7830 - lr: 0.0010\n",
      "Epoch 170/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 150.7458 - mae: 150.7458 - val_loss: 1422.2147 - val_mae: 1422.2147 - lr: 0.0010\n",
      "Epoch 171/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 144.9416 - mae: 144.9416 - val_loss: 1390.4540 - val_mae: 1390.4540 - lr: 0.0010\n",
      "Epoch 172/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.0453 - mae: 130.0453 - val_loss: 1383.9290 - val_mae: 1383.9290 - lr: 0.0010\n",
      "Epoch 173/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 134.6464 - mae: 134.6464INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 632ms/step - loss: 134.6464 - mae: 134.6464 - val_loss: 1291.9935 - val_mae: 1291.9935 - lr: 0.0010\n",
      "Epoch 174/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 127.0930 - mae: 127.0930 - val_loss: 1306.6776 - val_mae: 1306.6776 - lr: 0.0010\n",
      "Epoch 175/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 132.2657 - mae: 132.2657 - val_loss: 1314.8181 - val_mae: 1314.8181 - lr: 0.0010\n",
      "Epoch 176/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 129.9643 - mae: 129.9643 - val_loss: 1320.4731 - val_mae: 1320.4731 - lr: 0.0010\n",
      "Epoch 177/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 145.5489 - mae: 145.5489 - val_loss: 1374.9750 - val_mae: 1374.9750 - lr: 0.0010\n",
      "Epoch 178/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 152.0763 - mae: 152.0763 - val_loss: 1370.7085 - val_mae: 1370.7085 - lr: 0.0010\n",
      "Epoch 179/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 142.1741 - mae: 142.1741 - val_loss: 1469.1849 - val_mae: 1469.1849 - lr: 0.0010\n",
      "Epoch 180/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 141.0734 - mae: 141.0734 - val_loss: 1339.9269 - val_mae: 1339.9269 - lr: 0.0010\n",
      "Epoch 181/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 130.9592 - mae: 130.9592INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 621ms/step - loss: 130.9592 - mae: 130.9592 - val_loss: 1291.3462 - val_mae: 1291.3462 - lr: 0.0010\n",
      "Epoch 182/2000\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 124.8737 - mae: 124.8737INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 603ms/step - loss: 130.1805 - mae: 130.1805 - val_loss: 1289.5776 - val_mae: 1289.5776 - lr: 0.0010\n",
      "Epoch 183/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 141.9872 - mae: 141.9872 - val_loss: 1348.8485 - val_mae: 1348.8485 - lr: 0.0010\n",
      "Epoch 184/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 143.9860 - mae: 143.9860 - val_loss: 1395.7650 - val_mae: 1395.7650 - lr: 0.0010\n",
      "Epoch 185/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 139.4575 - mae: 139.4575 - val_loss: 1354.5292 - val_mae: 1354.5292 - lr: 0.0010\n",
      "Epoch 186/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 136.5578 - mae: 136.5578 - val_loss: 1290.1293 - val_mae: 1290.1293 - lr: 0.0010\n",
      "Epoch 187/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 151.5882 - mae: 151.5882 - val_loss: 1403.6414 - val_mae: 1403.6414 - lr: 0.0010\n",
      "Epoch 188/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 127.9418 - mae: 127.9418 - val_loss: 1344.0732 - val_mae: 1344.0732 - lr: 0.0010\n",
      "Epoch 189/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 24ms/step - loss: 143.5891 - mae: 143.5891 - val_loss: 1368.6882 - val_mae: 1368.6882 - lr: 0.0010\n",
      "Epoch 190/2000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 123.5750 - mae: 123.5750INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 631ms/step - loss: 123.7997 - mae: 123.7997 - val_loss: 1264.4734 - val_mae: 1264.4734 - lr: 0.0010\n",
      "Epoch 191/2000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 120.7362 - mae: 120.7362INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 589ms/step - loss: 121.0404 - mae: 121.0404 - val_loss: 1246.9081 - val_mae: 1246.9081 - lr: 0.0010\n",
      "Epoch 192/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 127.7395 - mae: 127.7395 - val_loss: 1277.9153 - val_mae: 1277.9153 - lr: 0.0010\n",
      "Epoch 193/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 132.7204 - mae: 132.7204 - val_loss: 1354.5056 - val_mae: 1354.5056 - lr: 0.0010\n",
      "Epoch 194/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 128.5840 - mae: 128.5840 - val_loss: 1274.6539 - val_mae: 1274.6539 - lr: 0.0010\n",
      "Epoch 195/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 127.9809 - mae: 127.9809 - val_loss: 1290.9722 - val_mae: 1290.9722 - lr: 0.0010\n",
      "Epoch 196/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.4981 - mae: 123.4981 - val_loss: 1286.7662 - val_mae: 1286.7662 - lr: 0.0010\n",
      "Epoch 197/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 128.1313 - mae: 128.1313 - val_loss: 1250.2699 - val_mae: 1250.2699 - lr: 0.0010\n",
      "Epoch 198/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 129.9256 - mae: 129.9256 - val_loss: 1281.0723 - val_mae: 1281.0723 - lr: 0.0010\n",
      "Epoch 199/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 125.2364 - mae: 125.2364INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 612ms/step - loss: 125.2364 - mae: 125.2364 - val_loss: 1246.7709 - val_mae: 1246.7709 - lr: 0.0010\n",
      "Epoch 200/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.5719 - mae: 122.5719 - val_loss: 1300.4290 - val_mae: 1300.4290 - lr: 0.0010\n",
      "Epoch 201/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 127.3478 - mae: 127.3478INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 594ms/step - loss: 127.3478 - mae: 127.3478 - val_loss: 1245.6322 - val_mae: 1245.6322 - lr: 0.0010\n",
      "Epoch 202/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 146.3468 - mae: 146.3468 - val_loss: 1484.5103 - val_mae: 1484.5103 - lr: 0.0010\n",
      "Epoch 203/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 163.1626 - mae: 163.1626 - val_loss: 1453.9207 - val_mae: 1453.9207 - lr: 0.0010\n",
      "Epoch 204/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 131.2643 - mae: 131.2643 - val_loss: 1294.0402 - val_mae: 1294.0402 - lr: 0.0010\n",
      "Epoch 205/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 140.9222 - mae: 140.9222 - val_loss: 1318.1918 - val_mae: 1318.1918 - lr: 0.0010\n",
      "Epoch 206/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 143.0819 - mae: 143.0819 - val_loss: 1371.2052 - val_mae: 1371.2052 - lr: 0.0010\n",
      "Epoch 207/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 140.9273 - mae: 140.9273 - val_loss: 1351.1938 - val_mae: 1351.1938 - lr: 0.0010\n",
      "Epoch 208/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 135.5073 - mae: 135.5073 - val_loss: 1297.0232 - val_mae: 1297.0232 - lr: 0.0010\n",
      "Epoch 209/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.3719 - mae: 123.3719 - val_loss: 1254.6324 - val_mae: 1254.6324 - lr: 0.0010\n",
      "Epoch 210/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.9697 - mae: 123.9697 - val_loss: 1287.3767 - val_mae: 1287.3767 - lr: 0.0010\n",
      "Epoch 211/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 137.0114 - mae: 137.0114 - val_loss: 1290.1364 - val_mae: 1290.1364 - lr: 0.0010\n",
      "Epoch 212/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 131.7013 - mae: 131.7013 - val_loss: 1245.8306 - val_mae: 1245.8306 - lr: 0.0010\n",
      "Epoch 213/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 124.6758 - mae: 124.6758INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 652ms/step - loss: 124.6758 - mae: 124.6758 - val_loss: 1232.1345 - val_mae: 1232.1345 - lr: 0.0010\n",
      "Epoch 214/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 123.9483 - mae: 123.9483 - val_loss: 1323.0356 - val_mae: 1323.0356 - lr: 0.0010\n",
      "Epoch 215/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.9159 - mae: 122.9159 - val_loss: 1251.9868 - val_mae: 1251.9868 - lr: 0.0010\n",
      "Epoch 216/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 118.0380 - mae: 118.0380 - val_loss: 1258.6583 - val_mae: 1258.6583 - lr: 0.0010\n",
      "Epoch 217/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 140.1929 - mae: 140.1929 - val_loss: 1353.0220 - val_mae: 1353.0220 - lr: 0.0010\n",
      "Epoch 218/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 140.4406 - mae: 140.4406 - val_loss: 1332.9233 - val_mae: 1332.9233 - lr: 0.0010\n",
      "Epoch 219/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 124.8290 - mae: 124.8290 - val_loss: 1239.4589 - val_mae: 1239.4589 - lr: 0.0010\n",
      "Epoch 220/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.9073 - mae: 122.9073 - val_loss: 1239.0208 - val_mae: 1239.0208 - lr: 0.0010\n",
      "Epoch 221/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 124.0595 - mae: 124.0595 - val_loss: 1320.7847 - val_mae: 1320.7847 - lr: 0.0010\n",
      "Epoch 222/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 154.8183 - mae: 154.8183 - val_loss: 1342.7213 - val_mae: 1342.7213 - lr: 0.0010\n",
      "Epoch 223/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 146.8602 - mae: 146.8602 - val_loss: 1369.0698 - val_mae: 1369.0698 - lr: 0.0010\n",
      "Epoch 224/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 140.3244 - mae: 140.3244 - val_loss: 1329.0243 - val_mae: 1329.0243 - lr: 0.0010\n",
      "Epoch 225/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 131.4304 - mae: 131.4304 - val_loss: 1289.3909 - val_mae: 1289.3909 - lr: 0.0010\n",
      "Epoch 226/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 136.6933 - mae: 136.6933 - val_loss: 1319.2748 - val_mae: 1319.2748 - lr: 0.0010\n",
      "Epoch 227/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.9864 - mae: 130.9864 - val_loss: 1322.7924 - val_mae: 1322.7924 - lr: 0.0010\n",
      "Epoch 228/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 145.8661 - mae: 145.8661 - val_loss: 1304.1025 - val_mae: 1304.1025 - lr: 0.0010\n",
      "Epoch 229/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 145.7501 - mae: 145.7501 - val_loss: 1335.3053 - val_mae: 1335.3053 - lr: 0.0010\n",
      "Epoch 230/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 156.1612 - mae: 156.1612 - val_loss: 1288.9113 - val_mae: 1288.9113 - lr: 0.0010\n",
      "Epoch 231/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 131.6358 - mae: 131.6358 - val_loss: 1283.3942 - val_mae: 1283.3942 - lr: 0.0010\n",
      "Epoch 232/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.8856 - mae: 123.8856 - val_loss: 1328.4152 - val_mae: 1328.4152 - lr: 0.0010\n",
      "Epoch 233/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 165.8618 - mae: 165.8618 - val_loss: 1361.1639 - val_mae: 1361.1639 - lr: 0.0010\n",
      "Epoch 234/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 134.7838 - mae: 134.7838 - val_loss: 1355.7589 - val_mae: 1355.7589 - lr: 0.0010\n",
      "Epoch 235/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 136.8847 - mae: 136.8847 - val_loss: 1293.1669 - val_mae: 1293.1669 - lr: 0.0010\n",
      "Epoch 236/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 24ms/step - loss: 129.9666 - mae: 129.9666 - val_loss: 1320.9741 - val_mae: 1320.9741 - lr: 0.0010\n",
      "Epoch 237/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 125.7178 - mae: 125.7178 - val_loss: 1249.2699 - val_mae: 1249.2699 - lr: 0.0010\n",
      "Epoch 238/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.8106 - mae: 123.8106 - val_loss: 1283.8079 - val_mae: 1283.8079 - lr: 0.0010\n",
      "Epoch 239/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 134.4283 - mae: 134.4283 - val_loss: 1306.6649 - val_mae: 1306.6649 - lr: 0.0010\n",
      "Epoch 240/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 148.4825 - mae: 148.4825 - val_loss: 1361.6189 - val_mae: 1361.6189 - lr: 0.0010\n",
      "Epoch 241/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 126.5599 - mae: 126.5599 - val_loss: 1264.4619 - val_mae: 1264.4619 - lr: 0.0010\n",
      "Epoch 242/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 121.8932 - mae: 121.8932 - val_loss: 1232.7786 - val_mae: 1232.7786 - lr: 0.0010\n",
      "Epoch 243/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 135.6385 - mae: 135.6385 - val_loss: 1356.2491 - val_mae: 1356.2491 - lr: 0.0010\n",
      "Epoch 244/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 127.9826 - mae: 127.9826 - val_loss: 1324.4723 - val_mae: 1324.4723 - lr: 0.0010\n",
      "Epoch 245/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 127.2575 - mae: 127.2575 - val_loss: 1276.1613 - val_mae: 1276.1613 - lr: 0.0010\n",
      "Epoch 246/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 119.3028 - mae: 119.3028INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 623ms/step - loss: 119.3028 - mae: 119.3028 - val_loss: 1230.9712 - val_mae: 1230.9712 - lr: 0.0010\n",
      "Epoch 247/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 123.0576 - mae: 123.0576 - val_loss: 1344.9794 - val_mae: 1344.9794 - lr: 0.0010\n",
      "Epoch 248/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 159.5168 - mae: 159.5168 - val_loss: 1415.7690 - val_mae: 1415.7690 - lr: 0.0010\n",
      "Epoch 249/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 139.4522 - mae: 139.4522 - val_loss: 1291.3979 - val_mae: 1291.3979 - lr: 0.0010\n",
      "Epoch 250/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 137.7565 - mae: 137.7565 - val_loss: 1324.9094 - val_mae: 1324.9094 - lr: 0.0010\n",
      "Epoch 251/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 128.1200 - mae: 128.1200 - val_loss: 1256.3328 - val_mae: 1256.3328 - lr: 0.0010\n",
      "Epoch 252/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.8108 - mae: 130.8108 - val_loss: 1266.3770 - val_mae: 1266.3770 - lr: 0.0010\n",
      "Epoch 253/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 134.3111 - mae: 134.3111 - val_loss: 1289.4781 - val_mae: 1289.4781 - lr: 0.0010\n",
      "Epoch 254/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 144.8668 - mae: 144.8668 - val_loss: 1320.1342 - val_mae: 1320.1342 - lr: 0.0010\n",
      "Epoch 255/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 166.4046 - mae: 166.4046 - val_loss: 1507.0482 - val_mae: 1507.0482 - lr: 0.0010\n",
      "Epoch 256/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 131.0171 - mae: 131.0171 - val_loss: 1331.6158 - val_mae: 1331.6158 - lr: 0.0010\n",
      "Epoch 257/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 132.1958 - mae: 132.1958 - val_loss: 1248.7115 - val_mae: 1248.7115 - lr: 0.0010\n",
      "Epoch 258/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 121.9956 - mae: 121.9956 - val_loss: 1248.1825 - val_mae: 1248.1825 - lr: 0.0010\n",
      "Epoch 259/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.3059 - mae: 119.3059 - val_loss: 1266.3619 - val_mae: 1266.3619 - lr: 0.0010\n",
      "Epoch 260/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.1771 - mae: 122.1771 - val_loss: 1278.8970 - val_mae: 1278.8970 - lr: 0.0010\n",
      "Epoch 261/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 150.0714 - mae: 150.0714 - val_loss: 1469.9393 - val_mae: 1469.9393 - lr: 0.0010\n",
      "Epoch 262/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 156.7124 - mae: 156.7124 - val_loss: 1376.7920 - val_mae: 1376.7920 - lr: 0.0010\n",
      "Epoch 263/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 129.5844 - mae: 129.5844 - val_loss: 1261.2361 - val_mae: 1261.2361 - lr: 0.0010\n",
      "Epoch 264/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 125.6407 - mae: 125.6407 - val_loss: 1247.7710 - val_mae: 1247.7710 - lr: 0.0010\n",
      "Epoch 265/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 127.0061 - mae: 127.0061 - val_loss: 1269.3386 - val_mae: 1269.3386 - lr: 0.0010\n",
      "Epoch 266/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 143.3864 - mae: 143.3864 - val_loss: 1297.6251 - val_mae: 1297.6251 - lr: 0.0010\n",
      "Epoch 267/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 142.3312 - mae: 142.3312 - val_loss: 1297.6705 - val_mae: 1297.6705 - lr: 0.0010\n",
      "Epoch 268/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 139.0481 - mae: 139.0481 - val_loss: 1248.6300 - val_mae: 1248.6300 - lr: 0.0010\n",
      "Epoch 269/2000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 122.7335 - mae: 122.7335INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 626ms/step - loss: 123.0283 - mae: 123.0283 - val_loss: 1229.0986 - val_mae: 1229.0986 - lr: 0.0010\n",
      "Epoch 270/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 124.4866 - mae: 124.4866 - val_loss: 1276.7723 - val_mae: 1276.7723 - lr: 0.0010\n",
      "Epoch 271/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 140.4961 - mae: 140.4961 - val_loss: 1317.3301 - val_mae: 1317.3301 - lr: 0.0010\n",
      "Epoch 272/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 147.3290 - mae: 147.3290 - val_loss: 1527.6375 - val_mae: 1527.6375 - lr: 0.0010\n",
      "Epoch 273/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 148.3305 - mae: 148.3305 - val_loss: 1301.8384 - val_mae: 1301.8384 - lr: 0.0010\n",
      "Epoch 274/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 128.3910 - mae: 128.3910 - val_loss: 1290.8350 - val_mae: 1290.8350 - lr: 0.0010\n",
      "Epoch 275/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.9899 - mae: 122.9899 - val_loss: 1262.2717 - val_mae: 1262.2717 - lr: 0.0010\n",
      "Epoch 276/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 135.9944 - mae: 135.9944 - val_loss: 1261.5774 - val_mae: 1261.5774 - lr: 0.0010\n",
      "Epoch 277/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 125.6392 - mae: 125.6392 - val_loss: 1264.3568 - val_mae: 1264.3568 - lr: 0.0010\n",
      "Epoch 278/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 121.0080 - mae: 121.0080 - val_loss: 1233.4308 - val_mae: 1233.4308 - lr: 0.0010\n",
      "Epoch 279/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 118.7086 - mae: 118.7086INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 15s 664ms/step - loss: 118.7086 - mae: 118.7086 - val_loss: 1226.0940 - val_mae: 1226.0940 - lr: 0.0010\n",
      "Epoch 280/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 122.5365 - mae: 122.5365 - val_loss: 1261.0017 - val_mae: 1261.0017 - lr: 0.0010\n",
      "Epoch 281/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 120.1983 - mae: 120.1983INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 15s 659ms/step - loss: 120.1983 - mae: 120.1983 - val_loss: 1218.8135 - val_mae: 1218.8135 - lr: 0.0010\n",
      "Epoch 282/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 121.2522 - mae: 121.2522 - val_loss: 1277.5533 - val_mae: 1277.5533 - lr: 0.0010\n",
      "Epoch 283/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 138.7673 - mae: 138.7673 - val_loss: 1331.1050 - val_mae: 1331.1050 - lr: 0.0010\n",
      "Epoch 284/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 24ms/step - loss: 123.1182 - mae: 123.1182 - val_loss: 1278.2852 - val_mae: 1278.2852 - lr: 0.0010\n",
      "Epoch 285/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 117.3857 - mae: 117.3857INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 634ms/step - loss: 117.3857 - mae: 117.3857 - val_loss: 1199.6721 - val_mae: 1199.6721 - lr: 0.0010\n",
      "Epoch 286/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.0128 - mae: 122.0128 - val_loss: 1277.1600 - val_mae: 1277.1600 - lr: 0.0010\n",
      "Epoch 287/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 120.3481 - mae: 120.3481 - val_loss: 1211.0444 - val_mae: 1211.0444 - lr: 0.0010\n",
      "Epoch 288/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.7494 - mae: 116.7494 - val_loss: 1208.6985 - val_mae: 1208.6985 - lr: 0.0010\n",
      "Epoch 289/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 115.5146 - mae: 115.5146INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 613ms/step - loss: 115.5146 - mae: 115.5146 - val_loss: 1197.5887 - val_mae: 1197.5887 - lr: 0.0010\n",
      "Epoch 290/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 117.0158 - mae: 117.0158 - val_loss: 1210.2367 - val_mae: 1210.2367 - lr: 0.0010\n",
      "Epoch 291/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 113.5376 - mae: 113.5376 - val_loss: 1242.5502 - val_mae: 1242.5502 - lr: 0.0010\n",
      "Epoch 292/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.7065 - mae: 130.7065 - val_loss: 1272.4910 - val_mae: 1272.4910 - lr: 0.0010\n",
      "Epoch 293/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.6676 - mae: 117.6676 - val_loss: 1274.5732 - val_mae: 1274.5732 - lr: 0.0010\n",
      "Epoch 294/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 131.9915 - mae: 131.9915 - val_loss: 1255.5497 - val_mae: 1255.5497 - lr: 0.0010\n",
      "Epoch 295/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.6023 - mae: 119.6023 - val_loss: 1207.2798 - val_mae: 1207.2798 - lr: 0.0010\n",
      "Epoch 296/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.8329 - mae: 115.8329 - val_loss: 1229.4109 - val_mae: 1229.4109 - lr: 0.0010\n",
      "Epoch 297/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.2845 - mae: 116.2845 - val_loss: 1249.7303 - val_mae: 1249.7303 - lr: 0.0010\n",
      "Epoch 298/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.7386 - mae: 122.7386 - val_loss: 1258.0305 - val_mae: 1258.0305 - lr: 0.0010\n",
      "Epoch 299/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 114.0042 - mae: 114.0042 - val_loss: 1202.7980 - val_mae: 1202.7980 - lr: 0.0010\n",
      "Epoch 300/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.2093 - mae: 119.2093 - val_loss: 1228.0150 - val_mae: 1228.0150 - lr: 0.0010\n",
      "Epoch 301/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 125.3952 - mae: 125.3952 - val_loss: 1238.1616 - val_mae: 1238.1616 - lr: 0.0010\n",
      "Epoch 302/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 127.0647 - mae: 127.0647 - val_loss: 1248.1378 - val_mae: 1248.1378 - lr: 0.0010\n",
      "Epoch 303/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 125.5419 - mae: 125.5419 - val_loss: 1228.0322 - val_mae: 1228.0322 - lr: 0.0010\n",
      "Epoch 304/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 120.3504 - mae: 120.3504 - val_loss: 1229.5875 - val_mae: 1229.5875 - lr: 0.0010\n",
      "Epoch 305/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.1056 - mae: 122.1056 - val_loss: 1240.1118 - val_mae: 1240.1118 - lr: 0.0010\n",
      "Epoch 306/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 120.9201 - mae: 120.9201 - val_loss: 1254.0717 - val_mae: 1254.0717 - lr: 0.0010\n",
      "Epoch 307/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 129.1193 - mae: 129.1193 - val_loss: 1235.6853 - val_mae: 1235.6853 - lr: 0.0010\n",
      "Epoch 308/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.9109 - mae: 119.9109 - val_loss: 1234.4678 - val_mae: 1234.4678 - lr: 0.0010\n",
      "Epoch 309/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.2705 - mae: 123.2705 - val_loss: 1253.3047 - val_mae: 1253.3047 - lr: 0.0010\n",
      "Epoch 310/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 114.6482 - mae: 114.6482INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 589ms/step - loss: 114.6482 - mae: 114.6482 - val_loss: 1190.6155 - val_mae: 1190.6155 - lr: 0.0010\n",
      "Epoch 311/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 114.2459 - mae: 114.2459 - val_loss: 1203.2875 - val_mae: 1203.2875 - lr: 0.0010\n",
      "Epoch 312/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 125.1630 - mae: 125.1630 - val_loss: 1246.1766 - val_mae: 1246.1766 - lr: 0.0010\n",
      "Epoch 313/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 136.1973 - mae: 136.1973 - val_loss: 1271.6675 - val_mae: 1271.6675 - lr: 0.0010\n",
      "Epoch 314/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.7218 - mae: 119.7218 - val_loss: 1203.4298 - val_mae: 1203.4298 - lr: 0.0010\n",
      "Epoch 315/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.2454 - mae: 112.2454 - val_loss: 1192.1029 - val_mae: 1192.1029 - lr: 0.0010\n",
      "Epoch 316/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.8496 - mae: 115.8496 - val_loss: 1243.8385 - val_mae: 1243.8385 - lr: 0.0010\n",
      "Epoch 317/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 118.2436 - mae: 118.2436 - val_loss: 1214.2462 - val_mae: 1214.2462 - lr: 0.0010\n",
      "Epoch 318/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 118.4484 - mae: 118.4484 - val_loss: 1254.3615 - val_mae: 1254.3615 - lr: 0.0010\n",
      "Epoch 319/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 120.4668 - mae: 120.4668 - val_loss: 1224.6479 - val_mae: 1224.6479 - lr: 0.0010\n",
      "Epoch 320/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 124.9355 - mae: 124.9355 - val_loss: 1201.7837 - val_mae: 1201.7837 - lr: 0.0010\n",
      "Epoch 321/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.0256 - mae: 115.0256 - val_loss: 1212.8522 - val_mae: 1212.8522 - lr: 0.0010\n",
      "Epoch 322/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.0237 - mae: 117.0237 - val_loss: 1268.9521 - val_mae: 1268.9521 - lr: 0.0010\n",
      "Epoch 323/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 124.1653 - mae: 124.1653 - val_loss: 1222.6409 - val_mae: 1222.6409 - lr: 0.0010\n",
      "Epoch 324/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 110.0295 - mae: 110.0295 - val_loss: 1212.4730 - val_mae: 1212.4730 - lr: 0.0010\n",
      "Epoch 325/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.8352 - mae: 122.8352 - val_loss: 1280.8057 - val_mae: 1280.8057 - lr: 0.0010\n",
      "Epoch 326/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.3136 - mae: 116.3136 - val_loss: 1274.3320 - val_mae: 1274.3320 - lr: 0.0010\n",
      "Epoch 327/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 137.0739 - mae: 137.0739 - val_loss: 1352.1261 - val_mae: 1352.1261 - lr: 0.0010\n",
      "Epoch 328/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 142.1763 - mae: 142.1763 - val_loss: 1260.1770 - val_mae: 1260.1770 - lr: 0.0010\n",
      "Epoch 329/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 118.3273 - mae: 118.3273 - val_loss: 1207.0703 - val_mae: 1207.0703 - lr: 0.0010\n",
      "Epoch 330/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 120.7770 - mae: 120.7770 - val_loss: 1221.2408 - val_mae: 1221.2408 - lr: 0.0010\n",
      "Epoch 331/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 129.1001 - mae: 129.1001 - val_loss: 1355.4103 - val_mae: 1355.4103 - lr: 0.0010\n",
      "Epoch 332/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 125.9652 - mae: 125.9652 - val_loss: 1197.0876 - val_mae: 1197.0876 - lr: 0.0010\n",
      "Epoch 333/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 24ms/step - loss: 118.1309 - mae: 118.1309 - val_loss: 1199.3917 - val_mae: 1199.3917 - lr: 0.0010\n",
      "Epoch 334/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 121.3574 - mae: 121.3574 - val_loss: 1200.6620 - val_mae: 1200.6620 - lr: 0.0010\n",
      "Epoch 335/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.7834 - mae: 117.7834 - val_loss: 1206.6405 - val_mae: 1206.6405 - lr: 0.0010\n",
      "Epoch 336/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.1820 - mae: 115.1820 - val_loss: 1216.6936 - val_mae: 1216.6936 - lr: 0.0010\n",
      "Epoch 337/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 121.5289 - mae: 121.5289 - val_loss: 1250.1147 - val_mae: 1250.1147 - lr: 0.0010\n",
      "Epoch 338/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.0276 - mae: 130.0276 - val_loss: 1235.2528 - val_mae: 1235.2528 - lr: 0.0010\n",
      "Epoch 339/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.0142 - mae: 119.0142 - val_loss: 1212.4124 - val_mae: 1212.4124 - lr: 0.0010\n",
      "Epoch 340/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 125.6829 - mae: 125.6829 - val_loss: 1208.8628 - val_mae: 1208.8628 - lr: 0.0010\n",
      "Epoch 341/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 127.5957 - mae: 127.5957 - val_loss: 1213.8215 - val_mae: 1213.8215 - lr: 0.0010\n",
      "Epoch 342/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 137.6500 - mae: 137.6500 - val_loss: 1240.2699 - val_mae: 1240.2699 - lr: 0.0010\n",
      "Epoch 343/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.5816 - mae: 117.5816 - val_loss: 1239.1136 - val_mae: 1239.1136 - lr: 0.0010\n",
      "Epoch 344/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 122.5647 - mae: 122.5647 - val_loss: 1226.5491 - val_mae: 1226.5491 - lr: 0.0010\n",
      "Epoch 345/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.2296 - mae: 130.2296 - val_loss: 1251.6237 - val_mae: 1251.6237 - lr: 0.0010\n",
      "Epoch 346/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 124.7936 - mae: 124.7936 - val_loss: 1255.1290 - val_mae: 1255.1290 - lr: 0.0010\n",
      "Epoch 347/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 118.0439 - mae: 118.0439 - val_loss: 1216.5404 - val_mae: 1216.5404 - lr: 0.0010\n",
      "Epoch 348/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.5164 - mae: 116.5164 - val_loss: 1221.7391 - val_mae: 1221.7391 - lr: 0.0010\n",
      "Epoch 349/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.2999 - mae: 117.2999 - val_loss: 1238.1591 - val_mae: 1238.1591 - lr: 0.0010\n",
      "Epoch 350/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.6406 - mae: 116.6406 - val_loss: 1234.7321 - val_mae: 1234.7321 - lr: 0.0010\n",
      "Epoch 351/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 135.3392 - mae: 135.3392 - val_loss: 1290.2941 - val_mae: 1290.2941 - lr: 0.0010\n",
      "Epoch 352/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.3881 - mae: 115.3881 - val_loss: 1198.8135 - val_mae: 1198.8135 - lr: 0.0010\n",
      "Epoch 353/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 113.9712 - mae: 113.9712 - val_loss: 1203.0924 - val_mae: 1203.0924 - lr: 0.0010\n",
      "Epoch 354/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.6171 - mae: 109.6171 - val_loss: 1222.1888 - val_mae: 1222.1888 - lr: 0.0010\n",
      "Epoch 355/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 127.7069 - mae: 127.7069 - val_loss: 1214.9115 - val_mae: 1214.9115 - lr: 0.0010\n",
      "Epoch 356/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.4194 - mae: 130.4194 - val_loss: 1509.8926 - val_mae: 1509.8926 - lr: 0.0010\n",
      "Epoch 357/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.1864 - mae: 119.1864 - val_loss: 1218.5841 - val_mae: 1218.5841 - lr: 0.0010\n",
      "Epoch 358/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 124.0319 - mae: 124.0319 - val_loss: 1240.3031 - val_mae: 1240.3031 - lr: 0.0010\n",
      "Epoch 359/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 135.1930 - mae: 135.1930 - val_loss: 1269.7660 - val_mae: 1269.7660 - lr: 0.0010\n",
      "Epoch 360/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 129.2537 - mae: 129.2537 - val_loss: 1237.3271 - val_mae: 1237.3271 - lr: 0.0010\n",
      "Epoch 361/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 111.5963 - mae: 111.5963 - val_loss: 1198.9186 - val_mae: 1198.9186 - lr: 0.0010\n",
      "Epoch 362/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 111.1324 - mae: 111.1324 - val_loss: 1223.0576 - val_mae: 1223.0576 - lr: 0.0010\n",
      "Epoch 363/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.9428 - mae: 123.9428 - val_loss: 1275.9542 - val_mae: 1275.9542 - lr: 0.0010\n",
      "Epoch 364/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 126.4139 - mae: 126.4139 - val_loss: 1229.7896 - val_mae: 1229.7896 - lr: 0.0010\n",
      "Epoch 365/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 118.6334 - mae: 118.6334 - val_loss: 1219.2513 - val_mae: 1219.2513 - lr: 0.0010\n",
      "Epoch 366/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 113.6120 - mae: 113.6120 - val_loss: 1207.9817 - val_mae: 1207.9817 - lr: 0.0010\n",
      "Epoch 367/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.7564 - mae: 119.7564 - val_loss: 1232.6449 - val_mae: 1232.6449 - lr: 0.0010\n",
      "Epoch 368/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.2959 - mae: 117.2959 - val_loss: 1197.6794 - val_mae: 1197.6794 - lr: 0.0010\n",
      "Epoch 369/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 113.4195 - mae: 113.4195INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 15s 684ms/step - loss: 113.4195 - mae: 113.4195 - val_loss: 1190.5804 - val_mae: 1190.5804 - lr: 0.0010\n",
      "Epoch 370/2000\n",
      "20/22 [==========================>...] - ETA: 0s - loss: 102.0785 - mae: 102.0785INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 593ms/step - loss: 106.8902 - mae: 106.8902 - val_loss: 1189.9069 - val_mae: 1189.9069 - lr: 0.0010\n",
      "Epoch 371/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 112.3122 - mae: 112.3122 - val_loss: 1232.3849 - val_mae: 1232.3849 - lr: 0.0010\n",
      "Epoch 372/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.2108 - mae: 106.2108 - val_loss: 1225.0868 - val_mae: 1225.0868 - lr: 0.0010\n",
      "Epoch 373/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.5825 - mae: 109.5825 - val_loss: 1206.9663 - val_mae: 1206.9663 - lr: 0.0010\n",
      "Epoch 374/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 119.0459 - mae: 119.0459INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 13s 599ms/step - loss: 119.0459 - mae: 119.0459 - val_loss: 1186.2432 - val_mae: 1186.2432 - lr: 0.0010\n",
      "Epoch 375/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 111.1290 - mae: 111.1290 - val_loss: 1219.4407 - val_mae: 1219.4407 - lr: 0.0010\n",
      "Epoch 376/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.4861 - mae: 106.4861 - val_loss: 1221.5560 - val_mae: 1221.5560 - lr: 0.0010\n",
      "Epoch 377/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.1017 - mae: 108.1017 - val_loss: 1213.5579 - val_mae: 1213.5579 - lr: 0.0010\n",
      "Epoch 378/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 110.1157 - mae: 110.1157 - val_loss: 1208.9659 - val_mae: 1208.9659 - lr: 0.0010\n",
      "Epoch 379/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 113.8218 - mae: 113.8218 - val_loss: 1226.3416 - val_mae: 1226.3416 - lr: 0.0010\n",
      "Epoch 380/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.4153 - mae: 119.4153 - val_loss: 1214.5743 - val_mae: 1214.5743 - lr: 0.0010\n",
      "Epoch 381/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.7655 - mae: 108.7655 - val_loss: 1190.7617 - val_mae: 1190.7617 - lr: 0.0010\n",
      "Epoch 382/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 24ms/step - loss: 107.3138 - mae: 107.3138 - val_loss: 1217.1843 - val_mae: 1217.1843 - lr: 0.0010\n",
      "Epoch 383/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 110.2552 - mae: 110.2552 - val_loss: 1272.5509 - val_mae: 1272.5509 - lr: 0.0010\n",
      "Epoch 384/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 127.7658 - mae: 127.7658 - val_loss: 1265.0376 - val_mae: 1265.0376 - lr: 0.0010\n",
      "Epoch 385/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 111.6373 - mae: 111.6373 - val_loss: 1239.5912 - val_mae: 1239.5912 - lr: 0.0010\n",
      "Epoch 386/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.3639 - mae: 116.3639 - val_loss: 1220.9968 - val_mae: 1220.9968 - lr: 0.0010\n",
      "Epoch 387/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.0832 - mae: 116.0832 - val_loss: 1218.2538 - val_mae: 1218.2538 - lr: 0.0010\n",
      "Epoch 388/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 122.9174 - mae: 122.9174 - val_loss: 1253.0243 - val_mae: 1253.0243 - lr: 0.0010\n",
      "Epoch 389/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 114.4880 - mae: 114.4880 - val_loss: 1208.9895 - val_mae: 1208.9895 - lr: 0.0010\n",
      "Epoch 390/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 111.5807 - mae: 111.5807 - val_loss: 1196.4834 - val_mae: 1196.4834 - lr: 0.0010\n",
      "Epoch 391/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 107.0919 - mae: 107.0919 - val_loss: 1186.3345 - val_mae: 1186.3345 - lr: 0.0010\n",
      "Epoch 392/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.3556 - mae: 109.3556 - val_loss: 1198.7242 - val_mae: 1198.7242 - lr: 0.0010\n",
      "Epoch 393/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.1988 - mae: 109.1988 - val_loss: 1228.6593 - val_mae: 1228.6593 - lr: 0.0010\n",
      "Epoch 394/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.6467 - mae: 115.6467 - val_loss: 1202.8119 - val_mae: 1202.8119 - lr: 0.0010\n",
      "Epoch 395/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.5854 - mae: 106.5854 - val_loss: 1211.6013 - val_mae: 1211.6013 - lr: 0.0010\n",
      "Epoch 396/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 110.0414 - mae: 110.0414 - val_loss: 1228.6877 - val_mae: 1228.6877 - lr: 0.0010\n",
      "Epoch 397/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 118.3499 - mae: 118.3499 - val_loss: 1272.2745 - val_mae: 1272.2745 - lr: 0.0010\n",
      "Epoch 398/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 124.2255 - mae: 124.2255 - val_loss: 1229.0559 - val_mae: 1229.0559 - lr: 0.0010\n",
      "Epoch 399/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 113.4395 - mae: 113.4395 - val_loss: 1251.1497 - val_mae: 1251.1497 - lr: 0.0010\n",
      "Epoch 400/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.1437 - mae: 130.1437 - val_loss: 1230.2859 - val_mae: 1230.2859 - lr: 0.0010\n",
      "Epoch 401/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.5154 - mae: 116.5154 - val_loss: 1216.3364 - val_mae: 1216.3364 - lr: 0.0010\n",
      "Epoch 402/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.8434 - mae: 115.8434 - val_loss: 1199.9443 - val_mae: 1199.9443 - lr: 0.0010\n",
      "Epoch 403/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.3410 - mae: 117.3410 - val_loss: 1221.4868 - val_mae: 1221.4868 - lr: 0.0010\n",
      "Epoch 404/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 131.0690 - mae: 131.0690 - val_loss: 1299.6669 - val_mae: 1299.6669 - lr: 0.0010\n",
      "Epoch 405/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 137.6588 - mae: 137.6588 - val_loss: 1380.1971 - val_mae: 1380.1971 - lr: 0.0010\n",
      "Epoch 406/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 129.8603 - mae: 129.8603 - val_loss: 1243.9700 - val_mae: 1243.9700 - lr: 0.0010\n",
      "Epoch 407/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.5438 - mae: 116.5438 - val_loss: 1226.3771 - val_mae: 1226.3771 - lr: 0.0010\n",
      "Epoch 408/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.1633 - mae: 123.1633 - val_loss: 1200.6661 - val_mae: 1200.6661 - lr: 0.0010\n",
      "Epoch 409/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.2055 - mae: 117.2055 - val_loss: 1236.8715 - val_mae: 1236.8715 - lr: 0.0010\n",
      "Epoch 410/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.3997 - mae: 123.3997 - val_loss: 1254.2544 - val_mae: 1254.2544 - lr: 0.0010\n",
      "Epoch 411/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 119.3014 - mae: 119.3014 - val_loss: 1200.1591 - val_mae: 1200.1591 - lr: 0.0010\n",
      "Epoch 412/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.5076 - mae: 117.5076 - val_loss: 1195.1620 - val_mae: 1195.1620 - lr: 0.0010\n",
      "Epoch 413/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.5403 - mae: 112.5403 - val_loss: 1189.7870 - val_mae: 1189.7870 - lr: 0.0010\n",
      "Epoch 414/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 113.1846 - mae: 113.1846 - val_loss: 1202.5986 - val_mae: 1202.5986 - lr: 0.0010\n",
      "Epoch 415/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.2818 - mae: 119.2818 - val_loss: 1239.9745 - val_mae: 1239.9745 - lr: 0.0010\n",
      "Epoch 416/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 130.7953 - mae: 130.7953 - val_loss: 1283.1199 - val_mae: 1283.1199 - lr: 0.0010\n",
      "Epoch 417/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.0893 - mae: 119.0893 - val_loss: 1211.1096 - val_mae: 1211.1096 - lr: 0.0010\n",
      "Epoch 418/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.5679 - mae: 112.5679 - val_loss: 1198.3912 - val_mae: 1198.3912 - lr: 0.0010\n",
      "Epoch 419/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.8915 - mae: 117.8915 - val_loss: 1200.9786 - val_mae: 1200.9786 - lr: 0.0010\n",
      "Epoch 420/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.1314 - mae: 115.1314 - val_loss: 1238.4858 - val_mae: 1238.4858 - lr: 0.0010\n",
      "Epoch 421/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.4621 - mae: 115.4621 - val_loss: 1214.0587 - val_mae: 1214.0587 - lr: 0.0010\n",
      "Epoch 422/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.1295 - mae: 109.1295 - val_loss: 1194.4238 - val_mae: 1194.4238 - lr: 0.0010\n",
      "Epoch 423/2000\n",
      "22/22 [==============================] - ETA: 0s - loss: 113.5936 - mae: 113.5936INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 14s 657ms/step - loss: 113.5936 - mae: 113.5936 - val_loss: 1169.0675 - val_mae: 1169.0675 - lr: 0.0010\n",
      "Epoch 424/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 117.1767 - mae: 117.1767 - val_loss: 1196.8647 - val_mae: 1196.8647 - lr: 0.0010\n",
      "Epoch 425/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 116.5512 - mae: 116.5512 - val_loss: 1234.8376 - val_mae: 1234.8376 - lr: 0.0010\n",
      "Epoch 426/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 110.7542 - mae: 110.7542 - val_loss: 1188.1144 - val_mae: 1188.1144 - lr: 0.0010\n",
      "Epoch 427/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 111.8122 - mae: 111.8122 - val_loss: 1217.6144 - val_mae: 1217.6144 - lr: 0.0010\n",
      "Epoch 428/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 110.9137 - mae: 110.9137 - val_loss: 1218.8599 - val_mae: 1218.8599 - lr: 0.0010\n",
      "Epoch 429/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 114.5828 - mae: 114.5828 - val_loss: 1227.5854 - val_mae: 1227.5854 - lr: 0.0010\n",
      "Epoch 430/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.5806 - mae: 108.5806 - val_loss: 1193.3525 - val_mae: 1193.3525 - lr: 0.0010\n",
      "Epoch 431/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 121.2902 - mae: 121.2902 - val_loss: 1262.3112 - val_mae: 1262.3112 - lr: 0.0010\n",
      "Epoch 432/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 118.2028 - mae: 118.2028 - val_loss: 1191.1758 - val_mae: 1191.1758 - lr: 0.0010\n",
      "Epoch 433/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 24ms/step - loss: 107.1002 - mae: 107.1002 - val_loss: 1196.4534 - val_mae: 1196.4534 - lr: 0.0010\n",
      "Epoch 434/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.0152 - mae: 106.0152 - val_loss: 1209.6832 - val_mae: 1209.6832 - lr: 0.0010\n",
      "Epoch 435/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.4154 - mae: 112.4154 - val_loss: 1216.4701 - val_mae: 1216.4701 - lr: 0.0010\n",
      "Epoch 436/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.8903 - mae: 115.8903 - val_loss: 1204.8652 - val_mae: 1204.8652 - lr: 0.0010\n",
      "Epoch 437/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 110.4489 - mae: 110.4489 - val_loss: 1216.0813 - val_mae: 1216.0813 - lr: 0.0010\n",
      "Epoch 438/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.0367 - mae: 106.0367 - val_loss: 1216.8608 - val_mae: 1216.8608 - lr: 0.0010\n",
      "Epoch 439/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.1859 - mae: 108.1859 - val_loss: 1228.9203 - val_mae: 1228.9203 - lr: 0.0010\n",
      "Epoch 440/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 111.1139 - mae: 111.1139 - val_loss: 1223.1926 - val_mae: 1223.1926 - lr: 0.0010\n",
      "Epoch 441/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.5895 - mae: 115.5895 - val_loss: 1226.3224 - val_mae: 1226.3224 - lr: 0.0010\n",
      "Epoch 442/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.9098 - mae: 108.9098 - val_loss: 1213.3142 - val_mae: 1213.3142 - lr: 0.0010\n",
      "Epoch 443/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.0521 - mae: 117.0521 - val_loss: 1201.6980 - val_mae: 1201.6980 - lr: 0.0010\n",
      "Epoch 444/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 113.2339 - mae: 113.2339 - val_loss: 1207.1682 - val_mae: 1207.1682 - lr: 0.0010\n",
      "Epoch 445/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.5684 - mae: 108.5684 - val_loss: 1198.9164 - val_mae: 1198.9164 - lr: 0.0010\n",
      "Epoch 446/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 134.0390 - mae: 134.0390 - val_loss: 1283.8390 - val_mae: 1283.8390 - lr: 0.0010\n",
      "Epoch 447/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 129.9156 - mae: 129.9156 - val_loss: 1207.2860 - val_mae: 1207.2860 - lr: 0.0010\n",
      "Epoch 448/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 114.8593 - mae: 114.8593 - val_loss: 1196.9231 - val_mae: 1196.9231 - lr: 0.0010\n",
      "Epoch 449/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.6764 - mae: 106.6764 - val_loss: 1194.2422 - val_mae: 1194.2422 - lr: 0.0010\n",
      "Epoch 450/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 100.8584 - mae: 100.8584 - val_loss: 1173.5006 - val_mae: 1173.5006 - lr: 0.0010\n",
      "Epoch 451/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 102.8795 - mae: 102.8795 - val_loss: 1214.5164 - val_mae: 1214.5164 - lr: 0.0010\n",
      "Epoch 452/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 104.2551 - mae: 104.2551 - val_loss: 1237.1293 - val_mae: 1237.1293 - lr: 0.0010\n",
      "Epoch 453/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 113.6509 - mae: 113.6509 - val_loss: 1208.0066 - val_mae: 1208.0066 - lr: 0.0010\n",
      "Epoch 454/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.5867 - mae: 106.5867 - val_loss: 1179.4042 - val_mae: 1179.4042 - lr: 0.0010\n",
      "Epoch 455/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 110.2628 - mae: 110.2628 - val_loss: 1199.9688 - val_mae: 1199.9688 - lr: 0.0010\n",
      "Epoch 456/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.7736 - mae: 112.7736 - val_loss: 1233.7216 - val_mae: 1233.7216 - lr: 0.0010\n",
      "Epoch 457/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.4091 - mae: 106.4091 - val_loss: 1206.4236 - val_mae: 1206.4236 - lr: 0.0010\n",
      "Epoch 458/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 123.5427 - mae: 123.5427 - val_loss: 1263.1431 - val_mae: 1263.1431 - lr: 0.0010\n",
      "Epoch 459/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.7655 - mae: 119.7655 - val_loss: 1217.4786 - val_mae: 1217.4786 - lr: 0.0010\n",
      "Epoch 460/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.4503 - mae: 112.4503 - val_loss: 1201.5317 - val_mae: 1201.5317 - lr: 0.0010\n",
      "Epoch 461/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.4097 - mae: 112.4097 - val_loss: 1249.6420 - val_mae: 1249.6420 - lr: 0.0010\n",
      "Epoch 462/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 118.7235 - mae: 118.7235 - val_loss: 1235.2069 - val_mae: 1235.2069 - lr: 0.0010\n",
      "Epoch 463/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 114.0037 - mae: 114.0037 - val_loss: 1217.7498 - val_mae: 1217.7498 - lr: 0.0010\n",
      "Epoch 464/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 113.9040 - mae: 113.9040 - val_loss: 1243.4899 - val_mae: 1243.4899 - lr: 0.0010\n",
      "Epoch 465/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 118.8371 - mae: 118.8371 - val_loss: 1230.8309 - val_mae: 1230.8309 - lr: 0.0010\n",
      "Epoch 466/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.9242 - mae: 109.9242 - val_loss: 1230.6338 - val_mae: 1230.6338 - lr: 0.0010\n",
      "Epoch 467/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.8301 - mae: 108.8301 - val_loss: 1183.7458 - val_mae: 1183.7458 - lr: 0.0010\n",
      "Epoch 468/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.5986 - mae: 109.5986 - val_loss: 1237.4683 - val_mae: 1237.4683 - lr: 0.0010\n",
      "Epoch 469/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 126.4036 - mae: 126.4036 - val_loss: 1264.6296 - val_mae: 1264.6296 - lr: 0.0010\n",
      "Epoch 470/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 119.8686 - mae: 119.8686 - val_loss: 1224.2499 - val_mae: 1224.2499 - lr: 0.0010\n",
      "Epoch 471/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 118.2282 - mae: 118.2282 - val_loss: 1217.8002 - val_mae: 1217.8002 - lr: 0.0010\n",
      "Epoch 472/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 105.3949 - mae: 105.3949 - val_loss: 1197.7383 - val_mae: 1197.7383 - lr: 0.0010\n",
      "Epoch 473/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.1755 - mae: 109.1755 - val_loss: 1232.4746 - val_mae: 1232.4746 - lr: 0.0010\n",
      "Epoch 474/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 110.5524 - mae: 110.5524 - val_loss: 1221.8566 - val_mae: 1221.8566 - lr: 0.0010\n",
      "Epoch 475/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 127.2698 - mae: 127.2698 - val_loss: 1225.2339 - val_mae: 1225.2339 - lr: 0.0010\n",
      "Epoch 476/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 109.1282 - mae: 109.1282 - val_loss: 1219.8162 - val_mae: 1219.8162 - lr: 0.0010\n",
      "Epoch 477/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.8714 - mae: 108.8714 - val_loss: 1203.9688 - val_mae: 1203.9688 - lr: 0.0010\n",
      "Epoch 478/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 105.5017 - mae: 105.5017 - val_loss: 1209.4795 - val_mae: 1209.4795 - lr: 0.0010\n",
      "Epoch 479/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.0588 - mae: 106.0588 - val_loss: 1227.1263 - val_mae: 1227.1263 - lr: 0.0010\n",
      "Epoch 480/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 123.4866 - mae: 123.4866 - val_loss: 1226.0359 - val_mae: 1226.0359 - lr: 0.0010\n",
      "Epoch 481/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 111.0710 - mae: 111.0710 - val_loss: 1227.3986 - val_mae: 1227.3986 - lr: 0.0010\n",
      "Epoch 482/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 113.9448 - mae: 113.9448 - val_loss: 1207.7867 - val_mae: 1207.7867 - lr: 0.0010\n",
      "Epoch 483/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.3308 - mae: 109.3308 - val_loss: 1206.2710 - val_mae: 1206.2710 - lr: 0.0010\n",
      "Epoch 484/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 107.4983 - mae: 107.4983 - val_loss: 1202.1907 - val_mae: 1202.1907 - lr: 0.0010\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 485/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 117.5793 - mae: 117.5793 - val_loss: 1234.5210 - val_mae: 1234.5210 - lr: 0.0010\n",
      "Epoch 486/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 112.5406 - mae: 112.5406 - val_loss: 1198.1985 - val_mae: 1198.1985 - lr: 0.0010\n",
      "Epoch 487/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.4432 - mae: 109.4432 - val_loss: 1209.5732 - val_mae: 1209.5732 - lr: 0.0010\n",
      "Epoch 488/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 107.8251 - mae: 107.8251 - val_loss: 1231.2401 - val_mae: 1231.2401 - lr: 0.0010\n",
      "Epoch 489/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 105.3262 - mae: 105.3262 - val_loss: 1236.5424 - val_mae: 1236.5424 - lr: 0.0010\n",
      "Epoch 490/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 102.8173 - mae: 102.8173 - val_loss: 1229.7646 - val_mae: 1229.7646 - lr: 0.0010\n",
      "Epoch 491/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 100.8288 - mae: 100.8288 - val_loss: 1213.9043 - val_mae: 1213.9043 - lr: 0.0010\n",
      "Epoch 492/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.9432 - mae: 109.9432 - val_loss: 1243.4406 - val_mae: 1243.4406 - lr: 0.0010\n",
      "Epoch 493/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 108.6620 - mae: 108.6620 - val_loss: 1227.2812 - val_mae: 1227.2812 - lr: 0.0010\n",
      "Epoch 494/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 112.0027 - mae: 112.0027 - val_loss: 1210.9208 - val_mae: 1210.9208 - lr: 0.0010\n",
      "Epoch 495/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 114.1000 - mae: 114.1000 - val_loss: 1219.4631 - val_mae: 1219.4631 - lr: 0.0010\n",
      "Epoch 496/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.7757 - mae: 108.7757 - val_loss: 1212.1929 - val_mae: 1212.1929 - lr: 0.0010\n",
      "Epoch 497/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 107.0627 - mae: 107.0627 - val_loss: 1195.9862 - val_mae: 1195.9862 - lr: 0.0010\n",
      "Epoch 498/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 109.3596 - mae: 109.3596 - val_loss: 1189.5739 - val_mae: 1189.5739 - lr: 0.0010\n",
      "Epoch 499/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.2362 - mae: 112.2362 - val_loss: 1234.8477 - val_mae: 1234.8477 - lr: 0.0010\n",
      "Epoch 500/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 123.2646 - mae: 123.2646 - val_loss: 1232.8153 - val_mae: 1232.8153 - lr: 0.0010\n",
      "Epoch 501/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 110.1025 - mae: 110.1025 - val_loss: 1211.0031 - val_mae: 1211.0031 - lr: 0.0010\n",
      "Epoch 502/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 110.6230 - mae: 110.6230 - val_loss: 1214.7543 - val_mae: 1214.7543 - lr: 0.0010\n",
      "Epoch 503/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 111.9242 - mae: 111.9242 - val_loss: 1224.0753 - val_mae: 1224.0753 - lr: 0.0010\n",
      "Epoch 504/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 122.8418 - mae: 122.8418 - val_loss: 1219.7930 - val_mae: 1219.7930 - lr: 0.0010\n",
      "Epoch 505/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.2716 - mae: 112.2716 - val_loss: 1219.8517 - val_mae: 1219.8518 - lr: 0.0010\n",
      "Epoch 506/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 104.4835 - mae: 104.4835 - val_loss: 1199.3413 - val_mae: 1199.3413 - lr: 0.0010\n",
      "Epoch 507/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 108.8578 - mae: 108.8578 - val_loss: 1247.8046 - val_mae: 1247.8046 - lr: 0.0010\n",
      "Epoch 508/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.6106 - mae: 106.6106 - val_loss: 1224.8346 - val_mae: 1224.8346 - lr: 0.0010\n",
      "Epoch 509/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.0101 - mae: 109.0101 - val_loss: 1211.6631 - val_mae: 1211.6631 - lr: 0.0010\n",
      "Epoch 510/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 106.4658 - mae: 106.4658 - val_loss: 1261.6080 - val_mae: 1261.6080 - lr: 0.0010\n",
      "Epoch 511/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 109.9396 - mae: 109.9396 - val_loss: 1219.6980 - val_mae: 1219.6980 - lr: 0.0010\n",
      "Epoch 512/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 109.3420 - mae: 109.3420 - val_loss: 1260.3954 - val_mae: 1260.3954 - lr: 0.0010\n",
      "Epoch 513/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 105.5090 - mae: 105.5090 - val_loss: 1250.4973 - val_mae: 1250.4973 - lr: 0.0010\n",
      "Epoch 514/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 106.6797 - mae: 106.6797 - val_loss: 1261.1628 - val_mae: 1261.1628 - lr: 0.0010\n",
      "Epoch 515/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 110.0002 - mae: 110.0002 - val_loss: 1257.0270 - val_mae: 1257.0270 - lr: 0.0010\n",
      "Epoch 516/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 106.8577 - mae: 106.8577 - val_loss: 1217.5715 - val_mae: 1217.5715 - lr: 0.0010\n",
      "Epoch 517/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 103.6596 - mae: 103.6596 - val_loss: 1248.3610 - val_mae: 1248.3610 - lr: 0.0010\n",
      "Epoch 518/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 104.1035 - mae: 104.1035 - val_loss: 1238.9861 - val_mae: 1238.9861 - lr: 0.0010\n",
      "Epoch 519/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 106.9305 - mae: 106.9305 - val_loss: 1262.9928 - val_mae: 1262.9928 - lr: 0.0010\n",
      "Epoch 520/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 111.3802 - mae: 111.3802 - val_loss: 1252.6685 - val_mae: 1252.6685 - lr: 0.0010\n",
      "Epoch 521/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 112.3023 - mae: 112.3023 - val_loss: 1217.7148 - val_mae: 1217.7148 - lr: 0.0010\n",
      "Epoch 522/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 115.3829 - mae: 115.3829 - val_loss: 1228.1490 - val_mae: 1228.1490 - lr: 0.0010\n",
      "Epoch 523/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 118.1088 - mae: 118.1088 - val_loss: 1187.4962 - val_mae: 1187.4962 - lr: 0.0010\n",
      "Epoch 524/2000\n",
      "21/22 [===========================>..] - ETA: 0s - loss: 101.9831 - mae: 101.9831INFO:tensorflow:Assets written to: modelos/n-beats/assets\n",
      "22/22 [==============================] - 16s 709ms/step - loss: 102.2605 - mae: 102.2605 - val_loss: 1166.3112 - val_mae: 1166.3112 - lr: 1.0000e-04\n",
      "Epoch 525/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 99.6698 - mae: 99.6698 - val_loss: 1171.9138 - val_mae: 1171.9138 - lr: 1.0000e-04\n",
      "Epoch 526/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 96.4575 - mae: 96.4575 - val_loss: 1167.0322 - val_mae: 1167.0322 - lr: 1.0000e-04\n",
      "Epoch 527/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 96.5507 - mae: 96.5507 - val_loss: 1176.9822 - val_mae: 1176.9822 - lr: 1.0000e-04\n",
      "Epoch 528/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 94.1921 - mae: 94.1921 - val_loss: 1170.5698 - val_mae: 1170.5698 - lr: 1.0000e-04\n",
      "Epoch 529/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 94.6306 - mae: 94.6306 - val_loss: 1181.8075 - val_mae: 1181.8075 - lr: 1.0000e-04\n",
      "Epoch 530/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 92.4988 - mae: 92.4988 - val_loss: 1173.6400 - val_mae: 1173.6400 - lr: 1.0000e-04\n",
      "Epoch 531/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 92.4876 - mae: 92.4876 - val_loss: 1185.3439 - val_mae: 1185.3439 - lr: 1.0000e-04\n",
      "Epoch 532/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 90.3559 - mae: 90.3559 - val_loss: 1176.4578 - val_mae: 1176.4578 - lr: 1.0000e-04\n",
      "Epoch 533/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 90.6057 - mae: 90.6057 - val_loss: 1188.6036 - val_mae: 1188.6036 - lr: 1.0000e-04\n",
      "Epoch 534/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 88.3556 - mae: 88.3556 - val_loss: 1178.0231 - val_mae: 1178.0231 - lr: 1.0000e-04\n",
      "Epoch 535/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 88.2875 - mae: 88.2875 - val_loss: 1189.6729 - val_mae: 1189.6729 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 536/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 86.1090 - mae: 86.1090 - val_loss: 1182.4249 - val_mae: 1182.4249 - lr: 1.0000e-04\n",
      "Epoch 537/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 85.6122 - mae: 85.6122 - val_loss: 1190.7903 - val_mae: 1190.7903 - lr: 1.0000e-04\n",
      "Epoch 538/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 84.2110 - mae: 84.2110 - val_loss: 1187.6501 - val_mae: 1187.6501 - lr: 1.0000e-04\n",
      "Epoch 539/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 83.3229 - mae: 83.3229 - val_loss: 1187.3350 - val_mae: 1187.3350 - lr: 1.0000e-04\n",
      "Epoch 540/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 82.8967 - mae: 82.8967 - val_loss: 1189.9965 - val_mae: 1189.9965 - lr: 1.0000e-04\n",
      "Epoch 541/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 82.2811 - mae: 82.2811 - val_loss: 1194.9510 - val_mae: 1194.9510 - lr: 1.0000e-04\n",
      "Epoch 542/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 81.8018 - mae: 81.8018 - val_loss: 1194.2393 - val_mae: 1194.2393 - lr: 1.0000e-04\n",
      "Epoch 543/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 80.9917 - mae: 80.9917 - val_loss: 1194.5538 - val_mae: 1194.5538 - lr: 1.0000e-04\n",
      "Epoch 544/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 80.8919 - mae: 80.8919 - val_loss: 1202.0668 - val_mae: 1202.0668 - lr: 1.0000e-04\n",
      "Epoch 545/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 81.1865 - mae: 81.1865 - val_loss: 1200.0315 - val_mae: 1200.0315 - lr: 1.0000e-04\n",
      "Epoch 546/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 79.7419 - mae: 79.7419 - val_loss: 1198.4619 - val_mae: 1198.4619 - lr: 1.0000e-04\n",
      "Epoch 547/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 79.6481 - mae: 79.6481 - val_loss: 1195.0192 - val_mae: 1195.0192 - lr: 1.0000e-04\n",
      "Epoch 548/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 80.2839 - mae: 80.2839 - val_loss: 1213.3181 - val_mae: 1213.3181 - lr: 1.0000e-04\n",
      "Epoch 549/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 78.5352 - mae: 78.5352 - val_loss: 1210.3716 - val_mae: 1210.3716 - lr: 1.0000e-04\n",
      "Epoch 550/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 79.1878 - mae: 79.1878 - val_loss: 1207.0333 - val_mae: 1207.0333 - lr: 1.0000e-04\n",
      "Epoch 551/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 79.3479 - mae: 79.3479 - val_loss: 1205.9641 - val_mae: 1205.9641 - lr: 1.0000e-04\n",
      "Epoch 552/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 79.8959 - mae: 79.8959 - val_loss: 1222.6539 - val_mae: 1222.6539 - lr: 1.0000e-04\n",
      "Epoch 553/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 77.4709 - mae: 77.4709 - val_loss: 1220.6400 - val_mae: 1220.6400 - lr: 1.0000e-04\n",
      "Epoch 554/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 77.6730 - mae: 77.6730 - val_loss: 1210.6635 - val_mae: 1210.6635 - lr: 1.0000e-04\n",
      "Epoch 555/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 78.9104 - mae: 78.9104 - val_loss: 1203.0258 - val_mae: 1203.0258 - lr: 1.0000e-04\n",
      "Epoch 556/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 76.6895 - mae: 76.6895 - val_loss: 1219.0518 - val_mae: 1219.0518 - lr: 1.0000e-04\n",
      "Epoch 557/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 74.5203 - mae: 74.5203 - val_loss: 1221.5977 - val_mae: 1221.5977 - lr: 1.0000e-04\n",
      "Epoch 558/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 76.6843 - mae: 76.6843 - val_loss: 1213.7552 - val_mae: 1213.7552 - lr: 1.0000e-04\n",
      "Epoch 559/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 74.1458 - mae: 74.1458 - val_loss: 1219.5299 - val_mae: 1219.5299 - lr: 1.0000e-04\n",
      "Epoch 560/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 75.8424 - mae: 75.8424 - val_loss: 1222.2563 - val_mae: 1222.2563 - lr: 1.0000e-04\n",
      "Epoch 561/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 73.5785 - mae: 73.5785 - val_loss: 1211.5715 - val_mae: 1211.5715 - lr: 1.0000e-04\n",
      "Epoch 562/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 74.4312 - mae: 74.4312 - val_loss: 1218.1434 - val_mae: 1218.1434 - lr: 1.0000e-04\n",
      "Epoch 563/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 75.1928 - mae: 75.1928 - val_loss: 1234.5217 - val_mae: 1234.5217 - lr: 1.0000e-04\n",
      "Epoch 564/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 71.8876 - mae: 71.8876 - val_loss: 1235.1628 - val_mae: 1235.1628 - lr: 1.0000e-04\n",
      "Epoch 565/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 72.8557 - mae: 72.8557 - val_loss: 1221.0121 - val_mae: 1221.0121 - lr: 1.0000e-04\n",
      "Epoch 566/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 71.9599 - mae: 71.9599 - val_loss: 1221.9745 - val_mae: 1221.9745 - lr: 1.0000e-04\n",
      "Epoch 567/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 71.5217 - mae: 71.5217 - val_loss: 1225.3357 - val_mae: 1225.3357 - lr: 1.0000e-04\n",
      "Epoch 568/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 71.3109 - mae: 71.3109 - val_loss: 1236.6807 - val_mae: 1236.6807 - lr: 1.0000e-04\n",
      "Epoch 569/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 70.8610 - mae: 70.8610 - val_loss: 1233.6891 - val_mae: 1233.6891 - lr: 1.0000e-04\n",
      "Epoch 570/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 70.7449 - mae: 70.7449 - val_loss: 1241.9313 - val_mae: 1241.9313 - lr: 1.0000e-04\n",
      "Epoch 571/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 69.6362 - mae: 69.6362 - val_loss: 1229.7725 - val_mae: 1229.7725 - lr: 1.0000e-04\n",
      "Epoch 572/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 71.0093 - mae: 71.0093 - val_loss: 1228.0042 - val_mae: 1228.0042 - lr: 1.0000e-04\n",
      "Epoch 573/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 70.3255 - mae: 70.3255 - val_loss: 1236.4253 - val_mae: 1236.4253 - lr: 1.0000e-04\n",
      "Epoch 574/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 73.3359 - mae: 73.3359 - val_loss: 1246.9487 - val_mae: 1246.9487 - lr: 1.0000e-04\n",
      "Epoch 575/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 69.3854 - mae: 69.3854 - val_loss: 1241.7457 - val_mae: 1241.7457 - lr: 1.0000e-04\n",
      "Epoch 576/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 71.3861 - mae: 71.3861 - val_loss: 1242.1553 - val_mae: 1242.1553 - lr: 1.0000e-04\n",
      "Epoch 577/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 69.1583 - mae: 69.1583 - val_loss: 1250.6740 - val_mae: 1250.6740 - lr: 1.0000e-04\n",
      "Epoch 578/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 69.4836 - mae: 69.4836 - val_loss: 1252.3215 - val_mae: 1252.3215 - lr: 1.0000e-04\n",
      "Epoch 579/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 70.0071 - mae: 70.0071 - val_loss: 1250.7476 - val_mae: 1250.7476 - lr: 1.0000e-04\n",
      "Epoch 580/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 70.1881 - mae: 70.1881 - val_loss: 1237.1433 - val_mae: 1237.1433 - lr: 1.0000e-04\n",
      "Epoch 581/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 70.4848 - mae: 70.4848 - val_loss: 1257.4078 - val_mae: 1257.4078 - lr: 1.0000e-04\n",
      "Epoch 582/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 69.6292 - mae: 69.6292 - val_loss: 1268.4979 - val_mae: 1268.4979 - lr: 1.0000e-04\n",
      "Epoch 583/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 67.4183 - mae: 67.4183 - val_loss: 1247.8190 - val_mae: 1247.8190 - lr: 1.0000e-04\n",
      "Epoch 584/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 66.5755 - mae: 66.5755 - val_loss: 1245.6726 - val_mae: 1245.6726 - lr: 1.0000e-04\n",
      "Epoch 585/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 64.6942 - mae: 64.6942 - val_loss: 1259.4487 - val_mae: 1259.4487 - lr: 1.0000e-04\n",
      "Epoch 586/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 66.3091 - mae: 66.3091 - val_loss: 1284.7788 - val_mae: 1284.7788 - lr: 1.0000e-04\n",
      "Epoch 587/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 24ms/step - loss: 65.4247 - mae: 65.4247 - val_loss: 1269.6471 - val_mae: 1269.6471 - lr: 1.0000e-04\n",
      "Epoch 588/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 65.1624 - mae: 65.1624 - val_loss: 1260.9552 - val_mae: 1260.9552 - lr: 1.0000e-04\n",
      "Epoch 589/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 66.6064 - mae: 66.6064 - val_loss: 1258.1600 - val_mae: 1258.1600 - lr: 1.0000e-04\n",
      "Epoch 590/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 64.4171 - mae: 64.4171 - val_loss: 1264.1448 - val_mae: 1264.1448 - lr: 1.0000e-04\n",
      "Epoch 591/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 61.8729 - mae: 61.8729 - val_loss: 1271.7742 - val_mae: 1271.7742 - lr: 1.0000e-04\n",
      "Epoch 592/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 63.9974 - mae: 63.9974 - val_loss: 1277.0846 - val_mae: 1277.0846 - lr: 1.0000e-04\n",
      "Epoch 593/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 61.6853 - mae: 61.6853 - val_loss: 1265.0598 - val_mae: 1265.0598 - lr: 1.0000e-04\n",
      "Epoch 594/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 62.3654 - mae: 62.3654 - val_loss: 1269.1932 - val_mae: 1269.1932 - lr: 1.0000e-04\n",
      "Epoch 595/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 59.1075 - mae: 59.1075 - val_loss: 1272.4894 - val_mae: 1272.4894 - lr: 1.0000e-04\n",
      "Epoch 596/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 62.3454 - mae: 62.3454 - val_loss: 1288.0281 - val_mae: 1288.0281 - lr: 1.0000e-04\n",
      "Epoch 597/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 59.6055 - mae: 59.6055 - val_loss: 1278.9535 - val_mae: 1278.9535 - lr: 1.0000e-04\n",
      "Epoch 598/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 59.2712 - mae: 59.2712 - val_loss: 1287.7418 - val_mae: 1287.7418 - lr: 1.0000e-04\n",
      "Epoch 599/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 59.9811 - mae: 59.9811 - val_loss: 1287.5818 - val_mae: 1287.5818 - lr: 1.0000e-04\n",
      "Epoch 600/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 59.1035 - mae: 59.1035 - val_loss: 1286.5432 - val_mae: 1286.5432 - lr: 1.0000e-04\n",
      "Epoch 601/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 61.3941 - mae: 61.3941 - val_loss: 1288.9928 - val_mae: 1288.9928 - lr: 1.0000e-04\n",
      "Epoch 602/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 67.1934 - mae: 67.1934 - val_loss: 1314.8335 - val_mae: 1314.8335 - lr: 1.0000e-04\n",
      "Epoch 603/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 62.7657 - mae: 62.7657 - val_loss: 1295.3323 - val_mae: 1295.3323 - lr: 1.0000e-04\n",
      "Epoch 604/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 58.5391 - mae: 58.5391 - val_loss: 1283.6143 - val_mae: 1283.6143 - lr: 1.0000e-04\n",
      "Epoch 605/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 58.9092 - mae: 58.9092 - val_loss: 1298.4243 - val_mae: 1298.4243 - lr: 1.0000e-04\n",
      "Epoch 606/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 61.8509 - mae: 61.8509 - val_loss: 1305.1907 - val_mae: 1305.1907 - lr: 1.0000e-04\n",
      "Epoch 607/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 65.4567 - mae: 65.4567 - val_loss: 1312.0873 - val_mae: 1312.0873 - lr: 1.0000e-04\n",
      "Epoch 608/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 59.8491 - mae: 59.8491 - val_loss: 1296.7908 - val_mae: 1296.7908 - lr: 1.0000e-04\n",
      "Epoch 609/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 60.0884 - mae: 60.0884 - val_loss: 1293.8619 - val_mae: 1293.8619 - lr: 1.0000e-04\n",
      "Epoch 610/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 60.2565 - mae: 60.2565 - val_loss: 1303.6494 - val_mae: 1303.6494 - lr: 1.0000e-04\n",
      "Epoch 611/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 58.0232 - mae: 58.0232 - val_loss: 1314.2863 - val_mae: 1314.2863 - lr: 1.0000e-04\n",
      "Epoch 612/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 61.6480 - mae: 61.6480 - val_loss: 1314.0327 - val_mae: 1314.0327 - lr: 1.0000e-04\n",
      "Epoch 613/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 58.6364 - mae: 58.6364 - val_loss: 1333.1938 - val_mae: 1333.1938 - lr: 1.0000e-04\n",
      "Epoch 614/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 59.5999 - mae: 59.5999 - val_loss: 1304.5911 - val_mae: 1304.5911 - lr: 1.0000e-04\n",
      "Epoch 615/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 60.6790 - mae: 60.6790 - val_loss: 1300.0575 - val_mae: 1300.0575 - lr: 1.0000e-04\n",
      "Epoch 616/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 64.2533 - mae: 64.2533 - val_loss: 1309.8055 - val_mae: 1309.8055 - lr: 1.0000e-04\n",
      "Epoch 617/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 72.7813 - mae: 72.7813 - val_loss: 1312.0037 - val_mae: 1312.0037 - lr: 1.0000e-04\n",
      "Epoch 618/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 70.3906 - mae: 70.3906 - val_loss: 1295.0822 - val_mae: 1295.0822 - lr: 1.0000e-04\n",
      "Epoch 619/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 70.5881 - mae: 70.5881 - val_loss: 1305.3094 - val_mae: 1305.3094 - lr: 1.0000e-04\n",
      "Epoch 620/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 63.2582 - mae: 63.2582 - val_loss: 1299.1753 - val_mae: 1299.1753 - lr: 1.0000e-04\n",
      "Epoch 621/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 59.1213 - mae: 59.1213 - val_loss: 1316.7036 - val_mae: 1316.7036 - lr: 1.0000e-04\n",
      "Epoch 622/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 56.7984 - mae: 56.7984 - val_loss: 1318.4482 - val_mae: 1318.4482 - lr: 1.0000e-04\n",
      "Epoch 623/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 54.7392 - mae: 54.7392 - val_loss: 1317.5916 - val_mae: 1317.5916 - lr: 1.0000e-04\n",
      "Epoch 624/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 55.1707 - mae: 55.1707 - val_loss: 1313.4534 - val_mae: 1313.4534 - lr: 1.0000e-04\n",
      "Epoch 625/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 50.0854 - mae: 50.0854 - val_loss: 1315.9965 - val_mae: 1315.9965 - lr: 1.0000e-05\n",
      "Epoch 626/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 47.8551 - mae: 47.8551 - val_loss: 1315.3678 - val_mae: 1315.3678 - lr: 1.0000e-05\n",
      "Epoch 627/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 47.0364 - mae: 47.0364 - val_loss: 1318.1180 - val_mae: 1318.1180 - lr: 1.0000e-05\n",
      "Epoch 628/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 46.5684 - mae: 46.5684 - val_loss: 1320.0461 - val_mae: 1320.0461 - lr: 1.0000e-05\n",
      "Epoch 629/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 46.1982 - mae: 46.1982 - val_loss: 1320.8235 - val_mae: 1320.8235 - lr: 1.0000e-05\n",
      "Epoch 630/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 45.9030 - mae: 45.9030 - val_loss: 1321.7352 - val_mae: 1321.7352 - lr: 1.0000e-05\n",
      "Epoch 631/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 45.6513 - mae: 45.6513 - val_loss: 1322.3519 - val_mae: 1322.3519 - lr: 1.0000e-05\n",
      "Epoch 632/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 45.4226 - mae: 45.4226 - val_loss: 1322.9559 - val_mae: 1322.9559 - lr: 1.0000e-05\n",
      "Epoch 633/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 45.2302 - mae: 45.2302 - val_loss: 1323.7577 - val_mae: 1323.7577 - lr: 1.0000e-05\n",
      "Epoch 634/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 45.0440 - mae: 45.0440 - val_loss: 1324.1104 - val_mae: 1324.1104 - lr: 1.0000e-05\n",
      "Epoch 635/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 44.8700 - mae: 44.8700 - val_loss: 1324.6847 - val_mae: 1324.6847 - lr: 1.0000e-05\n",
      "Epoch 636/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 44.6993 - mae: 44.6993 - val_loss: 1325.3796 - val_mae: 1325.3796 - lr: 1.0000e-05\n",
      "Epoch 637/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 44.5467 - mae: 44.5467 - val_loss: 1325.3600 - val_mae: 1325.3600 - lr: 1.0000e-05\n",
      "Epoch 638/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 25ms/step - loss: 44.4217 - mae: 44.4217 - val_loss: 1326.1345 - val_mae: 1326.1345 - lr: 1.0000e-05\n",
      "Epoch 639/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 44.3121 - mae: 44.3121 - val_loss: 1326.4191 - val_mae: 1326.4191 - lr: 1.0000e-05\n",
      "Epoch 640/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 44.2339 - mae: 44.2339 - val_loss: 1326.8132 - val_mae: 1326.8132 - lr: 1.0000e-05\n",
      "Epoch 641/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 44.1868 - mae: 44.1868 - val_loss: 1327.0028 - val_mae: 1327.0028 - lr: 1.0000e-05\n",
      "Epoch 642/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 44.1405 - mae: 44.1405 - val_loss: 1327.6920 - val_mae: 1327.6920 - lr: 1.0000e-05\n",
      "Epoch 643/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 44.0778 - mae: 44.0778 - val_loss: 1327.5575 - val_mae: 1327.5575 - lr: 1.0000e-05\n",
      "Epoch 644/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.9952 - mae: 43.9952 - val_loss: 1328.8217 - val_mae: 1328.8217 - lr: 1.0000e-05\n",
      "Epoch 645/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 43.9034 - mae: 43.9034 - val_loss: 1328.0657 - val_mae: 1328.0657 - lr: 1.0000e-05\n",
      "Epoch 646/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.8128 - mae: 43.8128 - val_loss: 1329.6758 - val_mae: 1329.6758 - lr: 1.0000e-05\n",
      "Epoch 647/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.8253 - mae: 43.8253 - val_loss: 1329.4705 - val_mae: 1329.4705 - lr: 1.0000e-05\n",
      "Epoch 648/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 43.8132 - mae: 43.8132 - val_loss: 1330.8766 - val_mae: 1330.8766 - lr: 1.0000e-05\n",
      "Epoch 649/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.8737 - mae: 43.8737 - val_loss: 1329.9858 - val_mae: 1329.9858 - lr: 1.0000e-05\n",
      "Epoch 650/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.8584 - mae: 43.8584 - val_loss: 1332.1602 - val_mae: 1332.1602 - lr: 1.0000e-05\n",
      "Epoch 651/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.9125 - mae: 43.9125 - val_loss: 1330.4513 - val_mae: 1330.4513 - lr: 1.0000e-05\n",
      "Epoch 652/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 43.8276 - mae: 43.8276 - val_loss: 1333.1162 - val_mae: 1333.1162 - lr: 1.0000e-05\n",
      "Epoch 653/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.8406 - mae: 43.8406 - val_loss: 1330.8591 - val_mae: 1330.8591 - lr: 1.0000e-05\n",
      "Epoch 654/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.6176 - mae: 43.6176 - val_loss: 1334.3867 - val_mae: 1334.3867 - lr: 1.0000e-05\n",
      "Epoch 655/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.5475 - mae: 43.5475 - val_loss: 1332.2443 - val_mae: 1332.2443 - lr: 1.0000e-05\n",
      "Epoch 656/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.3980 - mae: 43.3980 - val_loss: 1334.8875 - val_mae: 1334.8875 - lr: 1.0000e-05\n",
      "Epoch 657/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.2511 - mae: 43.2511 - val_loss: 1333.2107 - val_mae: 1333.2107 - lr: 1.0000e-05\n",
      "Epoch 658/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.1537 - mae: 43.1537 - val_loss: 1335.8903 - val_mae: 1335.8903 - lr: 1.0000e-05\n",
      "Epoch 659/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.0359 - mae: 43.0359 - val_loss: 1334.2839 - val_mae: 1334.2839 - lr: 1.0000e-05\n",
      "Epoch 660/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.9646 - mae: 42.9646 - val_loss: 1336.3008 - val_mae: 1336.3008 - lr: 1.0000e-05\n",
      "Epoch 661/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.8825 - mae: 42.8825 - val_loss: 1334.9329 - val_mae: 1334.9329 - lr: 1.0000e-05\n",
      "Epoch 662/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.8157 - mae: 42.8157 - val_loss: 1336.8718 - val_mae: 1336.8718 - lr: 1.0000e-05\n",
      "Epoch 663/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.7442 - mae: 42.7442 - val_loss: 1335.6000 - val_mae: 1335.6000 - lr: 1.0000e-05\n",
      "Epoch 664/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.7880 - mae: 42.7880 - val_loss: 1337.2758 - val_mae: 1337.2758 - lr: 1.0000e-05\n",
      "Epoch 665/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.7688 - mae: 42.7688 - val_loss: 1336.2209 - val_mae: 1336.2209 - lr: 1.0000e-05\n",
      "Epoch 666/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.0172 - mae: 43.0172 - val_loss: 1338.5356 - val_mae: 1338.5356 - lr: 1.0000e-05\n",
      "Epoch 667/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 43.0171 - mae: 43.0171 - val_loss: 1336.3569 - val_mae: 1336.3569 - lr: 1.0000e-05\n",
      "Epoch 668/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 42.8634 - mae: 42.8634 - val_loss: 1339.3949 - val_mae: 1339.3949 - lr: 1.0000e-05\n",
      "Epoch 669/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 42.7132 - mae: 42.7132 - val_loss: 1336.9883 - val_mae: 1336.9883 - lr: 1.0000e-05\n",
      "Epoch 670/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.6488 - mae: 42.6488 - val_loss: 1340.5811 - val_mae: 1340.5811 - lr: 1.0000e-05\n",
      "Epoch 671/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.5070 - mae: 42.5070 - val_loss: 1337.5994 - val_mae: 1337.5994 - lr: 1.0000e-05\n",
      "Epoch 672/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.4484 - mae: 42.4484 - val_loss: 1341.0281 - val_mae: 1341.0281 - lr: 1.0000e-05\n",
      "Epoch 673/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.2762 - mae: 42.2762 - val_loss: 1339.1006 - val_mae: 1339.1006 - lr: 1.0000e-05\n",
      "Epoch 674/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 42.0886 - mae: 42.0886 - val_loss: 1342.0037 - val_mae: 1342.0037 - lr: 1.0000e-05\n",
      "Epoch 675/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 41.9200 - mae: 41.9200 - val_loss: 1340.7081 - val_mae: 1340.7081 - lr: 1.0000e-05\n",
      "Epoch 676/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.8100 - mae: 41.8100 - val_loss: 1343.3712 - val_mae: 1343.3712 - lr: 1.0000e-05\n",
      "Epoch 677/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.7094 - mae: 41.7094 - val_loss: 1341.7424 - val_mae: 1341.7424 - lr: 1.0000e-05\n",
      "Epoch 678/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 41.6693 - mae: 41.6693 - val_loss: 1344.0753 - val_mae: 1344.0753 - lr: 1.0000e-05\n",
      "Epoch 679/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.5067 - mae: 41.5067 - val_loss: 1342.7806 - val_mae: 1342.7806 - lr: 1.0000e-05\n",
      "Epoch 680/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 41.4605 - mae: 41.4605 - val_loss: 1344.8480 - val_mae: 1344.8480 - lr: 1.0000e-05\n",
      "Epoch 681/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.3697 - mae: 41.3697 - val_loss: 1343.6100 - val_mae: 1343.6100 - lr: 1.0000e-05\n",
      "Epoch 682/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.4385 - mae: 41.4385 - val_loss: 1345.1691 - val_mae: 1345.1691 - lr: 1.0000e-05\n",
      "Epoch 683/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.3952 - mae: 41.3952 - val_loss: 1344.5731 - val_mae: 1344.5731 - lr: 1.0000e-05\n",
      "Epoch 684/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.4901 - mae: 41.4901 - val_loss: 1344.6178 - val_mae: 1344.6178 - lr: 1.0000e-05\n",
      "Epoch 685/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.4220 - mae: 41.4220 - val_loss: 1345.8014 - val_mae: 1345.8014 - lr: 1.0000e-05\n",
      "Epoch 686/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.4625 - mae: 41.4625 - val_loss: 1344.3737 - val_mae: 1344.3737 - lr: 1.0000e-05\n",
      "Epoch 687/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 41.3740 - mae: 41.3740 - val_loss: 1346.3354 - val_mae: 1346.3354 - lr: 1.0000e-05\n",
      "Epoch 688/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.4287 - mae: 41.4287 - val_loss: 1344.3944 - val_mae: 1344.3944 - lr: 1.0000e-05\n",
      "Epoch 689/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 25ms/step - loss: 41.3335 - mae: 41.3335 - val_loss: 1347.1713 - val_mae: 1347.1713 - lr: 1.0000e-05\n",
      "Epoch 690/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 41.3124 - mae: 41.3124 - val_loss: 1343.9607 - val_mae: 1343.9607 - lr: 1.0000e-05\n",
      "Epoch 691/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.0797 - mae: 41.0797 - val_loss: 1347.5793 - val_mae: 1347.5793 - lr: 1.0000e-05\n",
      "Epoch 692/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 41.0770 - mae: 41.0770 - val_loss: 1344.3783 - val_mae: 1344.3783 - lr: 1.0000e-05\n",
      "Epoch 693/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 40.8466 - mae: 40.8466 - val_loss: 1347.7701 - val_mae: 1347.7701 - lr: 1.0000e-05\n",
      "Epoch 694/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 40.8237 - mae: 40.8237 - val_loss: 1344.6699 - val_mae: 1344.6699 - lr: 1.0000e-05\n",
      "Epoch 695/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 40.5274 - mae: 40.5274 - val_loss: 1348.0623 - val_mae: 1348.0623 - lr: 1.0000e-05\n",
      "Epoch 696/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 40.4893 - mae: 40.4893 - val_loss: 1345.8925 - val_mae: 1345.8925 - lr: 1.0000e-05\n",
      "Epoch 697/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 40.2237 - mae: 40.2237 - val_loss: 1348.6057 - val_mae: 1348.6057 - lr: 1.0000e-05\n",
      "Epoch 698/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 40.2132 - mae: 40.2132 - val_loss: 1346.6580 - val_mae: 1346.6580 - lr: 1.0000e-05\n",
      "Epoch 699/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 39.9596 - mae: 39.9596 - val_loss: 1349.2891 - val_mae: 1349.2891 - lr: 1.0000e-05\n",
      "Epoch 700/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.9744 - mae: 39.9744 - val_loss: 1347.7568 - val_mae: 1347.7568 - lr: 1.0000e-05\n",
      "Epoch 701/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.8362 - mae: 39.8362 - val_loss: 1349.7925 - val_mae: 1349.7925 - lr: 1.0000e-05\n",
      "Epoch 702/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.8504 - mae: 39.8504 - val_loss: 1348.3164 - val_mae: 1348.3164 - lr: 1.0000e-05\n",
      "Epoch 703/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.8268 - mae: 39.8268 - val_loss: 1350.0321 - val_mae: 1350.0321 - lr: 1.0000e-05\n",
      "Epoch 704/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.9792 - mae: 39.9792 - val_loss: 1349.2570 - val_mae: 1349.2570 - lr: 1.0000e-05\n",
      "Epoch 705/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 40.0102 - mae: 40.0102 - val_loss: 1351.1117 - val_mae: 1351.1117 - lr: 1.0000e-05\n",
      "Epoch 706/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 40.1576 - mae: 40.1576 - val_loss: 1350.1346 - val_mae: 1350.1346 - lr: 1.0000e-05\n",
      "Epoch 707/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 40.1691 - mae: 40.1691 - val_loss: 1352.9667 - val_mae: 1352.9667 - lr: 1.0000e-05\n",
      "Epoch 708/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 40.0201 - mae: 40.0201 - val_loss: 1350.6973 - val_mae: 1350.6973 - lr: 1.0000e-05\n",
      "Epoch 709/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 39.8429 - mae: 39.8429 - val_loss: 1353.7245 - val_mae: 1353.7245 - lr: 1.0000e-05\n",
      "Epoch 710/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.6722 - mae: 39.6722 - val_loss: 1351.5133 - val_mae: 1351.5133 - lr: 1.0000e-05\n",
      "Epoch 711/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.4955 - mae: 39.4955 - val_loss: 1354.4176 - val_mae: 1354.4176 - lr: 1.0000e-05\n",
      "Epoch 712/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.3374 - mae: 39.3374 - val_loss: 1351.8723 - val_mae: 1351.8723 - lr: 1.0000e-05\n",
      "Epoch 713/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.1565 - mae: 39.1565 - val_loss: 1354.3347 - val_mae: 1354.3347 - lr: 1.0000e-05\n",
      "Epoch 714/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.0281 - mae: 39.0281 - val_loss: 1352.0327 - val_mae: 1352.0327 - lr: 1.0000e-05\n",
      "Epoch 715/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 38.9497 - mae: 38.9497 - val_loss: 1354.6575 - val_mae: 1354.6575 - lr: 1.0000e-05\n",
      "Epoch 716/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 38.9341 - mae: 38.9341 - val_loss: 1352.7260 - val_mae: 1352.7260 - lr: 1.0000e-05\n",
      "Epoch 717/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 38.8498 - mae: 38.8498 - val_loss: 1354.2346 - val_mae: 1354.2346 - lr: 1.0000e-05\n",
      "Epoch 718/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 38.8800 - mae: 38.8800 - val_loss: 1353.1194 - val_mae: 1353.1194 - lr: 1.0000e-05\n",
      "Epoch 719/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 38.8753 - mae: 38.8753 - val_loss: 1354.5419 - val_mae: 1354.5419 - lr: 1.0000e-05\n",
      "Epoch 720/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.0326 - mae: 39.0326 - val_loss: 1353.3636 - val_mae: 1353.3636 - lr: 1.0000e-05\n",
      "Epoch 721/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.2561 - mae: 39.2561 - val_loss: 1354.3383 - val_mae: 1354.3383 - lr: 1.0000e-05\n",
      "Epoch 722/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.4702 - mae: 39.4702 - val_loss: 1354.8781 - val_mae: 1354.8781 - lr: 1.0000e-05\n",
      "Epoch 723/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.5645 - mae: 39.5645 - val_loss: 1353.9539 - val_mae: 1353.9539 - lr: 1.0000e-05\n",
      "Epoch 724/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 39.4876 - mae: 39.4876 - val_loss: 1356.7147 - val_mae: 1356.7147 - lr: 1.0000e-05\n",
      "Epoch 725/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.7506 - mae: 37.7506 - val_loss: 1355.7925 - val_mae: 1355.7925 - lr: 1.0000e-06\n",
      "Epoch 726/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.6504 - mae: 37.6504 - val_loss: 1355.6599 - val_mae: 1355.6599 - lr: 1.0000e-06\n",
      "Epoch 727/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.6113 - mae: 37.6113 - val_loss: 1355.8337 - val_mae: 1355.8337 - lr: 1.0000e-06\n",
      "Epoch 728/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.5860 - mae: 37.5860 - val_loss: 1355.9957 - val_mae: 1355.9957 - lr: 1.0000e-06\n",
      "Epoch 729/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.5653 - mae: 37.5653 - val_loss: 1356.0797 - val_mae: 1356.0797 - lr: 1.0000e-06\n",
      "Epoch 730/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.5470 - mae: 37.5470 - val_loss: 1356.1569 - val_mae: 1356.1569 - lr: 1.0000e-06\n",
      "Epoch 731/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.5300 - mae: 37.5300 - val_loss: 1356.2279 - val_mae: 1356.2279 - lr: 1.0000e-06\n",
      "Epoch 732/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.5138 - mae: 37.5138 - val_loss: 1356.3230 - val_mae: 1356.3230 - lr: 1.0000e-06\n",
      "Epoch 733/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.4980 - mae: 37.4980 - val_loss: 1356.3625 - val_mae: 1356.3625 - lr: 1.0000e-06\n",
      "Epoch 734/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.4839 - mae: 37.4839 - val_loss: 1356.4423 - val_mae: 1356.4423 - lr: 1.0000e-06\n",
      "Epoch 735/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.4690 - mae: 37.4690 - val_loss: 1356.5010 - val_mae: 1356.5010 - lr: 1.0000e-06\n",
      "Epoch 736/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.4563 - mae: 37.4563 - val_loss: 1356.5533 - val_mae: 1356.5533 - lr: 1.0000e-06\n",
      "Epoch 737/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.4424 - mae: 37.4424 - val_loss: 1356.6205 - val_mae: 1356.6205 - lr: 1.0000e-06\n",
      "Epoch 738/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.4301 - mae: 37.4301 - val_loss: 1356.6356 - val_mae: 1356.6356 - lr: 1.0000e-06\n",
      "Epoch 739/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.4166 - mae: 37.4166 - val_loss: 1356.7015 - val_mae: 1356.7015 - lr: 1.0000e-06\n",
      "Epoch 740/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 25ms/step - loss: 37.4046 - mae: 37.4046 - val_loss: 1356.7670 - val_mae: 1356.7670 - lr: 1.0000e-06\n",
      "Epoch 741/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.3929 - mae: 37.3929 - val_loss: 1356.8049 - val_mae: 1356.8049 - lr: 1.0000e-06\n",
      "Epoch 742/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.3803 - mae: 37.3803 - val_loss: 1356.8845 - val_mae: 1356.8845 - lr: 1.0000e-06\n",
      "Epoch 743/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.3696 - mae: 37.3696 - val_loss: 1356.8735 - val_mae: 1356.8735 - lr: 1.0000e-06\n",
      "Epoch 744/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.3588 - mae: 37.3588 - val_loss: 1356.9963 - val_mae: 1356.9963 - lr: 1.0000e-06\n",
      "Epoch 745/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.3474 - mae: 37.3474 - val_loss: 1357.0159 - val_mae: 1357.0159 - lr: 1.0000e-06\n",
      "Epoch 746/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.3353 - mae: 37.3353 - val_loss: 1357.0815 - val_mae: 1357.0815 - lr: 1.0000e-06\n",
      "Epoch 747/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.3244 - mae: 37.3244 - val_loss: 1357.0930 - val_mae: 1357.0930 - lr: 1.0000e-06\n",
      "Epoch 748/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.3143 - mae: 37.3143 - val_loss: 1357.1509 - val_mae: 1357.1509 - lr: 1.0000e-06\n",
      "Epoch 749/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.3038 - mae: 37.3038 - val_loss: 1357.2333 - val_mae: 1357.2333 - lr: 1.0000e-06\n",
      "Epoch 750/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.2924 - mae: 37.2924 - val_loss: 1357.2159 - val_mae: 1357.2159 - lr: 1.0000e-06\n",
      "Epoch 751/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.2829 - mae: 37.2829 - val_loss: 1357.2727 - val_mae: 1357.2727 - lr: 1.0000e-06\n",
      "Epoch 752/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.2703 - mae: 37.2703 - val_loss: 1357.3217 - val_mae: 1357.3217 - lr: 1.0000e-06\n",
      "Epoch 753/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.2607 - mae: 37.2607 - val_loss: 1357.3851 - val_mae: 1357.3851 - lr: 1.0000e-06\n",
      "Epoch 754/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.2501 - mae: 37.2501 - val_loss: 1357.4441 - val_mae: 1357.4441 - lr: 1.0000e-06\n",
      "Epoch 755/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.2422 - mae: 37.2422 - val_loss: 1357.5387 - val_mae: 1357.5387 - lr: 1.0000e-06\n",
      "Epoch 756/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.2333 - mae: 37.2333 - val_loss: 1357.5061 - val_mae: 1357.5061 - lr: 1.0000e-06\n",
      "Epoch 757/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.2238 - mae: 37.2238 - val_loss: 1357.6482 - val_mae: 1357.6482 - lr: 1.0000e-06\n",
      "Epoch 758/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.2125 - mae: 37.2125 - val_loss: 1357.6327 - val_mae: 1357.6327 - lr: 1.0000e-06\n",
      "Epoch 759/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.2055 - mae: 37.2055 - val_loss: 1357.7402 - val_mae: 1357.7402 - lr: 1.0000e-06\n",
      "Epoch 760/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.1961 - mae: 37.1961 - val_loss: 1357.6921 - val_mae: 1357.6921 - lr: 1.0000e-06\n",
      "Epoch 761/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.1881 - mae: 37.1881 - val_loss: 1357.8479 - val_mae: 1357.8479 - lr: 1.0000e-06\n",
      "Epoch 762/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.1759 - mae: 37.1759 - val_loss: 1357.7732 - val_mae: 1357.7732 - lr: 1.0000e-06\n",
      "Epoch 763/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.1673 - mae: 37.1673 - val_loss: 1357.9041 - val_mae: 1357.9041 - lr: 1.0000e-06\n",
      "Epoch 764/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.1567 - mae: 37.1567 - val_loss: 1357.8866 - val_mae: 1357.8866 - lr: 1.0000e-06\n",
      "Epoch 765/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.1482 - mae: 37.1482 - val_loss: 1357.9631 - val_mae: 1357.9631 - lr: 1.0000e-06\n",
      "Epoch 766/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.1383 - mae: 37.1383 - val_loss: 1358.0321 - val_mae: 1358.0321 - lr: 1.0000e-06\n",
      "Epoch 767/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.1266 - mae: 37.1266 - val_loss: 1358.0844 - val_mae: 1358.0844 - lr: 1.0000e-06\n",
      "Epoch 768/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.1149 - mae: 37.1149 - val_loss: 1358.0873 - val_mae: 1358.0873 - lr: 1.0000e-06\n",
      "Epoch 769/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.1063 - mae: 37.1063 - val_loss: 1358.1464 - val_mae: 1358.1464 - lr: 1.0000e-06\n",
      "Epoch 770/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.0948 - mae: 37.0948 - val_loss: 1358.2560 - val_mae: 1358.2560 - lr: 1.0000e-06\n",
      "Epoch 771/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.0870 - mae: 37.0870 - val_loss: 1358.3306 - val_mae: 1358.3306 - lr: 1.0000e-06\n",
      "Epoch 772/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.0784 - mae: 37.0784 - val_loss: 1358.3080 - val_mae: 1358.3080 - lr: 1.0000e-06\n",
      "Epoch 773/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.0712 - mae: 37.0712 - val_loss: 1358.3918 - val_mae: 1358.3918 - lr: 1.0000e-06\n",
      "Epoch 774/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.0577 - mae: 37.0577 - val_loss: 1358.3881 - val_mae: 1358.3881 - lr: 1.0000e-06\n",
      "Epoch 775/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.0497 - mae: 37.0497 - val_loss: 1358.5033 - val_mae: 1358.5033 - lr: 1.0000e-06\n",
      "Epoch 776/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.0376 - mae: 37.0376 - val_loss: 1358.5114 - val_mae: 1358.5114 - lr: 1.0000e-06\n",
      "Epoch 777/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 37.0290 - mae: 37.0290 - val_loss: 1358.6566 - val_mae: 1358.6566 - lr: 1.0000e-06\n",
      "Epoch 778/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.0167 - mae: 37.0167 - val_loss: 1358.5696 - val_mae: 1358.5696 - lr: 1.0000e-06\n",
      "Epoch 779/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 37.0083 - mae: 37.0083 - val_loss: 1358.7593 - val_mae: 1358.7593 - lr: 1.0000e-06\n",
      "Epoch 780/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.9951 - mae: 36.9951 - val_loss: 1358.6874 - val_mae: 1358.6874 - lr: 1.0000e-06\n",
      "Epoch 781/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.9880 - mae: 36.9880 - val_loss: 1358.8669 - val_mae: 1358.8669 - lr: 1.0000e-06\n",
      "Epoch 782/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.9741 - mae: 36.9741 - val_loss: 1358.7855 - val_mae: 1358.7855 - lr: 1.0000e-06\n",
      "Epoch 783/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.9654 - mae: 36.9654 - val_loss: 1358.9154 - val_mae: 1358.9154 - lr: 1.0000e-06\n",
      "Epoch 784/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.9542 - mae: 36.9542 - val_loss: 1358.9630 - val_mae: 1358.9630 - lr: 1.0000e-06\n",
      "Epoch 785/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.9467 - mae: 36.9467 - val_loss: 1359.0695 - val_mae: 1359.0695 - lr: 1.0000e-06\n",
      "Epoch 786/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.9436 - mae: 36.9436 - val_loss: 1358.9507 - val_mae: 1358.9507 - lr: 1.0000e-06\n",
      "Epoch 787/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.9360 - mae: 36.9360 - val_loss: 1359.1211 - val_mae: 1359.1211 - lr: 1.0000e-06\n",
      "Epoch 788/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.9243 - mae: 36.9243 - val_loss: 1359.0084 - val_mae: 1359.0084 - lr: 1.0000e-06\n",
      "Epoch 789/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.9158 - mae: 36.9158 - val_loss: 1359.1797 - val_mae: 1359.1797 - lr: 1.0000e-06\n",
      "Epoch 790/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.9051 - mae: 36.9051 - val_loss: 1359.1118 - val_mae: 1359.1118 - lr: 1.0000e-06\n",
      "Epoch 791/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 25ms/step - loss: 36.8950 - mae: 36.8950 - val_loss: 1359.2953 - val_mae: 1359.2953 - lr: 1.0000e-06\n",
      "Epoch 792/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.8839 - mae: 36.8839 - val_loss: 1359.2207 - val_mae: 1359.2207 - lr: 1.0000e-06\n",
      "Epoch 793/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.8745 - mae: 36.8745 - val_loss: 1359.3978 - val_mae: 1359.3978 - lr: 1.0000e-06\n",
      "Epoch 794/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.8638 - mae: 36.8638 - val_loss: 1359.2926 - val_mae: 1359.2926 - lr: 1.0000e-06\n",
      "Epoch 795/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.8559 - mae: 36.8559 - val_loss: 1359.5586 - val_mae: 1359.5586 - lr: 1.0000e-06\n",
      "Epoch 796/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.8490 - mae: 36.8490 - val_loss: 1359.2756 - val_mae: 1359.2756 - lr: 1.0000e-06\n",
      "Epoch 797/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.8462 - mae: 36.8462 - val_loss: 1359.5979 - val_mae: 1359.5979 - lr: 1.0000e-06\n",
      "Epoch 798/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.8328 - mae: 36.8328 - val_loss: 1359.3403 - val_mae: 1359.3403 - lr: 1.0000e-06\n",
      "Epoch 799/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.8327 - mae: 36.8327 - val_loss: 1359.6471 - val_mae: 1359.6471 - lr: 1.0000e-06\n",
      "Epoch 800/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.8223 - mae: 36.8223 - val_loss: 1359.4972 - val_mae: 1359.4972 - lr: 1.0000e-06\n",
      "Epoch 801/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.8103 - mae: 36.8103 - val_loss: 1359.7814 - val_mae: 1359.7814 - lr: 1.0000e-06\n",
      "Epoch 802/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.8050 - mae: 36.8050 - val_loss: 1359.5671 - val_mae: 1359.5671 - lr: 1.0000e-06\n",
      "Epoch 803/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.8034 - mae: 36.8034 - val_loss: 1359.7357 - val_mae: 1359.7357 - lr: 1.0000e-06\n",
      "Epoch 804/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.7923 - mae: 36.7923 - val_loss: 1359.7341 - val_mae: 1359.7341 - lr: 1.0000e-06\n",
      "Epoch 805/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.7860 - mae: 36.7860 - val_loss: 1359.7603 - val_mae: 1359.7603 - lr: 1.0000e-06\n",
      "Epoch 806/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.7702 - mae: 36.7702 - val_loss: 1359.8867 - val_mae: 1359.8867 - lr: 1.0000e-06\n",
      "Epoch 807/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.7641 - mae: 36.7641 - val_loss: 1359.8276 - val_mae: 1359.8276 - lr: 1.0000e-06\n",
      "Epoch 808/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.7518 - mae: 36.7518 - val_loss: 1360.1315 - val_mae: 1360.1315 - lr: 1.0000e-06\n",
      "Epoch 809/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.7377 - mae: 36.7377 - val_loss: 1359.9924 - val_mae: 1359.9924 - lr: 1.0000e-06\n",
      "Epoch 810/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.7302 - mae: 36.7302 - val_loss: 1360.1537 - val_mae: 1360.1537 - lr: 1.0000e-06\n",
      "Epoch 811/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.7162 - mae: 36.7162 - val_loss: 1360.0458 - val_mae: 1360.0458 - lr: 1.0000e-06\n",
      "Epoch 812/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.7017 - mae: 36.7017 - val_loss: 1360.2476 - val_mae: 1360.2476 - lr: 1.0000e-06\n",
      "Epoch 813/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6912 - mae: 36.6912 - val_loss: 1360.1434 - val_mae: 1360.1434 - lr: 1.0000e-06\n",
      "Epoch 814/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6832 - mae: 36.6832 - val_loss: 1360.2012 - val_mae: 1360.2012 - lr: 1.0000e-06\n",
      "Epoch 815/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6763 - mae: 36.6763 - val_loss: 1360.1919 - val_mae: 1360.1919 - lr: 1.0000e-06\n",
      "Epoch 816/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6644 - mae: 36.6644 - val_loss: 1360.3540 - val_mae: 1360.3540 - lr: 1.0000e-06\n",
      "Epoch 817/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6597 - mae: 36.6597 - val_loss: 1360.3419 - val_mae: 1360.3419 - lr: 1.0000e-06\n",
      "Epoch 818/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6556 - mae: 36.6556 - val_loss: 1360.3804 - val_mae: 1360.3804 - lr: 1.0000e-06\n",
      "Epoch 819/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6505 - mae: 36.6505 - val_loss: 1360.3417 - val_mae: 1360.3417 - lr: 1.0000e-06\n",
      "Epoch 820/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6428 - mae: 36.6428 - val_loss: 1360.4188 - val_mae: 1360.4188 - lr: 1.0000e-06\n",
      "Epoch 821/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6418 - mae: 36.6418 - val_loss: 1360.3525 - val_mae: 1360.3525 - lr: 1.0000e-06\n",
      "Epoch 822/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.6248 - mae: 36.6248 - val_loss: 1360.5334 - val_mae: 1360.5334 - lr: 1.0000e-06\n",
      "Epoch 823/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.6208 - mae: 36.6208 - val_loss: 1360.4965 - val_mae: 1360.4965 - lr: 1.0000e-06\n",
      "Epoch 824/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.6045 - mae: 36.6045 - val_loss: 1360.6902 - val_mae: 1360.6902 - lr: 1.0000e-06\n",
      "Epoch 825/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5680 - mae: 36.5680 - val_loss: 1360.6769 - val_mae: 1360.6769 - lr: 1.0000e-07\n",
      "Epoch 826/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5657 - mae: 36.5657 - val_loss: 1360.6670 - val_mae: 1360.6670 - lr: 1.0000e-07\n",
      "Epoch 827/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5638 - mae: 36.5638 - val_loss: 1360.6698 - val_mae: 1360.6698 - lr: 1.0000e-07\n",
      "Epoch 828/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5620 - mae: 36.5620 - val_loss: 1360.6777 - val_mae: 1360.6777 - lr: 1.0000e-07\n",
      "Epoch 829/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.5603 - mae: 36.5603 - val_loss: 1360.6840 - val_mae: 1360.6840 - lr: 1.0000e-07\n",
      "Epoch 830/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5588 - mae: 36.5588 - val_loss: 1360.6917 - val_mae: 1360.6917 - lr: 1.0000e-07\n",
      "Epoch 831/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5573 - mae: 36.5573 - val_loss: 1360.6984 - val_mae: 1360.6984 - lr: 1.0000e-07\n",
      "Epoch 832/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.5558 - mae: 36.5558 - val_loss: 1360.7045 - val_mae: 1360.7045 - lr: 1.0000e-07\n",
      "Epoch 833/2000\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 36.5544 - mae: 36.5544 - val_loss: 1360.7101 - val_mae: 1360.7101 - lr: 1.0000e-07\n",
      "Epoch 834/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.5531 - mae: 36.5531 - val_loss: 1360.7152 - val_mae: 1360.7152 - lr: 1.0000e-07\n",
      "Epoch 835/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5518 - mae: 36.5518 - val_loss: 1360.7250 - val_mae: 1360.7250 - lr: 1.0000e-07\n",
      "Epoch 836/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.5505 - mae: 36.5505 - val_loss: 1360.7297 - val_mae: 1360.7297 - lr: 1.0000e-07\n",
      "Epoch 837/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5492 - mae: 36.5492 - val_loss: 1360.7343 - val_mae: 1360.7343 - lr: 1.0000e-07\n",
      "Epoch 838/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5480 - mae: 36.5480 - val_loss: 1360.7379 - val_mae: 1360.7379 - lr: 1.0000e-07\n",
      "Epoch 839/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5468 - mae: 36.5468 - val_loss: 1360.7413 - val_mae: 1360.7413 - lr: 1.0000e-07\n",
      "Epoch 840/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5456 - mae: 36.5456 - val_loss: 1360.7468 - val_mae: 1360.7468 - lr: 1.0000e-07\n",
      "Epoch 841/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5444 - mae: 36.5444 - val_loss: 1360.7472 - val_mae: 1360.7472 - lr: 1.0000e-07\n",
      "Epoch 842/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 29ms/step - loss: 36.5431 - mae: 36.5431 - val_loss: 1360.7561 - val_mae: 1360.7561 - lr: 1.0000e-07\n",
      "Epoch 843/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.5419 - mae: 36.5419 - val_loss: 1360.7581 - val_mae: 1360.7581 - lr: 1.0000e-07\n",
      "Epoch 844/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5407 - mae: 36.5407 - val_loss: 1360.7601 - val_mae: 1360.7601 - lr: 1.0000e-07\n",
      "Epoch 845/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.5394 - mae: 36.5394 - val_loss: 1360.7604 - val_mae: 1360.7604 - lr: 1.0000e-07\n",
      "Epoch 846/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.5383 - mae: 36.5383 - val_loss: 1360.7700 - val_mae: 1360.7700 - lr: 1.0000e-07\n",
      "Epoch 847/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.5372 - mae: 36.5372 - val_loss: 1360.7681 - val_mae: 1360.7681 - lr: 1.0000e-07\n",
      "Epoch 848/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5359 - mae: 36.5359 - val_loss: 1360.7787 - val_mae: 1360.7787 - lr: 1.0000e-07\n",
      "Epoch 849/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.5347 - mae: 36.5347 - val_loss: 1360.7697 - val_mae: 1360.7697 - lr: 1.0000e-07\n",
      "Epoch 850/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5335 - mae: 36.5335 - val_loss: 1360.7849 - val_mae: 1360.7849 - lr: 1.0000e-07\n",
      "Epoch 851/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.5324 - mae: 36.5324 - val_loss: 1360.7847 - val_mae: 1360.7847 - lr: 1.0000e-07\n",
      "Epoch 852/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.5312 - mae: 36.5312 - val_loss: 1360.7852 - val_mae: 1360.7852 - lr: 1.0000e-07\n",
      "Epoch 853/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5301 - mae: 36.5301 - val_loss: 1360.7800 - val_mae: 1360.7800 - lr: 1.0000e-07\n",
      "Epoch 854/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5290 - mae: 36.5290 - val_loss: 1360.7958 - val_mae: 1360.7958 - lr: 1.0000e-07\n",
      "Epoch 855/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.5277 - mae: 36.5277 - val_loss: 1360.7943 - val_mae: 1360.7943 - lr: 1.0000e-07\n",
      "Epoch 856/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5266 - mae: 36.5266 - val_loss: 1360.8070 - val_mae: 1360.8070 - lr: 1.0000e-07\n",
      "Epoch 857/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5255 - mae: 36.5255 - val_loss: 1360.7982 - val_mae: 1360.7982 - lr: 1.0000e-07\n",
      "Epoch 858/2000\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 36.5244 - mae: 36.5244 - val_loss: 1360.8071 - val_mae: 1360.8071 - lr: 1.0000e-07\n",
      "Epoch 859/2000\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 36.5233 - mae: 36.5233 - val_loss: 1360.8052 - val_mae: 1360.8052 - lr: 1.0000e-07\n",
      "Epoch 860/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5221 - mae: 36.5221 - val_loss: 1360.8149 - val_mae: 1360.8149 - lr: 1.0000e-07\n",
      "Epoch 861/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.5210 - mae: 36.5210 - val_loss: 1360.8096 - val_mae: 1360.8096 - lr: 1.0000e-07\n",
      "Epoch 862/2000\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 36.5198 - mae: 36.5198 - val_loss: 1360.8221 - val_mae: 1360.8221 - lr: 1.0000e-07\n",
      "Epoch 863/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5187 - mae: 36.5187 - val_loss: 1360.8182 - val_mae: 1360.8182 - lr: 1.0000e-07\n",
      "Epoch 864/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5175 - mae: 36.5175 - val_loss: 1360.8285 - val_mae: 1360.8285 - lr: 1.0000e-07\n",
      "Epoch 865/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5166 - mae: 36.5166 - val_loss: 1360.8221 - val_mae: 1360.8221 - lr: 1.0000e-07\n",
      "Epoch 866/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5155 - mae: 36.5155 - val_loss: 1360.8351 - val_mae: 1360.8351 - lr: 1.0000e-07\n",
      "Epoch 867/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5143 - mae: 36.5143 - val_loss: 1360.8267 - val_mae: 1360.8267 - lr: 1.0000e-07\n",
      "Epoch 868/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5131 - mae: 36.5131 - val_loss: 1360.8427 - val_mae: 1360.8427 - lr: 1.0000e-07\n",
      "Epoch 869/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5120 - mae: 36.5120 - val_loss: 1360.8385 - val_mae: 1360.8385 - lr: 1.0000e-07\n",
      "Epoch 870/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5109 - mae: 36.5109 - val_loss: 1360.8425 - val_mae: 1360.8425 - lr: 1.0000e-07\n",
      "Epoch 871/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5101 - mae: 36.5101 - val_loss: 1360.8389 - val_mae: 1360.8389 - lr: 1.0000e-07\n",
      "Epoch 872/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.5089 - mae: 36.5089 - val_loss: 1360.8535 - val_mae: 1360.8535 - lr: 1.0000e-07\n",
      "Epoch 873/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.5078 - mae: 36.5078 - val_loss: 1360.8518 - val_mae: 1360.8518 - lr: 1.0000e-07\n",
      "Epoch 874/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5066 - mae: 36.5066 - val_loss: 1360.8491 - val_mae: 1360.8491 - lr: 1.0000e-07\n",
      "Epoch 875/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5055 - mae: 36.5055 - val_loss: 1360.8560 - val_mae: 1360.8560 - lr: 1.0000e-07\n",
      "Epoch 876/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5043 - mae: 36.5043 - val_loss: 1360.8657 - val_mae: 1360.8657 - lr: 1.0000e-07\n",
      "Epoch 877/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.5032 - mae: 36.5032 - val_loss: 1360.8739 - val_mae: 1360.8739 - lr: 1.0000e-07\n",
      "Epoch 878/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5020 - mae: 36.5020 - val_loss: 1360.8655 - val_mae: 1360.8655 - lr: 1.0000e-07\n",
      "Epoch 879/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.5012 - mae: 36.5012 - val_loss: 1360.8740 - val_mae: 1360.8740 - lr: 1.0000e-07\n",
      "Epoch 880/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4999 - mae: 36.4999 - val_loss: 1360.8715 - val_mae: 1360.8715 - lr: 1.0000e-07\n",
      "Epoch 881/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4989 - mae: 36.4989 - val_loss: 1360.8820 - val_mae: 1360.8820 - lr: 1.0000e-07\n",
      "Epoch 882/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4977 - mae: 36.4977 - val_loss: 1360.8767 - val_mae: 1360.8767 - lr: 1.0000e-07\n",
      "Epoch 883/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4967 - mae: 36.4967 - val_loss: 1360.8966 - val_mae: 1360.8966 - lr: 1.0000e-07\n",
      "Epoch 884/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4957 - mae: 36.4957 - val_loss: 1360.8767 - val_mae: 1360.8767 - lr: 1.0000e-07\n",
      "Epoch 885/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4948 - mae: 36.4948 - val_loss: 1360.8975 - val_mae: 1360.8975 - lr: 1.0000e-07\n",
      "Epoch 886/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4937 - mae: 36.4937 - val_loss: 1360.8801 - val_mae: 1360.8801 - lr: 1.0000e-07\n",
      "Epoch 887/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4926 - mae: 36.4926 - val_loss: 1360.9067 - val_mae: 1360.9067 - lr: 1.0000e-07\n",
      "Epoch 888/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4915 - mae: 36.4915 - val_loss: 1360.8923 - val_mae: 1360.8923 - lr: 1.0000e-07\n",
      "Epoch 889/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4904 - mae: 36.4904 - val_loss: 1360.9160 - val_mae: 1360.9160 - lr: 1.0000e-07\n",
      "Epoch 890/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4894 - mae: 36.4894 - val_loss: 1360.8916 - val_mae: 1360.8916 - lr: 1.0000e-07\n",
      "Epoch 891/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4885 - mae: 36.4885 - val_loss: 1360.9159 - val_mae: 1360.9159 - lr: 1.0000e-07\n",
      "Epoch 892/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4871 - mae: 36.4871 - val_loss: 1360.8956 - val_mae: 1360.8956 - lr: 1.0000e-07\n",
      "Epoch 893/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4861 - mae: 36.4861 - val_loss: 1360.9258 - val_mae: 1360.9258 - lr: 1.0000e-07\n",
      "Epoch 894/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4849 - mae: 36.4849 - val_loss: 1360.9084 - val_mae: 1360.9084 - lr: 1.0000e-07\n",
      "Epoch 895/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4837 - mae: 36.4837 - val_loss: 1360.9358 - val_mae: 1360.9358 - lr: 1.0000e-07\n",
      "Epoch 896/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4825 - mae: 36.4825 - val_loss: 1360.9181 - val_mae: 1360.9181 - lr: 1.0000e-07\n",
      "Epoch 897/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4817 - mae: 36.4817 - val_loss: 1360.9429 - val_mae: 1360.9429 - lr: 1.0000e-07\n",
      "Epoch 898/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4807 - mae: 36.4807 - val_loss: 1360.9166 - val_mae: 1360.9166 - lr: 1.0000e-07\n",
      "Epoch 899/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4798 - mae: 36.4798 - val_loss: 1360.9410 - val_mae: 1360.9410 - lr: 1.0000e-07\n",
      "Epoch 900/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4789 - mae: 36.4789 - val_loss: 1360.9285 - val_mae: 1360.9285 - lr: 1.0000e-07\n",
      "Epoch 901/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4778 - mae: 36.4778 - val_loss: 1360.9570 - val_mae: 1360.9570 - lr: 1.0000e-07\n",
      "Epoch 902/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4765 - mae: 36.4765 - val_loss: 1360.9314 - val_mae: 1360.9314 - lr: 1.0000e-07\n",
      "Epoch 903/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4753 - mae: 36.4753 - val_loss: 1360.9646 - val_mae: 1360.9646 - lr: 1.0000e-07\n",
      "Epoch 904/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4740 - mae: 36.4740 - val_loss: 1360.9362 - val_mae: 1360.9362 - lr: 1.0000e-07\n",
      "Epoch 905/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4730 - mae: 36.4730 - val_loss: 1360.9561 - val_mae: 1360.9561 - lr: 1.0000e-07\n",
      "Epoch 906/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4716 - mae: 36.4716 - val_loss: 1360.9551 - val_mae: 1360.9551 - lr: 1.0000e-07\n",
      "Epoch 907/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4707 - mae: 36.4707 - val_loss: 1360.9739 - val_mae: 1360.9739 - lr: 1.0000e-07\n",
      "Epoch 908/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4696 - mae: 36.4696 - val_loss: 1360.9597 - val_mae: 1360.9597 - lr: 1.0000e-07\n",
      "Epoch 909/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4685 - mae: 36.4685 - val_loss: 1360.9810 - val_mae: 1360.9810 - lr: 1.0000e-07\n",
      "Epoch 910/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4675 - mae: 36.4675 - val_loss: 1360.9630 - val_mae: 1360.9630 - lr: 1.0000e-07\n",
      "Epoch 911/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4665 - mae: 36.4665 - val_loss: 1360.9775 - val_mae: 1360.9775 - lr: 1.0000e-07\n",
      "Epoch 912/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4652 - mae: 36.4652 - val_loss: 1360.9744 - val_mae: 1360.9744 - lr: 1.0000e-07\n",
      "Epoch 913/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4645 - mae: 36.4645 - val_loss: 1360.9908 - val_mae: 1360.9908 - lr: 1.0000e-07\n",
      "Epoch 914/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4631 - mae: 36.4631 - val_loss: 1360.9825 - val_mae: 1360.9825 - lr: 1.0000e-07\n",
      "Epoch 915/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4623 - mae: 36.4623 - val_loss: 1360.9878 - val_mae: 1360.9878 - lr: 1.0000e-07\n",
      "Epoch 916/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4612 - mae: 36.4612 - val_loss: 1360.9923 - val_mae: 1360.9923 - lr: 1.0000e-07\n",
      "Epoch 917/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4603 - mae: 36.4603 - val_loss: 1360.9950 - val_mae: 1360.9950 - lr: 1.0000e-07\n",
      "Epoch 918/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4592 - mae: 36.4592 - val_loss: 1360.9993 - val_mae: 1360.9993 - lr: 1.0000e-07\n",
      "Epoch 919/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4581 - mae: 36.4581 - val_loss: 1361.0021 - val_mae: 1361.0021 - lr: 1.0000e-07\n",
      "Epoch 920/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4571 - mae: 36.4571 - val_loss: 1361.0128 - val_mae: 1361.0128 - lr: 1.0000e-07\n",
      "Epoch 921/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4561 - mae: 36.4561 - val_loss: 1360.9988 - val_mae: 1360.9988 - lr: 1.0000e-07\n",
      "Epoch 922/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4553 - mae: 36.4553 - val_loss: 1361.0143 - val_mae: 1361.0143 - lr: 1.0000e-07\n",
      "Epoch 923/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4545 - mae: 36.4545 - val_loss: 1361.0094 - val_mae: 1361.0095 - lr: 1.0000e-07\n",
      "Epoch 924/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4531 - mae: 36.4531 - val_loss: 1361.0265 - val_mae: 1361.0265 - lr: 1.0000e-07\n",
      "Epoch 925/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4509 - mae: 36.4509 - val_loss: 1361.0269 - val_mae: 1361.0269 - lr: 1.0000e-08\n",
      "Epoch 926/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4507 - mae: 36.4507 - val_loss: 1361.0264 - val_mae: 1361.0264 - lr: 1.0000e-08\n",
      "Epoch 927/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4506 - mae: 36.4506 - val_loss: 1361.0260 - val_mae: 1361.0260 - lr: 1.0000e-08\n",
      "Epoch 928/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4504 - mae: 36.4504 - val_loss: 1361.0259 - val_mae: 1361.0259 - lr: 1.0000e-08\n",
      "Epoch 929/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4503 - mae: 36.4503 - val_loss: 1361.0259 - val_mae: 1361.0259 - lr: 1.0000e-08\n",
      "Epoch 930/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4502 - mae: 36.4502 - val_loss: 1361.0261 - val_mae: 1361.0261 - lr: 1.0000e-08\n",
      "Epoch 931/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4500 - mae: 36.4500 - val_loss: 1361.0266 - val_mae: 1361.0266 - lr: 1.0000e-08\n",
      "Epoch 932/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4499 - mae: 36.4499 - val_loss: 1361.0266 - val_mae: 1361.0266 - lr: 1.0000e-08\n",
      "Epoch 933/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4498 - mae: 36.4498 - val_loss: 1361.0264 - val_mae: 1361.0264 - lr: 1.0000e-08\n",
      "Epoch 934/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4497 - mae: 36.4497 - val_loss: 1361.0273 - val_mae: 1361.0273 - lr: 1.0000e-08\n",
      "Epoch 935/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4496 - mae: 36.4496 - val_loss: 1361.0273 - val_mae: 1361.0273 - lr: 1.0000e-08\n",
      "Epoch 936/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4495 - mae: 36.4495 - val_loss: 1361.0276 - val_mae: 1361.0276 - lr: 1.0000e-08\n",
      "Epoch 937/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4494 - mae: 36.4494 - val_loss: 1361.0278 - val_mae: 1361.0278 - lr: 1.0000e-08\n",
      "Epoch 938/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4493 - mae: 36.4493 - val_loss: 1361.0286 - val_mae: 1361.0286 - lr: 1.0000e-08\n",
      "Epoch 939/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4492 - mae: 36.4492 - val_loss: 1361.0287 - val_mae: 1361.0287 - lr: 1.0000e-08\n",
      "Epoch 940/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4491 - mae: 36.4491 - val_loss: 1361.0288 - val_mae: 1361.0288 - lr: 1.0000e-08\n",
      "Epoch 941/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4490 - mae: 36.4490 - val_loss: 1361.0292 - val_mae: 1361.0292 - lr: 1.0000e-08\n",
      "Epoch 942/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4489 - mae: 36.4489 - val_loss: 1361.0288 - val_mae: 1361.0288 - lr: 1.0000e-08\n",
      "Epoch 943/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4488 - mae: 36.4488 - val_loss: 1361.0295 - val_mae: 1361.0295 - lr: 1.0000e-08\n",
      "Epoch 944/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4487 - mae: 36.4487 - val_loss: 1361.0299 - val_mae: 1361.0299 - lr: 1.0000e-08\n",
      "Epoch 945/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4486 - mae: 36.4486 - val_loss: 1361.0306 - val_mae: 1361.0306 - lr: 1.0000e-08\n",
      "Epoch 946/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4485 - mae: 36.4485 - val_loss: 1361.0300 - val_mae: 1361.0300 - lr: 1.0000e-08\n",
      "Epoch 947/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4484 - mae: 36.4484 - val_loss: 1361.0310 - val_mae: 1361.0310 - lr: 1.0000e-08\n",
      "Epoch 948/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4483 - mae: 36.4483 - val_loss: 1361.0309 - val_mae: 1361.0309 - lr: 1.0000e-08\n",
      "Epoch 949/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4483 - mae: 36.4483 - val_loss: 1361.0311 - val_mae: 1361.0311 - lr: 1.0000e-08\n",
      "Epoch 950/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4481 - mae: 36.4481 - val_loss: 1361.0312 - val_mae: 1361.0312 - lr: 1.0000e-08\n",
      "Epoch 951/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4481 - mae: 36.4481 - val_loss: 1361.0319 - val_mae: 1361.0319 - lr: 1.0000e-08\n",
      "Epoch 952/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4480 - mae: 36.4480 - val_loss: 1361.0314 - val_mae: 1361.0314 - lr: 1.0000e-08\n",
      "Epoch 953/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4479 - mae: 36.4479 - val_loss: 1361.0316 - val_mae: 1361.0316 - lr: 1.0000e-08\n",
      "Epoch 954/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4478 - mae: 36.4478 - val_loss: 1361.0325 - val_mae: 1361.0325 - lr: 1.0000e-08\n",
      "Epoch 955/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4477 - mae: 36.4477 - val_loss: 1361.0327 - val_mae: 1361.0327 - lr: 1.0000e-08\n",
      "Epoch 956/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4476 - mae: 36.4476 - val_loss: 1361.0325 - val_mae: 1361.0325 - lr: 1.0000e-08\n",
      "Epoch 957/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4475 - mae: 36.4475 - val_loss: 1361.0337 - val_mae: 1361.0337 - lr: 1.0000e-08\n",
      "Epoch 958/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4474 - mae: 36.4474 - val_loss: 1361.0337 - val_mae: 1361.0337 - lr: 1.0000e-08\n",
      "Epoch 959/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4473 - mae: 36.4473 - val_loss: 1361.0327 - val_mae: 1361.0327 - lr: 1.0000e-08\n",
      "Epoch 960/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4472 - mae: 36.4472 - val_loss: 1361.0333 - val_mae: 1361.0333 - lr: 1.0000e-08\n",
      "Epoch 961/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4472 - mae: 36.4472 - val_loss: 1361.0336 - val_mae: 1361.0336 - lr: 1.0000e-08\n",
      "Epoch 962/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4471 - mae: 36.4471 - val_loss: 1361.0344 - val_mae: 1361.0344 - lr: 1.0000e-08\n",
      "Epoch 963/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4470 - mae: 36.4470 - val_loss: 1361.0348 - val_mae: 1361.0348 - lr: 1.0000e-08\n",
      "Epoch 964/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4469 - mae: 36.4469 - val_loss: 1361.0356 - val_mae: 1361.0356 - lr: 1.0000e-08\n",
      "Epoch 965/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4468 - mae: 36.4468 - val_loss: 1361.0350 - val_mae: 1361.0350 - lr: 1.0000e-08\n",
      "Epoch 966/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4467 - mae: 36.4467 - val_loss: 1361.0352 - val_mae: 1361.0352 - lr: 1.0000e-08\n",
      "Epoch 967/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4466 - mae: 36.4466 - val_loss: 1361.0363 - val_mae: 1361.0363 - lr: 1.0000e-08\n",
      "Epoch 968/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4465 - mae: 36.4465 - val_loss: 1361.0361 - val_mae: 1361.0361 - lr: 1.0000e-08\n",
      "Epoch 969/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4464 - mae: 36.4464 - val_loss: 1361.0366 - val_mae: 1361.0366 - lr: 1.0000e-08\n",
      "Epoch 970/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4463 - mae: 36.4463 - val_loss: 1361.0369 - val_mae: 1361.0369 - lr: 1.0000e-08\n",
      "Epoch 971/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4462 - mae: 36.4462 - val_loss: 1361.0370 - val_mae: 1361.0370 - lr: 1.0000e-08\n",
      "Epoch 972/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4461 - mae: 36.4461 - val_loss: 1361.0376 - val_mae: 1361.0376 - lr: 1.0000e-08\n",
      "Epoch 973/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4461 - mae: 36.4461 - val_loss: 1361.0378 - val_mae: 1361.0378 - lr: 1.0000e-08\n",
      "Epoch 974/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4460 - mae: 36.4460 - val_loss: 1361.0381 - val_mae: 1361.0381 - lr: 1.0000e-08\n",
      "Epoch 975/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4459 - mae: 36.4459 - val_loss: 1361.0380 - val_mae: 1361.0380 - lr: 1.0000e-08\n",
      "Epoch 976/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4458 - mae: 36.4458 - val_loss: 1361.0393 - val_mae: 1361.0393 - lr: 1.0000e-08\n",
      "Epoch 977/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4457 - mae: 36.4457 - val_loss: 1361.0393 - val_mae: 1361.0393 - lr: 1.0000e-08\n",
      "Epoch 978/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4456 - mae: 36.4456 - val_loss: 1361.0396 - val_mae: 1361.0396 - lr: 1.0000e-08\n",
      "Epoch 979/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4455 - mae: 36.4455 - val_loss: 1361.0396 - val_mae: 1361.0396 - lr: 1.0000e-08\n",
      "Epoch 980/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4454 - mae: 36.4454 - val_loss: 1361.0400 - val_mae: 1361.0400 - lr: 1.0000e-08\n",
      "Epoch 981/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4453 - mae: 36.4453 - val_loss: 1361.0400 - val_mae: 1361.0400 - lr: 1.0000e-08\n",
      "Epoch 982/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4452 - mae: 36.4452 - val_loss: 1361.0410 - val_mae: 1361.0410 - lr: 1.0000e-08\n",
      "Epoch 983/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4451 - mae: 36.4451 - val_loss: 1361.0406 - val_mae: 1361.0406 - lr: 1.0000e-08\n",
      "Epoch 984/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4451 - mae: 36.4451 - val_loss: 1361.0416 - val_mae: 1361.0416 - lr: 1.0000e-08\n",
      "Epoch 985/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4449 - mae: 36.4449 - val_loss: 1361.0415 - val_mae: 1361.0415 - lr: 1.0000e-08\n",
      "Epoch 986/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4449 - mae: 36.4449 - val_loss: 1361.0422 - val_mae: 1361.0422 - lr: 1.0000e-08\n",
      "Epoch 987/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4448 - mae: 36.4448 - val_loss: 1361.0424 - val_mae: 1361.0424 - lr: 1.0000e-08\n",
      "Epoch 988/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4447 - mae: 36.4447 - val_loss: 1361.0426 - val_mae: 1361.0426 - lr: 1.0000e-08\n",
      "Epoch 989/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4446 - mae: 36.4446 - val_loss: 1361.0426 - val_mae: 1361.0426 - lr: 1.0000e-08\n",
      "Epoch 990/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4445 - mae: 36.4445 - val_loss: 1361.0438 - val_mae: 1361.0438 - lr: 1.0000e-08\n",
      "Epoch 991/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4444 - mae: 36.4444 - val_loss: 1361.0428 - val_mae: 1361.0428 - lr: 1.0000e-08\n",
      "Epoch 992/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4443 - mae: 36.4443 - val_loss: 1361.0439 - val_mae: 1361.0439 - lr: 1.0000e-08\n",
      "Epoch 993/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4442 - mae: 36.4442 - val_loss: 1361.0441 - val_mae: 1361.0441 - lr: 1.0000e-08\n",
      "Epoch 994/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4441 - mae: 36.4441 - val_loss: 1361.0448 - val_mae: 1361.0448 - lr: 1.0000e-08\n",
      "Epoch 995/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4440 - mae: 36.4440 - val_loss: 1361.0442 - val_mae: 1361.0442 - lr: 1.0000e-08\n",
      "Epoch 996/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4440 - mae: 36.4440 - val_loss: 1361.0455 - val_mae: 1361.0455 - lr: 1.0000e-08\n",
      "Epoch 997/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4438 - mae: 36.4438 - val_loss: 1361.0448 - val_mae: 1361.0448 - lr: 1.0000e-08\n",
      "Epoch 998/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4438 - mae: 36.4438 - val_loss: 1361.0454 - val_mae: 1361.0454 - lr: 1.0000e-08\n",
      "Epoch 999/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4437 - mae: 36.4437 - val_loss: 1361.0460 - val_mae: 1361.0460 - lr: 1.0000e-08\n",
      "Epoch 1000/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4436 - mae: 36.4436 - val_loss: 1361.0471 - val_mae: 1361.0471 - lr: 1.0000e-08\n",
      "Epoch 1001/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4435 - mae: 36.4435 - val_loss: 1361.0460 - val_mae: 1361.0460 - lr: 1.0000e-08\n",
      "Epoch 1002/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4434 - mae: 36.4434 - val_loss: 1361.0468 - val_mae: 1361.0468 - lr: 1.0000e-08\n",
      "Epoch 1003/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4433 - mae: 36.4433 - val_loss: 1361.0474 - val_mae: 1361.0474 - lr: 1.0000e-08\n",
      "Epoch 1004/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4432 - mae: 36.4432 - val_loss: 1361.0479 - val_mae: 1361.0479 - lr: 1.0000e-08\n",
      "Epoch 1005/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4431 - mae: 36.4431 - val_loss: 1361.0476 - val_mae: 1361.0476 - lr: 1.0000e-08\n",
      "Epoch 1006/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4431 - mae: 36.4431 - val_loss: 1361.0487 - val_mae: 1361.0487 - lr: 1.0000e-08\n",
      "Epoch 1007/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4430 - mae: 36.4430 - val_loss: 1361.0471 - val_mae: 1361.0471 - lr: 1.0000e-08\n",
      "Epoch 1008/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4429 - mae: 36.4429 - val_loss: 1361.0482 - val_mae: 1361.0482 - lr: 1.0000e-08\n",
      "Epoch 1009/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4428 - mae: 36.4428 - val_loss: 1361.0487 - val_mae: 1361.0487 - lr: 1.0000e-08\n",
      "Epoch 1010/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4427 - mae: 36.4427 - val_loss: 1361.0492 - val_mae: 1361.0492 - lr: 1.0000e-08\n",
      "Epoch 1011/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4426 - mae: 36.4426 - val_loss: 1361.0497 - val_mae: 1361.0497 - lr: 1.0000e-08\n",
      "Epoch 1012/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4425 - mae: 36.4425 - val_loss: 1361.0502 - val_mae: 1361.0502 - lr: 1.0000e-08\n",
      "Epoch 1013/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4424 - mae: 36.4424 - val_loss: 1361.0503 - val_mae: 1361.0503 - lr: 1.0000e-08\n",
      "Epoch 1014/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4423 - mae: 36.4423 - val_loss: 1361.0510 - val_mae: 1361.0510 - lr: 1.0000e-08\n",
      "Epoch 1015/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4422 - mae: 36.4422 - val_loss: 1361.0507 - val_mae: 1361.0507 - lr: 1.0000e-08\n",
      "Epoch 1016/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4422 - mae: 36.4422 - val_loss: 1361.0518 - val_mae: 1361.0518 - lr: 1.0000e-08\n",
      "Epoch 1017/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4421 - mae: 36.4421 - val_loss: 1361.0519 - val_mae: 1361.0519 - lr: 1.0000e-08\n",
      "Epoch 1018/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4420 - mae: 36.4420 - val_loss: 1361.0526 - val_mae: 1361.0526 - lr: 1.0000e-08\n",
      "Epoch 1019/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4419 - mae: 36.4419 - val_loss: 1361.0510 - val_mae: 1361.0510 - lr: 1.0000e-08\n",
      "Epoch 1020/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4418 - mae: 36.4418 - val_loss: 1361.0524 - val_mae: 1361.0524 - lr: 1.0000e-08\n",
      "Epoch 1021/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4417 - mae: 36.4417 - val_loss: 1361.0516 - val_mae: 1361.0516 - lr: 1.0000e-08\n",
      "Epoch 1022/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4416 - mae: 36.4416 - val_loss: 1361.0535 - val_mae: 1361.0535 - lr: 1.0000e-08\n",
      "Epoch 1023/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4415 - mae: 36.4415 - val_loss: 1361.0533 - val_mae: 1361.0533 - lr: 1.0000e-08\n",
      "Epoch 1024/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4414 - mae: 36.4414 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-08\n",
      "Epoch 1025/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1026/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0538 - val_mae: 1361.0538 - lr: 1.0000e-09\n",
      "Epoch 1027/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1028/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1029/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0538 - val_mae: 1361.0538 - lr: 1.0000e-09\n",
      "Epoch 1030/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0536 - val_mae: 1361.0536 - lr: 1.0000e-09\n",
      "Epoch 1031/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1032/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1033/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1034/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0536 - val_mae: 1361.0536 - lr: 1.0000e-09\n",
      "Epoch 1035/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1036/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0538 - val_mae: 1361.0538 - lr: 1.0000e-09\n",
      "Epoch 1037/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1038/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1039/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1040/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1041/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1042/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1043/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0538 - val_mae: 1361.0538 - lr: 1.0000e-09\n",
      "Epoch 1044/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1045/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1046/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1047/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1048/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1049/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1050/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1051/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1052/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1053/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1054/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1055/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1056/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1057/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1058/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1059/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1060/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1061/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1062/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1063/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1064/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1065/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1066/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1067/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1068/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-09\n",
      "Epoch 1069/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-09\n",
      "Epoch 1070/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1071/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1072/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4413 - mae: 36.4413 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1073/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1074/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1075/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0538 - val_mae: 1361.0538 - lr: 1.0000e-09\n",
      "Epoch 1076/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0538 - val_mae: 1361.0538 - lr: 1.0000e-09\n",
      "Epoch 1077/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0538 - val_mae: 1361.0538 - lr: 1.0000e-09\n",
      "Epoch 1078/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1079/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1080/2000\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1081/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1082/2000\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1083/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1084/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1085/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0538 - val_mae: 1361.0538 - lr: 1.0000e-09\n",
      "Epoch 1086/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1087/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1088/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1089/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1090/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0537 - val_mae: 1361.0537 - lr: 1.0000e-09\n",
      "Epoch 1091/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1092/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1093/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1094/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1095/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1096/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1097/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1098/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1099/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0538 - val_mae: 1361.0538 - lr: 1.0000e-09\n",
      "Epoch 1100/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1101/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1102/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1103/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1104/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1105/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1106/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1107/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1108/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1109/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1110/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0540 - val_mae: 1361.0540 - lr: 1.0000e-09\n",
      "Epoch 1111/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1112/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1113/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1114/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1115/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1116/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1117/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1118/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1119/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1120/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1121/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-09\n",
      "Epoch 1122/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1123/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1124/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-09\n",
      "Epoch 1125/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1126/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1127/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1128/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1129/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1130/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1131/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1132/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1133/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1134/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1135/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1136/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1137/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1138/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1139/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1140/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1141/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1142/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1143/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1144/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1145/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1146/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1147/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1148/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1149/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1150/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1151/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1152/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1153/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1154/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1155/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1156/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1157/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1158/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1159/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1160/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1161/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1162/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1163/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1164/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1165/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1166/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1167/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1168/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1169/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1170/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1171/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1172/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1173/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1174/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1175/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1176/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1177/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1178/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1179/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1180/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1181/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1182/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1183/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1184/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1185/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1186/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1187/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1188/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1189/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0544 - val_mae: 1361.0544 - lr: 1.0000e-10\n",
      "Epoch 1190/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1191/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1192/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1193/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1194/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1195/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1196/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1197/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n",
      "Epoch 1198/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0542 - val_mae: 1361.0542 - lr: 1.0000e-10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1199/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1200/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1201/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1202/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1203/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1204/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1205/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0543 - val_mae: 1361.0543 - lr: 1.0000e-10\n",
      "Epoch 1206/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1207/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1208/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1209/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1210/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1211/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1212/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1213/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1214/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1215/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1216/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1217/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1218/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1219/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1220/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1221/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1222/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1223/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1224/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-10\n",
      "Epoch 1225/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1226/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1227/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1228/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1229/2000\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1230/2000\n",
      "22/22 [==============================] - 1s 27ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1231/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1232/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1233/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1234/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1235/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1236/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1237/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1238/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1239/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1240/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1241/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1242/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1243/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1244/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1245/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1246/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1247/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1248/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1249/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1250/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1251/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1252/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1253/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1254/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1255/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1256/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1257/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1258/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1259/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1260/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1261/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1262/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1263/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1264/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1265/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1266/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1267/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1268/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1269/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1270/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1271/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1272/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1273/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1274/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1275/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1276/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1277/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1278/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1279/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1280/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1281/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1282/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1283/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1284/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1285/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1286/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1287/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1288/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1289/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1290/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1291/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1292/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1293/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1294/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1295/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1296/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1297/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1298/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1299/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1300/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1301/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1302/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1303/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1304/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1305/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1306/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1307/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1308/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1309/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1310/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1311/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1312/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1313/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1314/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1315/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1316/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1317/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1318/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1319/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1320/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1321/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1322/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1323/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1324/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-11\n",
      "Epoch 1325/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1326/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1327/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1328/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1329/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1330/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1331/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1332/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1333/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1334/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1335/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1336/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1337/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1338/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1339/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1340/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1341/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1342/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1343/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1344/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1345/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1346/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1347/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1348/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1349/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1350/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1351/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1352/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1353/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1354/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1355/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1356/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1357/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1358/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1359/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1360/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1361/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1362/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1363/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1364/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1365/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1366/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1367/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1368/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1369/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1370/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1371/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1372/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1373/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1374/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1375/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1376/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1377/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1378/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1379/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1380/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1381/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1382/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1383/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1384/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1385/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1386/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1387/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1388/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1389/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1390/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1391/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1392/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1393/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1394/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1395/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1396/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1397/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1398/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1399/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1400/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1401/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1402/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1403/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1404/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1405/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1406/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1407/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1408/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1409/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1410/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1411/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1412/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1413/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1414/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1415/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1416/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1417/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1418/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1419/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1420/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1421/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1422/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1423/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1424/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-12\n",
      "Epoch 1425/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1426/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1427/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1428/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1429/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1430/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1431/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1432/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1433/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1434/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1435/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1436/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1437/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1438/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1439/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1440/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1441/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1442/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1443/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1444/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1445/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1446/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1447/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1448/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1449/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1450/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1451/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1452/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1453/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1454/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1455/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1456/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1457/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1458/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1459/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1460/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1461/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1462/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1463/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1464/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1465/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1466/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1467/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1468/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1469/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1470/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1471/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1472/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1473/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1474/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1475/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1476/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1477/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1478/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1479/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1480/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1481/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1482/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1483/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1484/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1485/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1486/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1487/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1488/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1489/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1490/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1491/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1492/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1493/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1494/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1495/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1496/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1497/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1498/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1499/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1500/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1501/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1502/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1503/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1504/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1505/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1506/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1507/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1508/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1509/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1510/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1511/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1512/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1513/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1514/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1515/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1516/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1517/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1518/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1519/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1520/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1521/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1522/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1523/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1524/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-13\n",
      "Epoch 1525/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1526/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1527/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1528/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1529/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1530/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1531/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1532/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1533/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1534/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1535/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1536/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1537/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1538/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1539/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1540/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1541/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1542/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1543/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1544/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1545/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1546/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1547/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1548/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1549/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1550/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1551/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1552/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1553/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1554/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1555/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1556/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1557/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1558/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1559/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1560/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1561/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1562/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1563/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1564/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1565/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1566/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1567/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1568/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1569/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1570/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1571/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1572/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1573/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1574/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1575/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1576/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1577/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1578/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1579/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1580/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1581/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1582/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1583/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1584/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1585/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1586/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1587/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1588/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1589/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1590/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1591/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1592/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1593/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1594/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1595/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1596/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1597/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1598/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1599/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1600/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1601/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1602/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1603/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1604/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1605/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1606/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1607/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1608/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1609/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1610/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1611/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1612/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1613/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1614/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1615/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1616/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1617/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1618/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1619/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1620/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1621/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1622/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1623/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1624/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-14\n",
      "Epoch 1625/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1626/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1627/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1628/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1629/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1630/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1631/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1632/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1633/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1634/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1635/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1636/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1637/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1638/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1639/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1640/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1641/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1642/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1643/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1644/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1645/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1646/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1647/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1648/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1649/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1650/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1651/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1652/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1653/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1654/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1655/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1656/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1657/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1658/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1659/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1660/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1661/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1662/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1663/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1664/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1665/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1666/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1667/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1668/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1669/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1670/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1671/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1672/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1673/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1674/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1675/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1676/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1677/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1678/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1679/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1680/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1681/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1682/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1683/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1684/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1685/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1686/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1687/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1688/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1689/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1690/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1691/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1692/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1693/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1694/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1695/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1696/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1697/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1698/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1699/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1700/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1701/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1702/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1703/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1704/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1705/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1706/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1707/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1708/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1709/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1710/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1711/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1712/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1713/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1714/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1715/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1716/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1717/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1718/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1719/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1720/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1721/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1722/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1723/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1724/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-15\n",
      "Epoch 1725/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1726/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1727/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1728/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1729/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1730/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1731/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1732/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1733/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1734/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1735/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1736/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1737/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1738/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1739/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1740/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1741/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1742/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1743/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1744/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1745/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1746/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1747/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1748/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1749/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1750/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1751/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1752/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1753/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1754/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1755/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1756/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1757/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1758/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1759/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1760/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1761/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1762/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1763/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1764/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1765/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1766/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1767/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1768/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1769/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1770/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1771/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1772/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1773/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1774/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1775/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1776/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1777/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1778/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1779/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1780/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1781/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1782/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1783/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1784/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1785/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1786/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1787/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1788/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1789/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1790/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1791/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1792/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1793/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1794/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1795/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1796/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1797/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1798/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1799/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1800/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1801/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1802/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1803/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1804/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1805/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1806/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1807/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1808/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1809/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1810/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1811/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1812/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1813/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1814/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1815/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1816/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1817/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1818/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1819/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1820/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1821/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1822/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1823/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1824/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-16\n",
      "Epoch 1825/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1826/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1827/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1828/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1829/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1830/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1831/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1832/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1833/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1834/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1835/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1836/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1837/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1838/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1839/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1840/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1841/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1842/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1843/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1844/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1845/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1846/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1847/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1848/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1849/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1850/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1851/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1852/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1853/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1854/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1855/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1856/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1857/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1858/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1859/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1860/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1861/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1862/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1863/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1864/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1865/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1866/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1867/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1868/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1869/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1870/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1871/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1872/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1873/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1874/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1875/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1876/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1877/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1878/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1879/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1880/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1881/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1882/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1883/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1884/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1885/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1886/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1887/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1888/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1889/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1890/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1891/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1892/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1893/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1894/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1895/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1896/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1897/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1898/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1899/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1900/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1901/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1902/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1903/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1904/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1905/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1906/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1907/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1908/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1909/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1910/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1911/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1912/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1913/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1914/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1915/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1916/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1917/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1918/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1919/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1920/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1921/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1922/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1923/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1924/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-17\n",
      "Epoch 1925/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1926/2000\n",
      "22/22 [==============================] - 1s 26ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1927/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1928/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1929/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1930/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1931/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1932/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1933/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1934/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1935/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1936/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1937/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1938/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1939/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1940/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1941/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1942/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1943/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1944/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1945/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1946/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1947/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1948/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1949/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1950/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1951/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1952/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1953/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1954/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1955/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1956/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1957/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1958/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1959/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1960/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1961/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1962/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1963/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1964/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1965/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1966/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1967/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1968/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1969/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1970/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1971/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1972/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1973/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1974/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1975/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1976/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1977/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1978/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1979/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1980/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1981/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1982/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1983/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1984/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1985/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1986/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1987/2000\n",
      "22/22 [==============================] - 1s 24ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1988/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1989/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1990/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1991/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1992/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1993/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1994/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1995/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1996/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1997/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1998/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 1999/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n",
      "Epoch 2000/2000\n",
      "22/22 [==============================] - 1s 25ms/step - loss: 36.4412 - mae: 36.4412 - val_loss: 1361.0541 - val_mae: 1361.0541 - lr: 1.0000e-18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f70cc0b87c0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"mae\"])\n",
    "\n",
    "model_4.fit(train_dataset_price,\n",
    "            epochs=2000,\n",
    "            validation_data=test_dataset_price,\n",
    "            verbose=1,\n",
    "            callbacks=[model_checkpoint(model_4.name),\n",
    "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 6ms/step - loss: 1166.3112 - mean_absolute_error: 1166.3112\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1166.3111572265625, 1166.3111572265625]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_4_best = tf.keras.models.load_model(os.path.join('modelos', 'n-beats'))\n",
    "model_4_best.evaluate(test_dataset_price)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_models(models):\n",
    "    res = dict()\n",
    "    for model in models:\n",
    "        model_best = tf.keras.models.load_model(os.path.join(\"modelos\", model.name))\n",
    "        res[model.name] = model_best.evaluate(test_dataset_price)[0]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 1ms/step - loss: 1209.3976 - mean_absolute_error: 1209.3976\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1605.4968 - mean_absolute_error: 1605.4968\n",
      "WARNING:tensorflow:Layer lstm will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "6/6 [==============================] - 0s 1ms/step - loss: 1514.5292 - mean_absolute_error: 1514.5292\n",
      "6/6 [==============================] - 0s 6ms/step - loss: 1166.3112 - mean_absolute_error: 1166.3112\n"
     ]
    }
   ],
   "source": [
    "model_accuracy = compare_models((model_1, model_2, model_3, model_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'FCC_simple': 1209.3975830078125,\n",
       " 'CNN_simple': 1605.496826171875,\n",
       " 'RNN_simple': 1514.5291748046875,\n",
       " 'n-beats': 1166.3111572265625}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (10, 5))\n",
    " \n",
    "plt.bar(model_accuracy.keys(), model_accuracy.values())\n",
    " \n",
    "plt.xlabel(\"Modelos\")\n",
    "plt.ylabel(\"Mae\")\n",
    "plt.title(\"Error cuadrático medio por modelo\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size=7\n",
    "theta_size=8\n",
    "horizon=1\n",
    "n_neurons=512\n",
    "n_layers=4\n",
    "stacks_len = 30\n",
    "\n",
    "nbeats_input = layers.Input(shape=(input_size), name=\"input\")\n",
    "residuals = nbeats_input\n",
    "\n",
    "for i in range(stacks_len):\n",
    "    x = residuals\n",
    "    for j in range(n_layers):\n",
    "        x = layers.Dense(n_neurons, activation=\"relu\", name=f\"{j}_dense_{i}th_stack\")(x)\n",
    "    theta = layers.Dense(theta_size, activation=\"linear\")(x)\n",
    "    \n",
    "    backcast, block_forecast = theta[:, :input_size], theta[:, horizon:]\n",
    "    residuals = layers.subtract([residuals, backcast])\n",
    "    if not i:\n",
    "        forecast = block_forecast\n",
    "    else:\n",
    "        forecast = layers.add([forecast, block_forecast])\n",
    "        \n",
    "final_model = tf.keras.Model(inputs=nbeats_input, \n",
    "                         outputs=forecast, \n",
    "                         name=\"n-beats_final\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "27/27 [==============================] - ETA: 0s - loss: 1213.7345 - mae: 1213.7345INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 531ms/step - loss: 1213.7345 - mae: 1213.7345 - lr: 0.0010\n",
      "Epoch 2/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 800.3018 - mae: 800.3018INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 39s 1s/step - loss: 813.9907 - mae: 813.9907 - lr: 0.0010\n",
      "Epoch 3/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 679.3627 - mae: 679.3627INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 13s 497ms/step - loss: 690.5219 - mae: 690.5219 - lr: 0.0010\n",
      "Epoch 4/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 746.3253 - mae: 746.3253 - lr: 0.0010\n",
      "Epoch 5/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 706.7487 - mae: 706.7487 - lr: 0.0010\n",
      "Epoch 6/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 545.1367 - mae: 545.1367INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 527ms/step - loss: 608.8500 - mae: 608.8500 - lr: 0.0010\n",
      "Epoch 7/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 678.8967 - mae: 678.8967 - lr: 0.0010\n",
      "Epoch 8/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 1522.7642 - mae: 1522.7642 - lr: 0.0010\n",
      "Epoch 9/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1369.2271 - mae: 1369.2271 - lr: 0.0010\n",
      "Epoch 10/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 990.8228 - mae: 990.8228 - lr: 0.0010\n",
      "Epoch 11/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 768.3572 - mae: 768.3572 - lr: 0.0010\n",
      "Epoch 12/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 668.8444 - mae: 668.8444 - lr: 0.0010\n",
      "Epoch 13/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 711.1199 - mae: 711.1199 - lr: 0.0010\n",
      "Epoch 14/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 697.5695 - mae: 697.5695 - lr: 0.0010\n",
      "Epoch 15/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 673.3400 - mae: 673.3400 - lr: 0.0010\n",
      "Epoch 16/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 710.8631 - mae: 710.8631 - lr: 0.0010\n",
      "Epoch 17/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 740.8307 - mae: 740.8307 - lr: 0.0010\n",
      "Epoch 18/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 809.9542 - mae: 809.9542 - lr: 0.0010\n",
      "Epoch 19/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1544.7800 - mae: 1544.7800 - lr: 0.0010\n",
      "Epoch 20/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 3404.1963 - mae: 3404.1963 - lr: 0.0010\n",
      "Epoch 21/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 7469.3564 - mae: 7469.3564 - lr: 0.0010\n",
      "Epoch 22/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1573.3151 - mae: 1573.3151 - lr: 0.00104199 - mae:\n",
      "Epoch 23/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 720.6746 - mae: 720.6746 - lr: 0.0010\n",
      "Epoch 24/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 749.7117 - mae: 749.7117 - lr: 0.0010\n",
      "Epoch 25/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 709.1315 - mae: 709.1315 - lr: 0.0010\n",
      "Epoch 26/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 645.7153 - mae: 645.7153 - lr: 0.0010\n",
      "Epoch 27/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 528.1248 - mae: 528.1248INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 531ms/step - loss: 595.8406 - mae: 595.8406 - lr: 0.0010\n",
      "Epoch 28/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 575.9575 - mae: 575.9575INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 15s 549ms/step - loss: 587.1586 - mae: 587.1586 - lr: 0.0010\n",
      "Epoch 29/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 778.9254 - mae: 778.9254 - lr: 0.0010\n",
      "Epoch 30/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1481.1792 - mae: 1481.1792 - lr: 0.0010\n",
      "Epoch 31/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1692.0759 - mae: 1692.0759 - lr: 0.0010\n",
      "Epoch 32/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 8895.9473 - mae: 8895.9473 - lr: 0.0010\n",
      "Epoch 33/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1249.8865 - mae: 1249.8865 - lr: 0.0010\n",
      "Epoch 34/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 883.7161 - mae: 883.7161 - lr: 0.0010\n",
      "Epoch 35/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 735.7778 - mae: 735.7778 - lr: 0.0010\n",
      "Epoch 36/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 679.5480 - mae: 679.5480 - lr: 0.0010\n",
      "Epoch 37/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 722.9570 - mae: 722.9570 - lr: 0.0010\n",
      "Epoch 38/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 678.1424 - mae: 678.1424 - lr: 0.0010\n",
      "Epoch 39/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 709.7096 - mae: 709.7096 - lr: 0.0010\n",
      "Epoch 40/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 640.9097 - mae: 640.9097 - lr: 0.0010\n",
      "Epoch 41/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 752.9398 - mae: 752.9398 - lr: 0.0010462 - mae\n",
      "Epoch 42/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 638.1487 - mae: 638.1487 - lr: 0.0010\n",
      "Epoch 43/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 613.9211 - mae: 613.9211 - lr: 0.0010\n",
      "Epoch 44/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 631.9858 - mae: 631.9858 - lr: 0.0010\n",
      "Epoch 45/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 601.6729 - mae: 601.6729 - lr: 0.0010\n",
      "Epoch 46/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 686.3502 - mae: 686.3502 - lr: 0.0010467 - mae\n",
      "Epoch 47/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 804.7818 - mae: 804.7818 - lr: 0.0010\n",
      "Epoch 48/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 716.9810 - mae: 716.9810 - lr: 0.0010\n",
      "Epoch 49/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 645.4503 - mae: 645.4503 - lr: 0.0010\n",
      "Epoch 50/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 749.5226 - mae: 749.5226 - lr: 0.0010\n",
      "Epoch 51/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 646.6877 - mae: 646.6877 - lr: 0.0010\n",
      "Epoch 52/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 630.9604 - mae: 630.9604 - lr: 0.0010\n",
      "Epoch 53/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 636.4095 - mae: 636.4095 - lr: 0.0010\n",
      "Epoch 54/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 600.5949 - mae: 600.5949 - lr: 0.0010\n",
      "Epoch 55/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 641.7875 - mae: 641.7875 - lr: 0.0010\n",
      "Epoch 56/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 665.0133 - mae: 665.0133 - lr: 0.0010\n",
      "Epoch 57/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 715.6631 - mae: 715.6631 - lr: 0.0010\n",
      "Epoch 58/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 732.8472 - mae: 732.8472 - lr: 0.0010\n",
      "Epoch 59/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 688.7838 - mae: 688.7838 - lr: 0.0010\n",
      "Epoch 60/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 639.5840 - mae: 639.5840 - lr: 0.0010\n",
      "Epoch 61/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 607.2587 - mae: 607.2587 - lr: 0.0010\n",
      "Epoch 62/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 659.7926 - mae: 659.7926 - lr: 0.0010\n",
      "Epoch 63/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 647.3972 - mae: 647.3972 - lr: 0.0010\n",
      "Epoch 64/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 724.6003 - mae: 724.6003 - lr: 0.0010\n",
      "Epoch 65/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 23ms/step - loss: 642.3176 - mae: 642.3176 - lr: 0.0010\n",
      "Epoch 66/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 642.4496 - mae: 642.4496 - lr: 0.0010\n",
      "Epoch 67/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 626.6760 - mae: 626.6760 - lr: 0.0010\n",
      "Epoch 68/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 740.1990 - mae: 740.1990 - lr: 0.0010\n",
      "Epoch 69/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 716.2601 - mae: 716.2601 - lr: 0.0010\n",
      "Epoch 70/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 690.4876 - mae: 690.4876 - lr: 0.0010\n",
      "Epoch 71/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 710.7297 - mae: 710.7297 - lr: 0.0010\n",
      "Epoch 72/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 669.3033 - mae: 669.3033 - lr: 0.0010\n",
      "Epoch 73/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 632.5269 - mae: 632.5269 - lr: 0.0010\n",
      "Epoch 74/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 634.7903 - mae: 634.7903 - lr: 0.0010\n",
      "Epoch 75/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 636.9072 - mae: 636.9072 - lr: 0.0010\n",
      "Epoch 76/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 623.1715 - mae: 623.1715 - lr: 0.0010\n",
      "Epoch 77/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 634.2933 - mae: 634.2933 - lr: 0.0010\n",
      "Epoch 78/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 757.6772 - mae: 757.6772 - lr: 0.0010\n",
      "Epoch 79/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 700.1301 - mae: 700.1301 - lr: 0.0010\n",
      "Epoch 80/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 650.7051 - mae: 650.7051 - lr: 0.0010\n",
      "Epoch 81/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 725.1028 - mae: 725.1028 - lr: 0.0010\n",
      "Epoch 82/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 711.1331 - mae: 711.1331 - lr: 0.0010\n",
      "Epoch 83/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 699.9572 - mae: 699.9572 - lr: 0.0010\n",
      "Epoch 84/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 720.3071 - mae: 720.3071 - lr: 0.0010\n",
      "Epoch 85/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 643.7415 - mae: 643.7415 - lr: 0.0010\n",
      "Epoch 86/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 646.7079 - mae: 646.7079 - lr: 0.0010\n",
      "Epoch 87/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 654.7206 - mae: 654.7206 - lr: 0.0010\n",
      "Epoch 88/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 631.3710 - mae: 631.3710 - lr: 0.0010\n",
      "Epoch 89/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 606.7476 - mae: 606.7476 - lr: 0.0010\n",
      "Epoch 90/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 683.3028 - mae: 683.3028 - lr: 0.0010\n",
      "Epoch 91/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 664.9001 - mae: 664.9001 - lr: 0.0010.8501 - mae:\n",
      "Epoch 92/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 669.2824 - mae: 669.2824 - lr: 0.0010\n",
      "Epoch 93/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 655.1800 - mae: 655.1800 - lr: 0.0010\n",
      "Epoch 94/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 634.1178 - mae: 634.1178 - lr: 0.0010\n",
      "Epoch 95/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 657.1893 - mae: 657.1893 - lr: 0.0010\n",
      "Epoch 96/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 653.5427 - mae: 653.5427 - lr: 0.0010\n",
      "Epoch 97/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 632.6095 - mae: 632.6095 - lr: 0.0010\n",
      "Epoch 98/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 646.9828 - mae: 646.9828 - lr: 0.0010\n",
      "Epoch 99/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 636.9434 - mae: 636.9434 - lr: 0.0010\n",
      "Epoch 100/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 649.9967 - mae: 649.9967 - lr: 0.0010\n",
      "Epoch 101/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 746.9957 - mae: 746.9957 - lr: 0.0010\n",
      "Epoch 102/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 704.2236 - mae: 704.2236 - lr: 0.0010\n",
      "Epoch 103/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 671.4990 - mae: 671.4990 - lr: 0.0010\n",
      "Epoch 104/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 634.2484 - mae: 634.2484 - lr: 0.0010\n",
      "Epoch 105/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 625.8576 - mae: 625.8576 - lr: 0.0010\n",
      "Epoch 106/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 682.5686 - mae: 682.5686 - lr: 0.0010\n",
      "Epoch 107/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 800.3607 - mae: 800.3607 - lr: 0.0010\n",
      "Epoch 108/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 665.5082 - mae: 665.5082 - lr: 0.0010\n",
      "Epoch 109/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 760.5154 - mae: 760.5154 - lr: 0.0010\n",
      "Epoch 110/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 649.7507 - mae: 649.7507 - lr: 0.0010\n",
      "Epoch 111/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 665.6578 - mae: 665.6578 - lr: 0.0010\n",
      "Epoch 112/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 649.0345 - mae: 649.0345 - lr: 0.0010\n",
      "Epoch 113/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 649.7181 - mae: 649.7181 - lr: 0.0010\n",
      "Epoch 114/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 651.0355 - mae: 651.0355 - lr: 0.0010\n",
      "Epoch 115/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 618.5157 - mae: 618.5157 - lr: 0.0010\n",
      "Epoch 116/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 633.4728 - mae: 633.4728 - lr: 0.0010\n",
      "Epoch 117/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 699.0197 - mae: 699.0197 - lr: 0.0010\n",
      "Epoch 118/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 765.3386 - mae: 765.3386 - lr: 0.0010\n",
      "Epoch 119/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 634.5358 - mae: 634.5358 - lr: 0.0010\n",
      "Epoch 120/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 632.0446 - mae: 632.0446 - lr: 0.0010\n",
      "Epoch 121/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 777.3744 - mae: 777.3744 - lr: 0.0010\n",
      "Epoch 122/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 784.8459 - mae: 784.8459 - lr: 0.0010\n",
      "Epoch 123/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 1102.1783 - mae: 1102.1783 - lr: 0.0010\n",
      "Epoch 124/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 718.7972 - mae: 718.7972 - lr: 0.0010\n",
      "Epoch 125/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 638.7424 - mae: 638.7424 - lr: 0.0010\n",
      "Epoch 126/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 625.1339 - mae: 625.1339 - lr: 0.0010\n",
      "Epoch 127/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 592.8276 - mae: 592.8276 - lr: 0.0010\n",
      "Epoch 128/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 681.8112 - mae: 681.8112 - lr: 0.0010\n",
      "Epoch 129/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 647.3232 - mae: 647.3232 - lr: 1.0000e-04\n",
      "Epoch 130/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 640.8082 - mae: 640.8082 - lr: 1.0000e-04\n",
      "Epoch 131/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 635.5644 - mae: 635.5644 - lr: 1.0000e-04\n",
      "Epoch 132/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 632.8295 - mae: 632.8295 - lr: 1.0000e-04\n",
      "Epoch 133/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 631.9633 - mae: 631.9633 - lr: 1.0000e-04\n",
      "Epoch 134/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 631.3719 - mae: 631.3719 - lr: 1.0000e-04\n",
      "Epoch 135/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 631.1025 - mae: 631.1025 - lr: 1.0000e-04\n",
      "Epoch 136/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 631.0613 - mae: 631.0613 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 137/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 629.9507 - mae: 629.9507 - lr: 1.0000e-04\n",
      "Epoch 138/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 628.6410 - mae: 628.6410 - lr: 1.0000e-04\n",
      "Epoch 139/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 627.2213 - mae: 627.2213 - lr: 1.0000e-04\n",
      "Epoch 140/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 625.1262 - mae: 625.1262 - lr: 1.0000e-04\n",
      "Epoch 141/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 621.6926 - mae: 621.6926 - lr: 1.0000e-04\n",
      "Epoch 142/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 617.0319 - mae: 617.0319 - lr: 1.0000e-04\n",
      "Epoch 143/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 617.6322 - mae: 617.6322 - lr: 1.0000e-04\n",
      "Epoch 144/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 608.0999 - mae: 608.0999 - lr: 1.0000e-04\n",
      "Epoch 145/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 587.7949 - mae: 587.7949 - lr: 1.0000e-04\n",
      "Epoch 146/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 619.9069 - mae: 619.9069 - lr: 1.0000e-04\n",
      "Epoch 147/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 524.8071 - mae: 524.8071INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 15s 542ms/step - loss: 578.4265 - mae: 578.4265 - lr: 1.0000e-04\n",
      "Epoch 148/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 510.5850 - mae: 510.5850INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 15s 567ms/step - loss: 558.7598 - mae: 558.7598 - lr: 1.0000e-04\n",
      "Epoch 149/500\n",
      "27/27 [==============================] - ETA: 0s - loss: 502.8193 - mae: 502.8193INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 519ms/step - loss: 502.8193 - mae: 502.8193 - lr: 1.0000e-04\n",
      "Epoch 150/500\n",
      "27/27 [==============================] - ETA: 0s - loss: 444.0893 - mae: 444.0893INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 502ms/step - loss: 444.0893 - mae: 444.0893 - lr: 1.0000e-04\n",
      "Epoch 151/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 421.9858 - mae: 421.9858INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 15s 548ms/step - loss: 429.0435 - mae: 429.0435 - lr: 1.0000e-04\n",
      "Epoch 152/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 405.2915 - mae: 405.2915INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 533ms/step - loss: 412.4098 - mae: 412.4098 - lr: 1.0000e-04\n",
      "Epoch 153/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 449.4351 - mae: 449.4351 - lr: 1.0000e-04\n",
      "Epoch 154/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 436.5505 - mae: 436.5505 - lr: 1.0000e-04\n",
      "Epoch 155/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 413.7952 - mae: 413.7952 - lr: 1.0000e-04\n",
      "Epoch 156/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 361.0681 - mae: 361.0681INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 524ms/step - loss: 403.0639 - mae: 403.0639 - lr: 1.0000e-04\n",
      "Epoch 157/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 358.0877 - mae: 358.0877INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 509ms/step - loss: 399.7322 - mae: 399.7322 - lr: 1.0000e-04\n",
      "Epoch 158/500\n",
      "27/27 [==============================] - ETA: 0s - loss: 396.5502 - mae: 396.5502INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 13s 499ms/step - loss: 396.5502 - mae: 396.5502 - lr: 1.0000e-04\n",
      "Epoch 159/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 403.4320 - mae: 403.4320 - lr: 1.0000e-04\n",
      "Epoch 160/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 422.9377 - mae: 422.9377 - lr: 1.0000e-04\n",
      "Epoch 161/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 423.2423 - mae: 423.2423 - lr: 1.0000e-04\n",
      "Epoch 162/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 441.7742 - mae: 441.7742 - lr: 1.0000e-04\n",
      "Epoch 163/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 408.1988 - mae: 408.1988 - lr: 1.0000e-04\n",
      "Epoch 164/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 416.5455 - mae: 416.5455 - lr: 1.0000e-04\n",
      "Epoch 165/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 431.7894 - mae: 431.7894 - lr: 1.0000e-04\n",
      "Epoch 166/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 553.2746 - mae: 553.2746 - lr: 1.0000e-04\n",
      "Epoch 167/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 467.4282 - mae: 467.4282 - lr: 1.0000e-04\n",
      "Epoch 168/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 471.3059 - mae: 471.3059 - lr: 1.0000e-04\n",
      "Epoch 169/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 424.5394 - mae: 424.5394 - lr: 1.0000e-04\n",
      "Epoch 170/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 445.0095 - mae: 445.0095 - lr: 1.0000e-04\n",
      "Epoch 171/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 406.3152 - mae: 406.3152 - lr: 1.0000e-04\n",
      "Epoch 172/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 424.5449 - mae: 424.5449 - lr: 1.0000e-04\n",
      "Epoch 173/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 414.7322 - mae: 414.7322 - lr: 1.0000e-04\n",
      "Epoch 174/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 405.1928 - mae: 405.1928 - lr: 1.0000e-04\n",
      "Epoch 175/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 402.4891 - mae: 402.4891 - lr: 1.0000e-04\n",
      "Epoch 176/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 424.8507 - mae: 424.8507 - lr: 1.0000e-04\n",
      "Epoch 177/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 411.1606 - mae: 411.1606 - lr: 1.0000e-04\n",
      "Epoch 178/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 430.1502 - mae: 430.1502 - lr: 1.0000e-04\n",
      "Epoch 179/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 413.1814 - mae: 413.1814 - lr: 1.0000e-04\n",
      "Epoch 180/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 431.7748 - mae: 431.7748 - lr: 1.0000e-04\n",
      "Epoch 181/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 420.9169 - mae: 420.9169 - lr: 1.0000e-04\n",
      "Epoch 182/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 452.0504 - mae: 452.0504 - lr: 1.0000e-04\n",
      "Epoch 183/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 438.8011 - mae: 438.8011 - lr: 1.0000e-04\n",
      "Epoch 184/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 441.4866 - mae: 441.4866 - lr: 1.0000e-04\n",
      "Epoch 185/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 417.1815 - mae: 417.1815 - lr: 1.0000e-04\n",
      "Epoch 186/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 418.6281 - mae: 418.6281 - lr: 1.0000e-04\n",
      "Epoch 187/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 409.4605 - mae: 409.4605 - lr: 1.0000e-04\n",
      "Epoch 188/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 437.9133 - mae: 437.9133 - lr: 1.0000e-04\n",
      "Epoch 189/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 429.8857 - mae: 429.8857 - lr: 1.0000e-04\n",
      "Epoch 190/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 466.0189 - mae: 466.0189 - lr: 1.0000e-04\n",
      "Epoch 191/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 462.0897 - mae: 462.0897 - lr: 1.0000e-04\n",
      "Epoch 192/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 424.0902 - mae: 424.0902 - lr: 1.0000e-04\n",
      "Epoch 193/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 433.5266 - mae: 433.5266 - lr: 1.0000e-04\n",
      "Epoch 194/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 473.3563 - mae: 473.3563 - lr: 1.0000e-04\n",
      "Epoch 195/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 23ms/step - loss: 520.6212 - mae: 520.6212 - lr: 1.0000e-04\n",
      "Epoch 196/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 546.1832 - mae: 546.1832 - lr: 1.0000e-04\n",
      "Epoch 197/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 541.8028 - mae: 541.8028 - lr: 1.0000e-04\n",
      "Epoch 198/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 473.5881 - mae: 473.5881 - lr: 1.0000e-04\n",
      "Epoch 199/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 501.3593 - mae: 501.3593 - lr: 1.0000e-04\n",
      "Epoch 200/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 473.8696 - mae: 473.8696 - lr: 1.0000e-04\n",
      "Epoch 201/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 517.0094 - mae: 517.0094 - lr: 1.0000e-048 - mae:\n",
      "Epoch 202/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 497.9398 - mae: 497.9398 - lr: 1.0000e-04\n",
      "Epoch 203/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 453.8497 - mae: 453.8497 - lr: 1.0000e-04\n",
      "Epoch 204/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 486.8456 - mae: 486.8456 - lr: 1.0000e-04\n",
      "Epoch 205/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 470.7688 - mae: 470.7688 - lr: 1.0000e-04\n",
      "Epoch 206/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 477.5566 - mae: 477.5566 - lr: 1.0000e-04\n",
      "Epoch 207/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 468.6133 - mae: 468.6133 - lr: 1.0000e-04\n",
      "Epoch 208/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 463.3983 - mae: 463.3983 - lr: 1.0000e-04\n",
      "Epoch 209/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 457.0566 - mae: 457.0566 - lr: 1.0000e-04\n",
      "Epoch 210/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 475.1724 - mae: 475.1724 - lr: 1.0000e-04\n",
      "Epoch 211/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 442.2045 - mae: 442.2045 - lr: 1.0000e-04\n",
      "Epoch 212/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 452.6425 - mae: 452.6425 - lr: 1.0000e-04\n",
      "Epoch 213/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 457.1973 - mae: 457.1973 - lr: 1.0000e-04\n",
      "Epoch 214/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 441.0257 - mae: 441.0257 - lr: 1.0000e-04\n",
      "Epoch 215/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 452.1405 - mae: 452.1405 - lr: 1.0000e-04\n",
      "Epoch 216/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 423.6055 - mae: 423.6055 - lr: 1.0000e-04\n",
      "Epoch 217/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 439.6573 - mae: 439.6573 - lr: 1.0000e-04\n",
      "Epoch 218/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 430.3590 - mae: 430.3590 - lr: 1.0000e-04\n",
      "Epoch 219/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 445.1233 - mae: 445.1233 - lr: 1.0000e-04\n",
      "Epoch 220/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 427.7811 - mae: 427.7811 - lr: 1.0000e-04\n",
      "Epoch 221/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 438.6915 - mae: 438.6915 - lr: 1.0000e-04\n",
      "Epoch 222/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 426.4566 - mae: 426.4566 - lr: 1.0000e-044 - mae:\n",
      "Epoch 223/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 440.4133 - mae: 440.4133 - lr: 1.0000e-04\n",
      "Epoch 224/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 421.0268 - mae: 421.0268 - lr: 1.0000e-04\n",
      "Epoch 225/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 434.9491 - mae: 434.9491 - lr: 1.0000e-04\n",
      "Epoch 226/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 418.4106 - mae: 418.4106 - lr: 1.0000e-04\n",
      "Epoch 227/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 435.2118 - mae: 435.2118 - lr: 1.0000e-04\n",
      "Epoch 228/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 419.1214 - mae: 419.1214 - lr: 1.0000e-04\n",
      "Epoch 229/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 429.5425 - mae: 429.5425 - lr: 1.0000e-04\n",
      "Epoch 230/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 422.4210 - mae: 422.4210 - lr: 1.0000e-04\n",
      "Epoch 231/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 431.3781 - mae: 431.3781 - lr: 1.0000e-04\n",
      "Epoch 232/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 428.5378 - mae: 428.5378 - lr: 1.0000e-04\n",
      "Epoch 233/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 431.2338 - mae: 431.2338 - lr: 1.0000e-04\n",
      "Epoch 234/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 432.8380 - mae: 432.8380 - lr: 1.0000e-04\n",
      "Epoch 235/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 408.1323 - mae: 408.1323 - lr: 1.0000e-04\n",
      "Epoch 236/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 421.8663 - mae: 421.8663 - lr: 1.0000e-04\n",
      "Epoch 237/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 463.7988 - mae: 463.7988 - lr: 1.0000e-04\n",
      "Epoch 238/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 415.6721 - mae: 415.6721 - lr: 1.0000e-04\n",
      "Epoch 239/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 435.3609 - mae: 435.3609 - lr: 1.0000e-04\n",
      "Epoch 240/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 417.1889 - mae: 417.1889 - lr: 1.0000e-04\n",
      "Epoch 241/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 423.8736 - mae: 423.8736 - lr: 1.0000e-04\n",
      "Epoch 242/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 441.7036 - mae: 441.7036 - lr: 1.0000e-04\n",
      "Epoch 243/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 455.1502 - mae: 455.1502 - lr: 1.0000e-04\n",
      "Epoch 244/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 448.5164 - mae: 448.5164 - lr: 1.0000e-04\n",
      "Epoch 245/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 420.7401 - mae: 420.7401 - lr: 1.0000e-04\n",
      "Epoch 246/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 426.2848 - mae: 426.2848 - lr: 1.0000e-04\n",
      "Epoch 247/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 439.8129 - mae: 439.8129 - lr: 1.0000e-04\n",
      "Epoch 248/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 421.3573 - mae: 421.3573 - lr: 1.0000e-04\n",
      "Epoch 249/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 423.0737 - mae: 423.0737 - lr: 1.0000e-04\n",
      "Epoch 250/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 409.2332 - mae: 409.2332 - lr: 1.0000e-04\n",
      "Epoch 251/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 418.4377 - mae: 418.4377 - lr: 1.0000e-04\n",
      "Epoch 252/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 413.2559 - mae: 413.2559 - lr: 1.0000e-04\n",
      "Epoch 253/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 412.6306 - mae: 412.6306 - lr: 1.0000e-04\n",
      "Epoch 254/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 422.5093 - mae: 422.5093 - lr: 1.0000e-04\n",
      "Epoch 255/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 438.1246 - mae: 438.1246 - lr: 1.0000e-04\n",
      "Epoch 256/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 427.4925 - mae: 427.4925 - lr: 1.0000e-04\n",
      "Epoch 257/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 354.8194 - mae: 354.8194INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 16s 606ms/step - loss: 395.5650 - mae: 395.5650 - lr: 1.0000e-04\n",
      "Epoch 258/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 383.6460 - mae: 383.6460INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 15s 563ms/step - loss: 389.8961 - mae: 389.8961 - lr: 1.0000e-04\n",
      "Epoch 259/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 403.3973 - mae: 403.3973 - lr: 1.0000e-04\n",
      "Epoch 260/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 417.2073 - mae: 417.2073 - lr: 1.0000e-04\n",
      "Epoch 261/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 427.7226 - mae: 427.7226 - lr: 1.0000e-04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 262/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 425.7500 - mae: 425.7500 - lr: 1.0000e-04\n",
      "Epoch 263/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 426.3745 - mae: 426.3745 - lr: 1.0000e-04\n",
      "Epoch 264/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 434.6801 - mae: 434.6801 - lr: 1.0000e-04\n",
      "Epoch 265/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 437.6843 - mae: 437.6843 - lr: 1.0000e-04\n",
      "Epoch 266/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 420.1735 - mae: 420.1735 - lr: 1.0000e-045 - mae:\n",
      "Epoch 267/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 424.2545 - mae: 424.2545 - lr: 1.0000e-04\n",
      "Epoch 268/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 406.7913 - mae: 406.7913 - lr: 1.0000e-04\n",
      "Epoch 269/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 408.5867 - mae: 408.5867 - lr: 1.0000e-04\n",
      "Epoch 270/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 420.1844 - mae: 420.1844 - lr: 1.0000e-04\n",
      "Epoch 271/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 424.8123 - mae: 424.8123 - lr: 1.0000e-04\n",
      "Epoch 272/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 436.5606 - mae: 436.5606 - lr: 1.0000e-04\n",
      "Epoch 273/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 439.5616 - mae: 439.5616 - lr: 1.0000e-04\n",
      "Epoch 274/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 408.3284 - mae: 408.3284 - lr: 1.0000e-04\n",
      "Epoch 275/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 411.7237 - mae: 411.7237 - lr: 1.0000e-04\n",
      "Epoch 276/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 412.6684 - mae: 412.6684 - lr: 1.0000e-04\n",
      "Epoch 277/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 421.5164 - mae: 421.5164 - lr: 1.0000e-04\n",
      "Epoch 278/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 400.9903 - mae: 400.9903 - lr: 1.0000e-04\n",
      "Epoch 279/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 407.9280 - mae: 407.9280 - lr: 1.0000e-04\n",
      "Epoch 280/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 405.0621 - mae: 405.0621 - lr: 1.0000e-04\n",
      "Epoch 281/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 411.4278 - mae: 411.4278 - lr: 1.0000e-04\n",
      "Epoch 282/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 412.5156 - mae: 412.5156 - lr: 1.0000e-04\n",
      "Epoch 283/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 423.5475 - mae: 423.5475 - lr: 1.0000e-04\n",
      "Epoch 284/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 406.8600 - mae: 406.8600 - lr: 1.0000e-04\n",
      "Epoch 285/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 408.0678 - mae: 408.0678 - lr: 1.0000e-04\n",
      "Epoch 286/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 406.6743 - mae: 406.6743 - lr: 1.0000e-04\n",
      "Epoch 287/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 398.7762 - mae: 398.7762 - lr: 1.0000e-04\n",
      "Epoch 288/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 345.9375 - mae: 345.9375INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 512ms/step - loss: 385.6457 - mae: 385.6457 - lr: 1.0000e-04\n",
      "Epoch 289/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 387.4221 - mae: 387.4221 - lr: 1.0000e-04\n",
      "Epoch 290/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 395.1396 - mae: 395.1396 - lr: 1.0000e-04\n",
      "Epoch 291/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 410.0000 - mae: 410.0000 - lr: 1.0000e-04\n",
      "Epoch 292/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 410.6658 - mae: 410.6658 - lr: 1.0000e-04\n",
      "Epoch 293/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 407.5472 - mae: 407.5472 - lr: 1.0000e-04\n",
      "Epoch 294/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 403.5433 - mae: 403.5433 - lr: 1.0000e-04\n",
      "Epoch 295/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 420.4766 - mae: 420.4766 - lr: 1.0000e-04\n",
      "Epoch 296/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 403.4525 - mae: 403.4525 - lr: 1.0000e-04- mae\n",
      "Epoch 297/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 413.2566 - mae: 413.2567 - lr: 1.0000e-04\n",
      "Epoch 298/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 397.6011 - mae: 397.6011 - lr: 1.0000e-04\n",
      "Epoch 299/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 393.5998 - mae: 393.5998 - lr: 1.0000e-04\n",
      "Epoch 300/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 400.1251 - mae: 400.1251 - lr: 1.0000e-04\n",
      "Epoch 301/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 394.4387 - mae: 394.4387 - lr: 1.0000e-04\n",
      "Epoch 302/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 402.3542 - mae: 402.3542 - lr: 1.0000e-04\n",
      "Epoch 303/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 394.0373 - mae: 394.0373 - lr: 1.0000e-04\n",
      "Epoch 304/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 404.6684 - mae: 404.6684 - lr: 1.0000e-04\n",
      "Epoch 305/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 397.1555 - mae: 397.1555 - lr: 1.0000e-04\n",
      "Epoch 306/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 392.5803 - mae: 392.5803 - lr: 1.0000e-04\n",
      "Epoch 307/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 389.4149 - mae: 389.4149 - lr: 1.0000e-04\n",
      "Epoch 308/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 395.3316 - mae: 395.3316 - lr: 1.0000e-04\n",
      "Epoch 309/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 395.8239 - mae: 395.8239 - lr: 1.0000e-04\n",
      "Epoch 310/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 405.0768 - mae: 405.0768 - lr: 1.0000e-04\n",
      "Epoch 311/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 396.3830 - mae: 396.3830 - lr: 1.0000e-04\n",
      "Epoch 312/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 396.2869 - mae: 396.2869 - lr: 1.0000e-04\n",
      "Epoch 313/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 390.8185 - mae: 390.8185 - lr: 1.0000e-04\n",
      "Epoch 314/500\n",
      "27/27 [==============================] - ETA: 0s - loss: 378.6825 - mae: 378.6825INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 523ms/step - loss: 378.6825 - mae: 378.6825 - lr: 1.0000e-04\n",
      "Epoch 315/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 381.5865 - mae: 381.5865 - lr: 1.0000e-04\n",
      "Epoch 316/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 385.1218 - mae: 385.1218 - lr: 1.0000e-04\n",
      "Epoch 317/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 390.2299 - mae: 390.2299 - lr: 1.0000e-04\n",
      "Epoch 318/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 383.8033 - mae: 383.8033 - lr: 1.0000e-04\n",
      "Epoch 319/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 380.9654 - mae: 380.9654 - lr: 1.0000e-04\n",
      "Epoch 320/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 384.7404 - mae: 384.7404 - lr: 1.0000e-04\n",
      "Epoch 321/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 335.0958 - mae: 335.0958INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 527ms/step - loss: 372.9330 - mae: 372.9330 - lr: 1.0000e-04\n",
      "Epoch 322/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 364.7952 - mae: 364.7952INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 15s 555ms/step - loss: 370.2157 - mae: 370.2157 - lr: 1.0000e-04\n",
      "Epoch 323/500\n",
      "27/27 [==============================] - ETA: 0s - loss: 368.3993 - mae: 368.3993INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 529ms/step - loss: 368.3993 - mae: 368.3993 - lr: 1.0000e-04\n",
      "Epoch 324/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 373.4109 - mae: 373.4109 - lr: 1.0000e-04\n",
      "Epoch 325/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 23ms/step - loss: 378.9962 - mae: 378.9962 - lr: 1.0000e-04\n",
      "Epoch 326/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 388.2555 - mae: 388.2555 - lr: 1.0000e-04\n",
      "Epoch 327/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 375.8752 - mae: 375.8752 - lr: 1.0000e-04\n",
      "Epoch 328/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 372.4454 - mae: 372.4454 - lr: 1.0000e-04\n",
      "Epoch 329/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 331.5222 - mae: 331.5222INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 523ms/step - loss: 367.9868 - mae: 367.9868 - lr: 1.0000e-04\n",
      "Epoch 330/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 376.4437 - mae: 376.4437 - lr: 1.0000e-04\n",
      "Epoch 331/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 327.0630 - mae: 327.0630INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 527ms/step - loss: 362.8073 - mae: 362.8073 - lr: 1.0000e-04\n",
      "Epoch 332/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 369.9898 - mae: 369.9898 - lr: 1.0000e-04\n",
      "Epoch 333/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 363.0882 - mae: 363.0882 - lr: 1.0000e-04\n",
      "Epoch 334/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 369.6629 - mae: 369.6629 - lr: 1.0000e-04\n",
      "Epoch 335/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 322.5557 - mae: 322.5557INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 525ms/step - loss: 358.2389 - mae: 358.2389 - lr: 1.0000e-04\n",
      "Epoch 336/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 363.6310 - mae: 363.6310 - lr: 1.0000e-04\n",
      "Epoch 337/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 368.4496 - mae: 368.4496 - lr: 1.0000e-04\n",
      "Epoch 338/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 384.7362 - mae: 384.7362 - lr: 1.0000e-04\n",
      "Epoch 339/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 383.4661 - mae: 383.4661 - lr: 1.0000e-04\n",
      "Epoch 340/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 359.0510 - mae: 359.0510 - lr: 1.0000e-04\n",
      "Epoch 341/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 364.6530 - mae: 364.6530 - lr: 1.0000e-04\n",
      "Epoch 342/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 366.8529 - mae: 366.8529 - lr: 1.0000e-04\n",
      "Epoch 343/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 376.6344 - mae: 376.6344 - lr: 1.0000e-04\n",
      "Epoch 344/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 359.5828 - mae: 359.5828 - lr: 1.0000e-04\n",
      "Epoch 345/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 361.9545 - mae: 361.9545 - lr: 1.0000e-04\n",
      "Epoch 346/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 321.5436 - mae: 321.5436INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 521ms/step - loss: 355.9833 - mae: 355.9833 - lr: 1.0000e-04\n",
      "Epoch 347/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 356.6452 - mae: 356.6452 - lr: 1.0000e-04\n",
      "Epoch 348/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 319.7287 - mae: 319.7287INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 514ms/step - loss: 353.4575 - mae: 353.4575 - lr: 1.0000e-04\n",
      "Epoch 349/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 368.0373 - mae: 368.0373 - lr: 1.0000e-04\n",
      "Epoch 350/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 313.4449 - mae: 313.4449INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 505ms/step - loss: 347.5070 - mae: 347.5070 - lr: 1.0000e-04\n",
      "Epoch 351/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 351.3765 - mae: 351.3765 - lr: 1.0000e-04\n",
      "Epoch 352/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 348.3553 - mae: 348.3553 - lr: 1.0000e-04\n",
      "Epoch 353/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 356.1700 - mae: 356.1700 - lr: 1.0000e-04\n",
      "Epoch 354/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 353.9575 - mae: 353.9575 - lr: 1.0000e-04\n",
      "Epoch 355/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 355.9750 - mae: 355.9750 - lr: 1.0000e-04\n",
      "Epoch 356/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 312.5840 - mae: 312.5840INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 13s 492ms/step - loss: 346.4355 - mae: 346.4355 - lr: 1.0000e-04\n",
      "Epoch 357/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 348.2166 - mae: 348.2166 - lr: 1.0000e-04\n",
      "Epoch 358/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 309.7187 - mae: 309.7187INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 500ms/step - loss: 342.5994 - mae: 342.5994 - lr: 1.0000e-04\n",
      "Epoch 359/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 381.4437 - mae: 381.4437 - lr: 1.0000e-04\n",
      "Epoch 360/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 352.1610 - mae: 352.1610 - lr: 1.0000e-04\n",
      "Epoch 361/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 355.3736 - mae: 355.3736 - lr: 1.0000e-04\n",
      "Epoch 362/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 357.1921 - mae: 357.1921 - lr: 1.0000e-04\n",
      "Epoch 363/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 367.0988 - mae: 367.0988 - lr: 1.0000e-04\n",
      "Epoch 364/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 372.8950 - mae: 372.8950 - lr: 1.0000e-04\n",
      "Epoch 365/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 368.9818 - mae: 368.9818 - lr: 1.0000e-04\n",
      "Epoch 366/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 344.0183 - mae: 344.0183 - lr: 1.0000e-04\n",
      "Epoch 367/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 308.4886 - mae: 308.4886INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 15s 558ms/step - loss: 342.0637 - mae: 342.0637 - lr: 1.0000e-04\n",
      "Epoch 368/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 354.8760 - mae: 354.8760 - lr: 1.0000e-04\n",
      "Epoch 369/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 352.3004 - mae: 352.3004 - lr: 1.0000e-04\n",
      "Epoch 370/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 357.5499 - mae: 357.5499 - lr: 1.0000e-04\n",
      "Epoch 371/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 337.1699 - mae: 337.1699INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 15s 560ms/step - loss: 341.3960 - mae: 341.3960 - lr: 1.0000e-04\n",
      "Epoch 372/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 303.8072 - mae: 303.8072INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 504ms/step - loss: 336.3571 - mae: 336.3571 - lr: 1.0000e-04\n",
      "Epoch 373/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 352.3748 - mae: 352.3748 - lr: 1.0000e-04\n",
      "Epoch 374/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 344.4156 - mae: 344.4156 - lr: 1.0000e-04\n",
      "Epoch 375/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 298.9462 - mae: 298.9462INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 14s 531ms/step - loss: 331.3210 - mae: 331.3210 - lr: 1.0000e-04\n",
      "Epoch 376/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 342.3459 - mae: 342.3459 - lr: 1.0000e-04\n",
      "Epoch 377/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 340.8143 - mae: 340.8143 - lr: 1.0000e-04\n",
      "Epoch 378/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 350.5249 - mae: 350.5249 - lr: 1.0000e-04\n",
      "Epoch 379/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 23ms/step - loss: 340.4543 - mae: 340.4543 - lr: 1.0000e-04\n",
      "Epoch 380/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 353.8888 - mae: 353.8888 - lr: 1.0000e-04\n",
      "Epoch 381/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 362.5021 - mae: 362.5021 - lr: 1.0000e-04\n",
      "Epoch 382/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 344.5569 - mae: 344.5569 - lr: 1.0000e-04\n",
      "Epoch 383/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 348.1424 - mae: 348.1424 - lr: 1.0000e-04\n",
      "Epoch 384/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 366.5113 - mae: 366.5113 - lr: 1.0000e-04\n",
      "Epoch 385/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 357.8914 - mae: 357.8914 - lr: 1.0000e-04\n",
      "Epoch 386/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 342.0577 - mae: 342.0577 - lr: 1.0000e-04\n",
      "Epoch 387/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 369.2531 - mae: 369.2531 - lr: 1.0000e-04\n",
      "Epoch 388/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 364.6796 - mae: 364.6796 - lr: 1.0000e-04\n",
      "Epoch 389/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 351.8775 - mae: 351.8775 - lr: 1.0000e-04\n",
      "Epoch 390/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 349.5650 - mae: 349.5650 - lr: 1.0000e-04\n",
      "Epoch 391/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 358.8210 - mae: 358.8210 - lr: 1.0000e-04\n",
      "Epoch 392/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 344.3916 - mae: 344.3916 - lr: 1.0000e-04\n",
      "Epoch 393/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 365.0479 - mae: 365.0479 - lr: 1.0000e-04\n",
      "Epoch 394/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 359.1868 - mae: 359.1868 - lr: 1.0000e-04\n",
      "Epoch 395/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 343.6700 - mae: 343.6700 - lr: 1.0000e-04\n",
      "Epoch 396/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 360.8414 - mae: 360.8414 - lr: 1.0000e-04\n",
      "Epoch 397/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 363.7624 - mae: 363.7624 - lr: 1.0000e-04\n",
      "Epoch 398/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 350.6204 - mae: 350.6204 - lr: 1.0000e-04\n",
      "Epoch 399/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 350.3584 - mae: 350.3584 - lr: 1.0000e-04\n",
      "Epoch 400/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 350.3698 - mae: 350.3698 - lr: 1.0000e-04\n",
      "Epoch 401/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 351.1940 - mae: 351.1940 - lr: 1.0000e-04\n",
      "Epoch 402/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 342.6418 - mae: 342.6418 - lr: 1.0000e-04\n",
      "Epoch 403/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 336.6704 - mae: 336.6704 - lr: 1.0000e-04\n",
      "Epoch 404/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 361.1616 - mae: 361.1616 - lr: 1.0000e-04\n",
      "Epoch 405/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 352.6447 - mae: 352.6447 - lr: 1.0000e-04\n",
      "Epoch 406/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 348.8088 - mae: 348.8088 - lr: 1.0000e-04\n",
      "Epoch 407/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 347.4085 - mae: 347.4085 - lr: 1.0000e-04\n",
      "Epoch 408/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 367.9622 - mae: 367.9622 - lr: 1.0000e-04\n",
      "Epoch 409/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 384.3607 - mae: 384.3607 - lr: 1.0000e-04\n",
      "Epoch 410/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 344.4343 - mae: 344.4343 - lr: 1.0000e-04\n",
      "Epoch 411/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 348.9720 - mae: 348.9720 - lr: 1.0000e-04\n",
      "Epoch 412/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 360.2838 - mae: 360.2838 - lr: 1.0000e-04\n",
      "Epoch 413/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 340.2809 - mae: 340.2809 - lr: 1.0000e-04\n",
      "Epoch 414/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 332.6085 - mae: 332.6085 - lr: 1.0000e-04\n",
      "Epoch 415/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 336.0540 - mae: 336.0540 - lr: 1.0000e-04\n",
      "Epoch 416/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 356.5799 - mae: 356.5799 - lr: 1.0000e-04\n",
      "Epoch 417/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 393.8191 - mae: 393.8191 - lr: 1.0000e-04\n",
      "Epoch 418/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 351.6530 - mae: 351.6530 - lr: 1.0000e-04\n",
      "Epoch 419/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 345.2279 - mae: 345.2279 - lr: 1.0000e-04\n",
      "Epoch 420/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 337.4677 - mae: 337.4677 - lr: 1.0000e-04\n",
      "Epoch 421/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 339.5120 - mae: 339.5120 - lr: 1.0000e-04\n",
      "Epoch 422/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 359.8894 - mae: 359.8894 - lr: 1.0000e-04\n",
      "Epoch 423/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 354.8133 - mae: 354.8133 - lr: 1.0000e-04\n",
      "Epoch 424/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 351.1338 - mae: 351.1338 - lr: 1.0000e-04\n",
      "Epoch 425/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 349.3994 - mae: 349.3994 - lr: 1.0000e-04\n",
      "Epoch 426/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 355.4748 - mae: 355.4748 - lr: 1.0000e-04\n",
      "Epoch 427/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 384.5096 - mae: 384.5096 - lr: 1.0000e-04\n",
      "Epoch 428/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 367.4390 - mae: 367.4390 - lr: 1.0000e-04\n",
      "Epoch 429/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 345.1349 - mae: 345.1349 - lr: 1.0000e-04\n",
      "Epoch 430/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 327.0533 - mae: 327.0533INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 15s 551ms/step - loss: 330.5356 - mae: 330.5356 - lr: 1.0000e-04\n",
      "Epoch 431/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 334.0579 - mae: 334.0579 - lr: 1.0000e-04\n",
      "Epoch 432/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 338.5430 - mae: 338.5430 - lr: 1.0000e-04\n",
      "Epoch 433/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 334.0150 - mae: 334.0150 - lr: 1.0000e-04\n",
      "Epoch 434/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 338.3102 - mae: 338.3102 - lr: 1.0000e-04\n",
      "Epoch 435/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 357.7236 - mae: 357.7236 - lr: 1.0000e-04\n",
      "Epoch 436/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 352.1600 - mae: 352.1600 - lr: 1.0000e-04\n",
      "Epoch 437/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 333.2811 - mae: 333.2811 - lr: 1.0000e-04\n",
      "Epoch 438/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 342.2003 - mae: 342.2003 - lr: 1.0000e-04\n",
      "Epoch 439/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 354.3835 - mae: 354.3835 - lr: 1.0000e-04\n",
      "Epoch 440/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 358.9127 - mae: 358.9127 - lr: 1.0000e-04\n",
      "Epoch 441/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 345.5771 - mae: 345.5771 - lr: 1.0000e-04\n",
      "Epoch 442/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 349.4109 - mae: 349.4109 - lr: 1.0000e-04\n",
      "Epoch 443/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 342.9368 - mae: 342.9368 - lr: 1.0000e-04\n",
      "Epoch 444/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 349.5146 - mae: 349.5146 - lr: 1.0000e-04\n",
      "Epoch 445/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 331.7195 - mae: 331.7195 - lr: 1.0000e-04\n",
      "Epoch 446/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 348.8055 - mae: 348.8055 - lr: 1.0000e-04\n",
      "Epoch 447/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27/27 [==============================] - 1s 23ms/step - loss: 340.8655 - mae: 340.8655 - lr: 1.0000e-04\n",
      "Epoch 448/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 347.8114 - mae: 347.8114 - lr: 1.0000e-04\n",
      "Epoch 449/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 342.6366 - mae: 342.6366 - lr: 1.0000e-04\n",
      "Epoch 450/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 348.9814 - mae: 348.9814 - lr: 1.0000e-04\n",
      "Epoch 451/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 353.1248 - mae: 353.1248 - lr: 1.0000e-04\n",
      "Epoch 452/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 348.7598 - mae: 348.7598 - lr: 1.0000e-04\n",
      "Epoch 453/500\n",
      "26/27 [===========================>..] - ETA: 0s - loss: 322.0231 - mae: 322.0231INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 16s 587ms/step - loss: 325.7268 - mae: 325.7268 - lr: 1.0000e-04\n",
      "Epoch 454/500\n",
      "27/27 [==============================] - 1s 27ms/step - loss: 326.9337 - mae: 326.9337 - lr: 1.0000e-04\n",
      "Epoch 455/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 325.8090 - mae: 325.8090 - lr: 1.0000e-04\n",
      "Epoch 456/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 329.9356 - mae: 329.9356 - lr: 1.0000e-04\n",
      "Epoch 457/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 326.2451 - mae: 326.2451 - lr: 1.0000e-04\n",
      "Epoch 458/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 340.8911 - mae: 340.8911 - lr: 1.0000e-04\n",
      "Epoch 459/500\n",
      "25/27 [==========================>...] - ETA: 0s - loss: 293.7558 - mae: 293.7558INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 17s 639ms/step - loss: 324.5640 - mae: 324.5640 - lr: 1.0000e-04\n",
      "Epoch 460/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 339.7928 - mae: 339.7928 - lr: 1.0000e-04\n",
      "Epoch 461/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 331.2902 - mae: 331.2902 - lr: 1.0000e-04\n",
      "Epoch 462/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 326.0495 - mae: 326.0495 - lr: 1.0000e-04\n",
      "Epoch 463/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 345.6654 - mae: 345.6654 - lr: 1.0000e-04\n",
      "Epoch 464/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 340.2869 - mae: 340.2869 - lr: 1.0000e-04\n",
      "Epoch 465/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 340.6534 - mae: 340.6534 - lr: 1.0000e-04\n",
      "Epoch 466/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 325.7405 - mae: 325.7405 - lr: 1.0000e-04\n",
      "Epoch 467/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 324.8366 - mae: 324.8366 - lr: 1.0000e-04\n",
      "Epoch 468/500\n",
      "27/27 [==============================] - ETA: 0s - loss: 319.4445 - mae: 319.4445INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 16s 590ms/step - loss: 319.4445 - mae: 319.4445 - lr: 1.0000e-04\n",
      "Epoch 469/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 321.3003 - mae: 321.3003 - lr: 1.0000e-04\n",
      "Epoch 470/500\n",
      "27/27 [==============================] - ETA: 0s - loss: 318.7802 - mae: 318.7802INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 17s 628ms/step - loss: 318.7802 - mae: 318.7802 - lr: 1.0000e-04\n",
      "Epoch 471/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 319.1259 - mae: 319.1259 - lr: 1.0000e-04\n",
      "Epoch 472/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 332.1708 - mae: 332.1708 - lr: 1.0000e-04\n",
      "Epoch 473/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 332.6115 - mae: 332.6115 - lr: 1.0000e-04\n",
      "Epoch 474/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 347.7318 - mae: 347.7318 - lr: 1.0000e-04\n",
      "Epoch 475/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 334.8591 - mae: 334.8591 - lr: 1.0000e-04\n",
      "Epoch 476/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 335.2926 - mae: 335.2926 - lr: 1.0000e-04\n",
      "Epoch 477/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 343.9136 - mae: 343.9136 - lr: 1.0000e-04\n",
      "Epoch 478/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 323.2682 - mae: 323.2682 - lr: 1.0000e-04\n",
      "Epoch 479/500\n",
      "27/27 [==============================] - 1s 22ms/step - loss: 324.1129 - mae: 324.1129 - lr: 1.0000e-04\n",
      "Epoch 480/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 324.8168 - mae: 324.8168 - lr: 1.0000e-04\n",
      "Epoch 481/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 333.8359 - mae: 333.8359 - lr: 1.0000e-04\n",
      "Epoch 482/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 331.1823 - mae: 331.1823 - lr: 1.0000e-04\n",
      "Epoch 483/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 333.6187 - mae: 333.6187 - lr: 1.0000e-04\n",
      "Epoch 484/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 340.1182 - mae: 340.1182 - lr: 1.0000e-04\n",
      "Epoch 485/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 321.7290 - mae: 321.7290 - lr: 1.0000e-04\n",
      "Epoch 486/500\n",
      "27/27 [==============================] - ETA: 0s - loss: 309.3724 - mae: 309.3724INFO:tensorflow:Assets written to: modelos/n-beats_final/assets\n",
      "27/27 [==============================] - 18s 663ms/step - loss: 309.3724 - mae: 309.3724 - lr: 1.0000e-04\n",
      "Epoch 487/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 333.6636 - mae: 333.6636 - lr: 1.0000e-04\n",
      "Epoch 488/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 338.5391 - mae: 338.5391 - lr: 1.0000e-04\n",
      "Epoch 489/500\n",
      "27/27 [==============================] - 1s 23ms/step - loss: 344.3433 - mae: 344.3433 - lr: 1.0000e-04\n",
      "Epoch 490/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 332.8902 - mae: 332.8902 - lr: 1.0000e-04\n",
      "Epoch 491/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 320.8260 - mae: 320.8260 - lr: 1.0000e-04\n",
      "Epoch 492/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 325.7264 - mae: 325.7264 - lr: 1.0000e-04\n",
      "Epoch 493/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 321.7955 - mae: 321.7955 - lr: 1.0000e-04\n",
      "Epoch 494/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 322.6528 - mae: 322.6528 - lr: 1.0000e-04\n",
      "Epoch 495/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 311.2996 - mae: 311.2996 - lr: 1.0000e-04\n",
      "Epoch 496/500\n",
      "27/27 [==============================] - 1s 24ms/step - loss: 315.4243 - mae: 315.4243 - lr: 1.0000e-04\n",
      "Epoch 497/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 327.6512 - mae: 327.6512 - lr: 1.0000e-04\n",
      "Epoch 498/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 332.7675 - mae: 332.7675 - lr: 1.0000e-04\n",
      "Epoch 499/500\n",
      "27/27 [==============================] - 1s 25ms/step - loss: 324.4462 - mae: 324.4462 - lr: 1.0000e-04\n",
      "Epoch 500/500\n",
      "27/27 [==============================] - 1s 26ms/step - loss: 331.0191 - mae: 331.0191 - lr: 1.0000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f7064406310>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset_price, _ = get_train_test_datasets(X, y, split=1)\n",
    "\n",
    "\n",
    "final_model.compile(loss=\"mae\",\n",
    "                optimizer=tf.keras.optimizers.Adam(),\n",
    "                metrics=[\"mae\"])\n",
    "\n",
    "final_model.fit(train_dataset_price,\n",
    "            epochs=500,\n",
    "            verbose=1,\n",
    "            callbacks=[model_checkpoint(final_model.name, metric=\"loss\"),\n",
    "                       tf.keras.callbacks.ReduceLROnPlateau(monitor=\"loss\", patience=100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
